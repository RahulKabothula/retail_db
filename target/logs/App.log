2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 5
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 127.0 in stage 41.0 (TID 1373) in 45 ms on host.docker.internal (executor driver) (142/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 19 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 19 ms
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1385 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3e218644
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 128.0 in stage 41.0 (TID 1374) in 60 ms on host.docker.internal (executor driver) (143/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 142-143
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1383 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3a4fa8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1385 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3e218644
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1384 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2065201a
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 140.0 in stage 41.0 (TID 1385). 5966 bytes result sent to driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1383 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3a4fa8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1386 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4a956b7e
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 138.0 in stage 41.0 (TID 1383). 5880 bytes result sent to driver
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1384 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2065201a
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 143.0 in stage 41.0 (TID 1388) (host.docker.internal, executor driver, partition 143, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 3
2022-01-11 16:18:08 INFO  Executor:57 - Running task 143.0 in stage 41.0 (TID 1388)
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1386 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4a956b7e
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 139.0 in stage 41.0 (TID 1384). 5923 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 3 ms
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 3
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 141.0 in stage 41.0 (TID 1386). 5880 bytes result sent to driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 2
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 144.0 in stage 41.0 (TID 1389) (host.docker.internal, executor driver, partition 144, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 135.0 in stage 41.0 (TID 1380) in 47 ms on host.docker.internal (executor driver) (144/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 144.0 in stage 41.0 (TID 1389)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 133.0 in stage 41.0 (TID 1378) in 56 ms on host.docker.internal (executor driver) (145/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 3
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1387 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4be39b8a
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 145.0 in stage 41.0 (TID 1390) (host.docker.internal, executor driver, partition 145, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 INFO  Executor:57 - Running task 145.0 in stage 41.0 (TID 1390)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 134.0 in stage 41.0 (TID 1379) in 54 ms on host.docker.internal (executor driver) (146/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 143-144
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1387 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4be39b8a
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 131.0 in stage 41.0 (TID 1377) in 59 ms on host.docker.internal (executor driver) (147/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 142.0 in stage 41.0 (TID 1387). 5923 bytes result sent to driver
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 146.0 in stage 41.0 (TID 1391) (host.docker.internal, executor driver, partition 146, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 3
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 INFO  Executor:57 - Running task 146.0 in stage 41.0 (TID 1391)
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 144-145
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 145-146
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 147.0 in stage 41.0 (TID 1392) (host.docker.internal, executor driver, partition 147, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  Executor:57 - Running task 147.0 in stage 41.0 (TID 1392)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 136.0 in stage 41.0 (TID 1381) in 52 ms on host.docker.internal (executor driver) (148/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 5
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 146-147
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1388 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@6713d629
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 148.0 in stage 41.0 (TID 1393) (host.docker.internal, executor driver, partition 148, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1389 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1518efb6
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 147-148
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1388 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@6713d629
2022-01-11 16:18:08 INFO  Executor:57 - Running task 148.0 in stage 41.0 (TID 1393)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 137.0 in stage 41.0 (TID 1382) in 53 ms on host.docker.internal (executor driver) (149/200)
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1389 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1518efb6
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 143.0 in stage 41.0 (TID 1388). 5923 bytes result sent to driver
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 6
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 138.0 in stage 41.0 (TID 1383) in 46 ms on host.docker.internal (executor driver) (150/200)
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1390 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@209c8b8e
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 144.0 in stage 41.0 (TID 1389). 5880 bytes result sent to driver
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 5
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1390 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@209c8b8e
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 148-149
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 145.0 in stage 41.0 (TID 1390). 5880 bytes result sent to driver
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 149.0 in stage 41.0 (TID 1394) (host.docker.internal, executor driver, partition 149, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 3
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1391 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@30c575e8
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1392 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@642f6092
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 INFO  Executor:57 - Running task 149.0 in stage 41.0 (TID 1394)
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1391 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@30c575e8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 150.0 in stage 41.0 (TID 1395) (host.docker.internal, executor driver, partition 150, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1392 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@642f6092
2022-01-11 16:18:08 INFO  Executor:57 - Running task 150.0 in stage 41.0 (TID 1395)
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 146.0 in stage 41.0 (TID 1391). 5880 bytes result sent to driver
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 147.0 in stage 41.0 (TID 1392). 5880 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 3
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1393 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2a7f6a45
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 151.0 in stage 41.0 (TID 1396) (host.docker.internal, executor driver, partition 151, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 3
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 INFO  Executor:57 - Running task 151.0 in stage 41.0 (TID 1396)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1393 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2a7f6a45
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 152.0 in stage 41.0 (TID 1397) (host.docker.internal, executor driver, partition 152, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 149-150
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 INFO  Executor:57 - Running task 152.0 in stage 41.0 (TID 1397)
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 148.0 in stage 41.0 (TID 1393). 5880 bytes result sent to driver
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 150-151
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 153.0 in stage 41.0 (TID 1398) (host.docker.internal, executor driver, partition 153, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 3
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  Executor:57 - Running task 153.0 in stage 41.0 (TID 1398)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 140.0 in stage 41.0 (TID 1385) in 51 ms on host.docker.internal (executor driver) (151/200)
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 5
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 151-152
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 154.0 in stage 41.0 (TID 1399) (host.docker.internal, executor driver, partition 154, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  Executor:57 - Running task 154.0 in stage 41.0 (TID 1399)
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 3 ms
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 152-153
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 155.0 in stage 41.0 (TID 1400) (host.docker.internal, executor driver, partition 155, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 153-154
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 6
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  Executor:57 - Running task 155.0 in stage 41.0 (TID 1400)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 139.0 in stage 41.0 (TID 1384) in 57 ms on host.docker.internal (executor driver) (152/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1395 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1c148f89
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 141.0 in stage 41.0 (TID 1386) in 54 ms on host.docker.internal (executor driver) (153/200)
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1394 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2afe2d97
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 144.0 in stage 41.0 (TID 1389) in 25 ms on host.docker.internal (executor driver) (154/200)
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1395 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1c148f89
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 154-155
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1396 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@609a7aa9
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 155-156
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 150.0 in stage 41.0 (TID 1395). 5880 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 142.0 in stage 41.0 (TID 1387) in 54 ms on host.docker.internal (executor driver) (155/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 6
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1396 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@609a7aa9
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1394 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2afe2d97
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1397 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7e2b35d5
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 149.0 in stage 41.0 (TID 1394). 5923 bytes result sent to driver
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 151.0 in stage 41.0 (TID 1396). 5880 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 5
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1398 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1861c2eb
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 156.0 in stage 41.0 (TID 1401) (host.docker.internal, executor driver, partition 156, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Running task 156.0 in stage 41.0 (TID 1401)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 146.0 in stage 41.0 (TID 1391) in 27 ms on host.docker.internal (executor driver) (156/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1397 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7e2b35d5
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1398 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1861c2eb
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1400 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@530418da
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 143.0 in stage 41.0 (TID 1388) in 33 ms on host.docker.internal (executor driver) (157/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 5
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 148.0 in stage 41.0 (TID 1393) in 25 ms on host.docker.internal (executor driver) (158/200)
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 152.0 in stage 41.0 (TID 1397). 5880 bytes result sent to driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 145.0 in stage 41.0 (TID 1390) in 31 ms on host.docker.internal (executor driver) (159/200)
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1400 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@530418da
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 153.0 in stage 41.0 (TID 1398). 5880 bytes result sent to driver
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 147.0 in stage 41.0 (TID 1392) in 29 ms on host.docker.internal (executor driver) (160/200)
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1399 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@51df0772
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 155.0 in stage 41.0 (TID 1400). 5880 bytes result sent to driver
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 156-157
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 3
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 157.0 in stage 41.0 (TID 1402) (host.docker.internal, executor driver, partition 157, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 2
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1399 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@51df0772
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 INFO  Executor:57 - Running task 157.0 in stage 41.0 (TID 1402)
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 154.0 in stage 41.0 (TID 1399). 5880 bytes result sent to driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 3
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 2
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 158.0 in stage 41.0 (TID 1403) (host.docker.internal, executor driver, partition 158, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Running task 158.0 in stage 41.0 (TID 1403)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 150.0 in stage 41.0 (TID 1395) in 23 ms on host.docker.internal (executor driver) (161/200)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 149.0 in stage 41.0 (TID 1394) in 25 ms on host.docker.internal (executor driver) (162/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 3
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 159.0 in stage 41.0 (TID 1404) (host.docker.internal, executor driver, partition 159, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1401 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3c13bb02
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 INFO  Executor:57 - Running task 159.0 in stage 41.0 (TID 1404)
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 157-158
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1401 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3c13bb02
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 161.0 in stage 41.0 (TID 1405) (host.docker.internal, executor driver, partition 161, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 INFO  Executor:57 - Running task 161.0 in stage 41.0 (TID 1405)
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 156.0 in stage 41.0 (TID 1401). 5880 bytes result sent to driver
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 158-159
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 5
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 159-160
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 162.0 in stage 41.0 (TID 1406) (host.docker.internal, executor driver, partition 162, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 INFO  Executor:57 - Running task 162.0 in stage 41.0 (TID 1406)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 151.0 in stage 41.0 (TID 1396) in 25 ms on host.docker.internal (executor driver) (163/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1402 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4fca6497
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 5
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 161-162
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1402 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4fca6497
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 163.0 in stage 41.0 (TID 1407) (host.docker.internal, executor driver, partition 163, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 157.0 in stage 41.0 (TID 1402). 5880 bytes result sent to driver
2022-01-11 16:18:08 INFO  Executor:57 - Running task 163.0 in stage 41.0 (TID 1407)
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1404 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@35927beb
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1403 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7dfe8c84
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 5
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1404 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@35927beb
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 162-163
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 2 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1403 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7dfe8c84
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 159.0 in stage 41.0 (TID 1404). 5880 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 3 ms
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 158.0 in stage 41.0 (TID 1403). 5880 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 165.0 in stage 41.0 (TID 1408) (host.docker.internal, executor driver, partition 165, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 3
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 INFO  Executor:57 - Running task 165.0 in stage 41.0 (TID 1408)
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 163-164
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 167.0 in stage 41.0 (TID 1409) (host.docker.internal, executor driver, partition 167, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 152.0 in stage 41.0 (TID 1397) in 35 ms on host.docker.internal (executor driver) (164/200)
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1405 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@723d3745
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 153.0 in stage 41.0 (TID 1398) in 34 ms on host.docker.internal (executor driver) (165/200)
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  Executor:57 - Running task 167.0 in stage 41.0 (TID 1409)
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 154.0 in stage 41.0 (TID 1399) in 33 ms on host.docker.internal (executor driver) (166/200)
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1406 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7fe54b17
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 5
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 165-166
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1406 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7fe54b17
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1405 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@723d3745
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 168.0 in stage 41.0 (TID 1410) (host.docker.internal, executor driver, partition 168, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 161.0 in stage 41.0 (TID 1405). 5880 bytes result sent to driver
2022-01-11 16:18:08 INFO  Executor:57 - Running task 168.0 in stage 41.0 (TID 1410)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 156.0 in stage 41.0 (TID 1401) in 26 ms on host.docker.internal (executor driver) (167/200)
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 162.0 in stage 41.0 (TID 1406). 5923 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 5
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 155.0 in stage 41.0 (TID 1400) in 35 ms on host.docker.internal (executor driver) (168/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1407 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@436372f6
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 157.0 in stage 41.0 (TID 1402) in 21 ms on host.docker.internal (executor driver) (169/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 167-168
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1407 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@436372f6
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 168-169
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1408 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1cdb6294
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 163.0 in stage 41.0 (TID 1407). 5923 bytes result sent to driver
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 3
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 170.0 in stage 41.0 (TID 1411) (host.docker.internal, executor driver, partition 170, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1408 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1cdb6294
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-01-11 16:18:08 INFO  Executor:57 - Running task 170.0 in stage 41.0 (TID 1411)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 159.0 in stage 41.0 (TID 1404) in 21 ms on host.docker.internal (executor driver) (170/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 165.0 in stage 41.0 (TID 1408). 5880 bytes result sent to driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 3
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 171.0 in stage 41.0 (TID 1412) (host.docker.internal, executor driver, partition 171, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1410 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4af90eab
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Running task 171.0 in stage 41.0 (TID 1412)
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1409 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@d6969d7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1410 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4af90eab
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1409 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@d6969d7
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 172.0 in stage 41.0 (TID 1413) (host.docker.internal, executor driver, partition 172, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 168.0 in stage 41.0 (TID 1410). 5880 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 3
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 167.0 in stage 41.0 (TID 1409). 5923 bytes result sent to driver
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 170-171
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 2
2022-01-11 16:18:08 INFO  Executor:57 - Running task 172.0 in stage 41.0 (TID 1413)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 158.0 in stage 41.0 (TID 1403) in 26 ms on host.docker.internal (executor driver) (171/200)
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 3
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 161.0 in stage 41.0 (TID 1405) in 25 ms on host.docker.internal (executor driver) (172/200)
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 171-172
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 173.0 in stage 41.0 (TID 1414) (host.docker.internal, executor driver, partition 173, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 172-173
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 INFO  Executor:57 - Running task 173.0 in stage 41.0 (TID 1414)
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1411 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@267706c8
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 174.0 in stage 41.0 (TID 1415) (host.docker.internal, executor driver, partition 174, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 INFO  Executor:57 - Running task 174.0 in stage 41.0 (TID 1415)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 162.0 in stage 41.0 (TID 1406) in 27 ms on host.docker.internal (executor driver) (173/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1411 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@267706c8
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 163.0 in stage 41.0 (TID 1407) in 23 ms on host.docker.internal (executor driver) (174/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 5
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 2 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 3 ms
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 170.0 in stage 41.0 (TID 1411). 5923 bytes result sent to driver
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1412 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@28ca34b
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 175.0 in stage 41.0 (TID 1416) (host.docker.internal, executor driver, partition 175, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 173-174
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 INFO  Executor:57 - Running task 175.0 in stage 41.0 (TID 1416)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 174-175
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1412 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@28ca34b
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 5
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 177.0 in stage 41.0 (TID 1417) (host.docker.internal, executor driver, partition 177, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 171.0 in stage 41.0 (TID 1412). 5923 bytes result sent to driver
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1413 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7d09eb04
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-01-11 16:18:08 INFO  Executor:57 - Running task 177.0 in stage 41.0 (TID 1417)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 5
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1413 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7d09eb04
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 178.0 in stage 41.0 (TID 1418) (host.docker.internal, executor driver, partition 178, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 INFO  Executor:57 - Running task 178.0 in stage 41.0 (TID 1418)
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 172.0 in stage 41.0 (TID 1413). 5880 bytes result sent to driver
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 165.0 in stage 41.0 (TID 1408) in 28 ms on host.docker.internal (executor driver) (175/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 175-176
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 5
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 3 ms
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1414 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@196fb782
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 177-178
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 180.0 in stage 41.0 (TID 1419) (host.docker.internal, executor driver, partition 180, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 INFO  Executor:57 - Running task 180.0 in stage 41.0 (TID 1419)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 168.0 in stage 41.0 (TID 1410) in 25 ms on host.docker.internal (executor driver) (176/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 6
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 167.0 in stage 41.0 (TID 1409) in 30 ms on host.docker.internal (executor driver) (177/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 178-179
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1415 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@77c9ce07
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1414 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@196fb782
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 2 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 3 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 173.0 in stage 41.0 (TID 1414). 5923 bytes result sent to driver
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 181.0 in stage 41.0 (TID 1420) (host.docker.internal, executor driver, partition 181, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 5
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1415 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@77c9ce07
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 180-181
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1416 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@55b5c435
2022-01-11 16:18:08 INFO  Executor:57 - Running task 181.0 in stage 41.0 (TID 1420)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 170.0 in stage 41.0 (TID 1411) in 24 ms on host.docker.internal (executor driver) (178/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 6
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 174.0 in stage 41.0 (TID 1415). 5923 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 5
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1416 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@55b5c435
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 171.0 in stage 41.0 (TID 1412) in 22 ms on host.docker.internal (executor driver) (179/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 175.0 in stage 41.0 (TID 1416). 5880 bytes result sent to driver
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1417 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5df186c9
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1418 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@26ac3d13
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 181-182
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1417 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5df186c9
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 182.0 in stage 41.0 (TID 1421) (host.docker.internal, executor driver, partition 182, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 177.0 in stage 41.0 (TID 1417). 5923 bytes result sent to driver
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 INFO  Executor:57 - Running task 182.0 in stage 41.0 (TID 1421)
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1418 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@26ac3d13
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 3
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 178.0 in stage 41.0 (TID 1418). 5923 bytes result sent to driver
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1419 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@f8cea91
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 3
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 184.0 in stage 41.0 (TID 1422) (host.docker.internal, executor driver, partition 184, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Running task 184.0 in stage 41.0 (TID 1422)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 172.0 in stage 41.0 (TID 1413) in 27 ms on host.docker.internal (executor driver) (180/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 173.0 in stage 41.0 (TID 1414) in 24 ms on host.docker.internal (executor driver) (181/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1419 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@f8cea91
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1420 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@67d091fc
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 182-183
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 180.0 in stage 41.0 (TID 1419). 5880 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 3
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 185.0 in stage 41.0 (TID 1423) (host.docker.internal, executor driver, partition 185, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1420 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@67d091fc
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 INFO  Executor:57 - Running task 185.0 in stage 41.0 (TID 1423)
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 181.0 in stage 41.0 (TID 1420). 5880 bytes result sent to driver
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 186.0 in stage 41.0 (TID 1424) (host.docker.internal, executor driver, partition 186, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 INFO  Executor:57 - Running task 186.0 in stage 41.0 (TID 1424)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 174.0 in stage 41.0 (TID 1415) in 27 ms on host.docker.internal (executor driver) (182/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 3
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 175.0 in stage 41.0 (TID 1416) in 23 ms on host.docker.internal (executor driver) (183/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 184-185
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 187.0 in stage 41.0 (TID 1425) (host.docker.internal, executor driver, partition 187, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 INFO  Executor:57 - Running task 187.0 in stage 41.0 (TID 1425)
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 185-186
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1421 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5ada4a5
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 5
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 186-187
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1421 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5ada4a5
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 188.0 in stage 41.0 (TID 1426) (host.docker.internal, executor driver, partition 188, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 182.0 in stage 41.0 (TID 1421). 5880 bytes result sent to driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  Executor:57 - Running task 188.0 in stage 41.0 (TID 1426)
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1422 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@75f51106
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 5
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 187-188
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 189.0 in stage 41.0 (TID 1427) (host.docker.internal, executor driver, partition 189, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1423 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@340b25ce
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Running task 189.0 in stage 41.0 (TID 1427)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 177.0 in stage 41.0 (TID 1417) in 28 ms on host.docker.internal (executor driver) (184/200)
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1422 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@75f51106
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 6
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1423 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@340b25ce
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 184.0 in stage 41.0 (TID 1422). 5880 bytes result sent to driver
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 192.0 in stage 41.0 (TID 1428) (host.docker.internal, executor driver, partition 192, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 5
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1424 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@29919373
2022-01-11 16:18:08 INFO  Executor:57 - Running task 192.0 in stage 41.0 (TID 1428)
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 185.0 in stage 41.0 (TID 1423). 5880 bytes result sent to driver
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 178.0 in stage 41.0 (TID 1418) in 29 ms on host.docker.internal (executor driver) (185/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 5
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 188-189
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 189-190
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 194.0 in stage 41.0 (TID 1429) (host.docker.internal, executor driver, partition 194, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  Executor:57 - Running task 194.0 in stage 41.0 (TID 1429)
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1424 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@29919373
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1425 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@10cf269a
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 192-193
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 6
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 3 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 3 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 3 ms
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1425 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@10cf269a
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 186.0 in stage 41.0 (TID 1424). 5880 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 187.0 in stage 41.0 (TID 1425). 5880 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 5
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 194-195
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 2 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 3 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 195.0 in stage 41.0 (TID 1430) (host.docker.internal, executor driver, partition 195, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Running task 195.0 in stage 41.0 (TID 1430)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 180.0 in stage 41.0 (TID 1419) in 35 ms on host.docker.internal (executor driver) (186/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1427 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2a29c405
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 181.0 in stage 41.0 (TID 1420) in 31 ms on host.docker.internal (executor driver) (187/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 5
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1426 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7abff993
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 184.0 in stage 41.0 (TID 1422) in 24 ms on host.docker.internal (executor driver) (188/200)
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1428 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@90617d9
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1427 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2a29c405
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 196.0 in stage 41.0 (TID 1431) (host.docker.internal, executor driver, partition 196, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1428 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@90617d9
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1426 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7abff993
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 192.0 in stage 41.0 (TID 1428). 5880 bytes result sent to driver
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 189.0 in stage 41.0 (TID 1427). 5880 bytes result sent to driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 INFO  Executor:57 - Running task 196.0 in stage 41.0 (TID 1431)
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 195-196
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 188.0 in stage 41.0 (TID 1426). 5880 bytes result sent to driver
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 197.0 in stage 41.0 (TID 1432) (host.docker.internal, executor driver, partition 197, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 5
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1429 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@55b7ebd8
2022-01-11 16:18:08 INFO  Executor:57 - Running task 197.0 in stage 41.0 (TID 1432)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 185.0 in stage 41.0 (TID 1423) in 25 ms on host.docker.internal (executor driver) (189/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 5
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 182.0 in stage 41.0 (TID 1421) in 30 ms on host.docker.internal (executor driver) (190/200)
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1429 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@55b7ebd8
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 194.0 in stage 41.0 (TID 1429). 5880 bytes result sent to driver
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 196-197
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 198.0 in stage 41.0 (TID 1433) (host.docker.internal, executor driver, partition 198, PROCESS_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 3
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1430 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5383f6dd
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  Executor:57 - Running task 198.0 in stage 41.0 (TID 1433)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 186.0 in stage 41.0 (TID 1424) in 27 ms on host.docker.internal (executor driver) (191/200)
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 4
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 187.0 in stage 41.0 (TID 1425) in 24 ms on host.docker.internal (executor driver) (192/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1430 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5383f6dd
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 197-198
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_41.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 195.0 in stage 41.0 (TID 1430). 5880 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 3
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1431 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@f802222
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 192.0 in stage 41.0 (TID 1428) in 20 ms on host.docker.internal (executor driver) (193/200)
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 189.0 in stage 41.0 (TID 1427) in 22 ms on host.docker.internal (executor driver) (194/200)
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 194.0 in stage 41.0 (TID 1429) in 16 ms on host.docker.internal (executor driver) (195/200)
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 198-199
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 195.0 in stage 41.0 (TID 1430) in 12 ms on host.docker.internal (executor driver) (196/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 188.0 in stage 41.0 (TID 1426) in 27 ms on host.docker.internal (executor driver) (197/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1431 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@f802222
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 196.0 in stage 41.0 (TID 1431). 5880 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 2
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 196.0 in stage 41.0 (TID 1431) in 11 ms on host.docker.internal (executor driver) (198/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1432 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@52565da9
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1432 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@52565da9
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1433 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@10701330
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 197.0 in stage 41.0 (TID 1432). 5880 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (41, 0) -> 1
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 197.0 in stage 41.0 (TID 1432) in 11 ms on host.docker.internal (executor driver) (199/200)
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1433 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@10701330
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 198.0 in stage 41.0 (TID 1433). 5880 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - removing (41, 0) from stageTCMP
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 198.0 in stage 41.0 (TID 1433) in 9 ms on host.docker.internal (executor driver) (200/200)
2022-01-11 16:18:08 INFO  TaskSchedulerImpl:57 - Removed TaskSet 41.0, whose tasks have all completed, from pool 
2022-01-11 16:18:08 INFO  DAGScheduler:57 - ResultStage 41 (save at Load.java:11) finished in 0.635 s
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - After removal of stage 41, remaining stages = 1
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - After removal of stage 40, remaining stages = 0
2022-01-11 16:18:08 INFO  DAGScheduler:57 - Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
2022-01-11 16:18:08 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 41: Stage finished
2022-01-11 16:18:08 INFO  DAGScheduler:57 - Job 28 finished: save at Load.java:11, took 0.850685 s
2022-01-11 16:18:08 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-01-11 16:18:08 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-01-11 16:18:08 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage6(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=6
/* 006 */ final class GeneratedIteratorForCodegenStage6 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean sort_needToSort_0;
/* 010 */   private org.apache.spark.sql.execution.UnsafeExternalRowSorter sort_sorter_0;
/* 011 */   private org.apache.spark.executor.TaskMetrics sort_metrics_0;
/* 012 */   private scala.collection.Iterator<UnsafeRow> sort_sortedIter_0;
/* 013 */   private scala.collection.Iterator inputadapter_input_0;
/* 014 */
/* 015 */   public GeneratedIteratorForCodegenStage6(Object[] references) {
/* 016 */     this.references = references;
/* 017 */   }
/* 018 */
/* 019 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 020 */     partitionIndex = index;
/* 021 */     this.inputs = inputs;
/* 022 */     sort_needToSort_0 = true;
/* 023 */     sort_sorter_0 = ((org.apache.spark.sql.execution.SortExec) references[0] /* plan */).createSorter();
/* 024 */     sort_metrics_0 = org.apache.spark.TaskContext.get().taskMetrics();
/* 025 */
/* 026 */     inputadapter_input_0 = inputs[0];
/* 027 */
/* 028 */   }
/* 029 */
/* 030 */   private void sort_addToSorter_0() throws java.io.IOException {
/* 031 */     while ( inputadapter_input_0.hasNext()) {
/* 032 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 033 */
/* 034 */       sort_sorter_0.insertRow((UnsafeRow)inputadapter_row_0);
/* 035 */       // shouldStop check is eliminated
/* 036 */     }
/* 037 */
/* 038 */   }
/* 039 */
/* 040 */   protected void processNext() throws java.io.IOException {
/* 041 */     if (sort_needToSort_0) {
/* 042 */       long sort_spillSizeBefore_0 = sort_metrics_0.memoryBytesSpilled();
/* 043 */       sort_addToSorter_0();
/* 044 */       sort_sortedIter_0 = sort_sorter_0.sort();
/* 045 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[3] /* sortTime */).add(sort_sorter_0.getSortTimeNanos() / 1000000);
/* 046 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* peakMemory */).add(sort_sorter_0.getPeakMemoryUsage());
/* 047 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[2] /* spillSize */).add(sort_metrics_0.memoryBytesSpilled() - sort_spillSizeBefore_0);
/* 048 */       sort_metrics_0.incPeakExecutionMemory(sort_sorter_0.getPeakMemoryUsage());
/* 049 */       sort_needToSort_0 = false;
/* 050 */     }
/* 051 */
/* 052 */     while ( sort_sortedIter_0.hasNext()) {
/* 053 */       UnsafeRow sort_outputRow_0 = (UnsafeRow)sort_sortedIter_0.next();
/* 054 */
/* 055 */       append(sort_outputRow_0);
/* 056 */
/* 057 */       if (shouldStop()) return;
/* 058 */     }
/* 059 */   }
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-01-11 16:18:08 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-01-11 16:18:08 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$write$15
2022-01-11 16:18:08 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$write$15) is now cleaned +++
2022-01-11 16:18:08 INFO  SparkContext:57 - Starting job: save at Load.java:11
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - Merging stage rdd profiles: Set()
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - Merging stage rdd profiles: Set()
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - Merging stage rdd profiles: Set()
2022-01-11 16:18:08 INFO  DAGScheduler:57 - Registering RDD 169 (save at Load.java:11) as input to shuffle 9
2022-01-11 16:18:08 INFO  DAGScheduler:57 - Got job 29 (save at Load.java:11) with 1 output partitions
2022-01-11 16:18:08 INFO  DAGScheduler:57 - Final stage: ResultStage 44 (save at Load.java:11)
2022-01-11 16:18:08 INFO  DAGScheduler:57 - Parents of final stage: List(ShuffleMapStage 43)
2022-01-11 16:18:08 INFO  DAGScheduler:57 - Missing parents: List(ShuffleMapStage 43)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - submitStage(ResultStage 44 (name=save at Load.java:11;jobs=29))
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - missing: List(ShuffleMapStage 43)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - submitStage(ShuffleMapStage 43 (name=save at Load.java:11;jobs=29))
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - missing: List()
2022-01-11 16:18:08 INFO  DAGScheduler:57 - Submitting ShuffleMapStage 43 (MapPartitionsRDD[169] at save at Load.java:11), which has no missing parents
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - submitMissingTasks(ShuffleMapStage 43)
2022-01-11 16:18:08 INFO  MemoryStore:57 - Block broadcast_72 stored as values in memory (estimated size 49.0 KiB, free 2.2 GiB)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Put block broadcast_72 locally took 0 ms
2022-01-11 16:18:08 DEBUG BlockManager:61 - Putting block broadcast_72 without replication took 0 ms
2022-01-11 16:18:08 INFO  MemoryStore:57 - Block broadcast_72_piece0 stored as bytes in memory (estimated size 23.0 KiB, free 2.2 GiB)
2022-01-11 16:18:08 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_72_piece0 for BlockManagerId(driver, host.docker.internal, 57009, None)
2022-01-11 16:18:08 INFO  BlockManagerInfo:57 - Added broadcast_72_piece0 in memory on host.docker.internal:57009 (size: 23.0 KiB, free: 2.2 GiB)
2022-01-11 16:18:08 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_72_piece0
2022-01-11 16:18:08 DEBUG BlockManager:61 - Told master about block broadcast_72_piece0
2022-01-11 16:18:08 DEBUG BlockManager:61 - Put block broadcast_72_piece0 locally took 0 ms
2022-01-11 16:18:08 DEBUG BlockManager:61 - Putting block broadcast_72_piece0 without replication took 0 ms
2022-01-11 16:18:08 INFO  SparkContext:57 - Created broadcast 72 from broadcast at DAGScheduler.scala:1388
2022-01-11 16:18:08 INFO  DAGScheduler:57 - Submitting 200 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[169] at save at Load.java:11) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2022-01-11 16:18:08 INFO  TaskSchedulerImpl:57 - Adding task set 43.0 with 200 tasks resource profile 0
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Epoch for TaskSet 43.0: 9
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 43.0: NODE_LOCAL, NO_PREF, ANY
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 0
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 7.0 in stage 43.0 (TID 1434) (host.docker.internal, executor driver, partition 7, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 17.0 in stage 43.0 (TID 1435) (host.docker.internal, executor driver, partition 17, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 19.0 in stage 43.0 (TID 1436) (host.docker.internal, executor driver, partition 19, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 29.0 in stage 43.0 (TID 1437) (host.docker.internal, executor driver, partition 29, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 31.0 in stage 43.0 (TID 1438) (host.docker.internal, executor driver, partition 31, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 35.0 in stage 43.0 (TID 1439) (host.docker.internal, executor driver, partition 35, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 38.0 in stage 43.0 (TID 1440) (host.docker.internal, executor driver, partition 38, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 42.0 in stage 43.0 (TID 1441) (host.docker.internal, executor driver, partition 42, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  Executor:57 - Running task 7.0 in stage 43.0 (TID 1434)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 38.0 in stage 43.0 (TID 1440)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 42.0 in stage 43.0 (TID 1441)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 35.0 in stage 43.0 (TID 1439)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 29.0 in stage 43.0 (TID 1437)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 19.0 in stage 43.0 (TID 1436)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 31.0 in stage 43.0 (TID 1438)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 6
2022-01-11 16:18:08 INFO  Executor:57 - Running task 17.0 in stage 43.0 (TID 1435)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 5
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 4
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 3
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 2
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 1
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local block broadcast_72
2022-01-11 16:18:08 DEBUG BlockManager:61 - Level for block broadcast_72 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 31-32
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 7-8
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 19-20
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 42-43
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 29-30
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 17-18
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 35-36
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 38-39
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_31,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_31
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_29,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_29
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_7,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_7
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 3 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_17,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_17
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_19,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_19
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 3 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_42,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_42
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 3 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_38,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_38
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 3 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 4 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1437 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@59bd8db5
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 3 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_35,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_35
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1438 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4e64a62e
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1434 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@32700c83
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1435 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2fd11d2d
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 5 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1440 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@263cba1a
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1436 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@340b94ff
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1438 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@4e64a62e
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1434 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@32700c83
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1437 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@59bd8db5
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1434 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@32700c83
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1438 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4e64a62e
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1436 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@340b94ff
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1441 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@461eaa29
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1437 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@59bd8db5
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1441 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@461eaa29
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1435 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@2fd11d2d
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1441 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@461eaa29
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1436 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@340b94ff
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1440 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@263cba1a
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1439 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2ded6fe4
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1435 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2fd11d2d
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1434 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@32700c83
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1440 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@263cba1a
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1437 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@59bd8db5
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1436 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@340b94ff
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1438 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@4e64a62e
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1435 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@2fd11d2d
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1441 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@461eaa29
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1439 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@2ded6fe4
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1439 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2ded6fe4
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1439 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@2ded6fe4
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1440 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@263cba1a
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1436 with length 33
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1435 with length 33
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1441 with length 33
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1437 with length 33
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1438 with length 33
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1434 with length 33
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1439 with length 33
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1440 with length 33
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1436: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,88,0,0,0,0,0,0]
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 19.0 in stage 43.0 (TID 1436). 6139 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 43.0 in stage 43.0 (TID 1442) (host.docker.internal, executor driver, partition 43, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  Executor:57 - Running task 43.0 in stage 43.0 (TID 1442)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 19.0 in stage 43.0 (TID 1436) in 45 ms on host.docker.internal (executor driver) (1/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 43-44
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_43,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_43
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1442 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@581726ff
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1442 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@581726ff
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1442 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@581726ff
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1442 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@581726ff
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1440: [0,0,0,0,0,79,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 38.0 in stage 43.0 (TID 1440). 6139 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 48.0 in stage 43.0 (TID 1443) (host.docker.internal, executor driver, partition 48, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  Executor:57 - Running task 48.0 in stage 43.0 (TID 1443)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 38.0 in stage 43.0 (TID 1440) in 55 ms on host.docker.internal (executor driver) (2/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1442 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 48-49
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_48,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_48
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1443 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@32038f90
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1443 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@32038f90
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1439: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,84,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1443 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@32038f90
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 35.0 in stage 43.0 (TID 1439). 6096 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 52.0 in stage 43.0 (TID 1444) (host.docker.internal, executor driver, partition 52, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  Executor:57 - Running task 52.0 in stage 43.0 (TID 1444)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 35.0 in stage 43.0 (TID 1439) in 66 ms on host.docker.internal (executor driver) (3/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1443 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@32038f90
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 52-53
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_52,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_52
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1444 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@266d1488
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1444 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@266d1488
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1444 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@266d1488
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1434: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,92,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 7.0 in stage 43.0 (TID 1434). 6139 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1444 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@266d1488
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 63.0 in stage 43.0 (TID 1445) (host.docker.internal, executor driver, partition 63, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1443 with length 33
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 7.0 in stage 43.0 (TID 1434) in 77 ms on host.docker.internal (executor driver) (4/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 63.0 in stage 43.0 (TID 1445)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 63-64
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_63,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_63
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1444 with length 33
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1445 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@231744c
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1445 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@231744c
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1445 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@231744c
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1438: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,100,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 31.0 in stage 43.0 (TID 1438). 6139 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 73.0 in stage 43.0 (TID 1446) (host.docker.internal, executor driver, partition 73, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 31.0 in stage 43.0 (TID 1438) in 87 ms on host.docker.internal (executor driver) (5/200)
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1445 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@231744c
2022-01-11 16:18:08 INFO  Executor:57 - Running task 73.0 in stage 43.0 (TID 1446)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 73-74
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_73,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_73
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1445 with length 33
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1437: [0,0,0,0,0,0,0,0,100,0,0,0,0,0,0,0,0,0,0,0,88,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1446 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@68767315
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 29.0 in stage 43.0 (TID 1437). 6139 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 74.0 in stage 43.0 (TID 1447) (host.docker.internal, executor driver, partition 74, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1446 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@68767315
2022-01-11 16:18:08 INFO  Executor:57 - Running task 74.0 in stage 43.0 (TID 1447)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 29.0 in stage 43.0 (TID 1437) in 96 ms on host.docker.internal (executor driver) (6/200)
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1446 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@68767315
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 74-75
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1446 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@68767315
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_74,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_74
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1447 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@50653072
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1447 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@50653072
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1447 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@50653072
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1441: [0,0,0,84,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1447 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@50653072
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 42.0 in stage 43.0 (TID 1441). 6139 bytes result sent to driver
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1446 with length 33
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 86.0 in stage 43.0 (TID 1448) (host.docker.internal, executor driver, partition 86, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 42.0 in stage 43.0 (TID 1441) in 107 ms on host.docker.internal (executor driver) (7/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 86.0 in stage 43.0 (TID 1448)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1447 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 86-87
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_86,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_86
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1448 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2b44a0ea
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1448 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@2b44a0ea
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1448 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2b44a0ea
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1435: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,92,0,0,0,0,0,0,0]
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 17.0 in stage 43.0 (TID 1435). 6139 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1448 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@2b44a0ea
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 89.0 in stage 43.0 (TID 1449) (host.docker.internal, executor driver, partition 89, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  Executor:57 - Running task 89.0 in stage 43.0 (TID 1449)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 17.0 in stage 43.0 (TID 1435) in 121 ms on host.docker.internal (executor driver) (8/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 89-90
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1448 with length 33
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_89,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_89
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1449 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2265f7c6
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1447: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,92,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1449 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@2265f7c6
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1449 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2265f7c6
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 74.0 in stage 43.0 (TID 1447). 6139 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 90.0 in stage 43.0 (TID 1450) (host.docker.internal, executor driver, partition 90, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  Executor:57 - Running task 90.0 in stage 43.0 (TID 1450)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 74.0 in stage 43.0 (TID 1447) in 35 ms on host.docker.internal (executor driver) (9/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1449 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@2265f7c6
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 90-91
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_90,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_90
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1450 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2000f70a
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1450 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@2000f70a
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1449 with length 33
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1450 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2000f70a
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1446: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,92,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 73.0 in stage 43.0 (TID 1446). 6182 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 108.0 in stage 43.0 (TID 1451) (host.docker.internal, executor driver, partition 108, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 73.0 in stage 43.0 (TID 1446) in 56 ms on host.docker.internal (executor driver) (10/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 108.0 in stage 43.0 (TID 1451)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1450 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@2000f70a
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 108-109
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1450 with length 33
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_108,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_108
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1451 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@51c07ca4
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1451 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@51c07ca4
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1451 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@51c07ca4
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1445: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,100,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 63.0 in stage 43.0 (TID 1445). 6139 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 115.0 in stage 43.0 (TID 1452) (host.docker.internal, executor driver, partition 115, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1451 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@51c07ca4
2022-01-11 16:18:08 INFO  Executor:57 - Running task 115.0 in stage 43.0 (TID 1452)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 63.0 in stage 43.0 (TID 1445) in 78 ms on host.docker.internal (executor driver) (11/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 115-116
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_115,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_115
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1451 with length 33
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1452 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@48a4426
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1444: [0,0,92,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1452 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@48a4426
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1452 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@48a4426
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 52.0 in stage 43.0 (TID 1444). 6139 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 132.0 in stage 43.0 (TID 1453) (host.docker.internal, executor driver, partition 132, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 52.0 in stage 43.0 (TID 1444) in 98 ms on host.docker.internal (executor driver) (12/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 132.0 in stage 43.0 (TID 1453)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1452 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@48a4426
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 132-133
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_132,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_132
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1443: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,92]
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1453 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@71154e6d
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 48.0 in stage 43.0 (TID 1443). 6139 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 160.0 in stage 43.0 (TID 1454) (host.docker.internal, executor driver, partition 160, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1453 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@71154e6d
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1452 with length 33
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1453 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@71154e6d
2022-01-11 16:18:08 INFO  Executor:57 - Running task 160.0 in stage 43.0 (TID 1454)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 48.0 in stage 43.0 (TID 1443) in 115 ms on host.docker.internal (executor driver) (13/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1453 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@71154e6d
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 160-161
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_160,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_160
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1454 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7be265ac
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1454 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@7be265ac
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1454 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7be265ac
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1442: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,92,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1453 with length 33
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 43.0 in stage 43.0 (TID 1442). 6139 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 164.0 in stage 43.0 (TID 1455) (host.docker.internal, executor driver, partition 164, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 43.0 in stage 43.0 (TID 1442) in 139 ms on host.docker.internal (executor driver) (14/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 164.0 in stage 43.0 (TID 1455)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1454 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@7be265ac
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 164-165
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_164,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_164
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1455 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@58ccfb20
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1455 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@58ccfb20
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1455 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@58ccfb20
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1452: [0,0,0,0,88,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 115.0 in stage 43.0 (TID 1452). 6139 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1454 with length 33
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 166.0 in stage 43.0 (TID 1456) (host.docker.internal, executor driver, partition 166, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 115.0 in stage 43.0 (TID 1452) in 38 ms on host.docker.internal (executor driver) (15/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 166.0 in stage 43.0 (TID 1456)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1455 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@58ccfb20
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 166-167
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_166,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_166
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1456 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@70ba12fa
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1456 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@70ba12fa
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1456 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@70ba12fa
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1455 with length 33
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1451: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,88,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1456 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@70ba12fa
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 108.0 in stage 43.0 (TID 1451). 6139 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 169.0 in stage 43.0 (TID 1457) (host.docker.internal, executor driver, partition 169, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 108.0 in stage 43.0 (TID 1451) in 60 ms on host.docker.internal (executor driver) (16/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 169.0 in stage 43.0 (TID 1457)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 169-170
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_169,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_169
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1456 with length 33
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1457 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1a9413d5
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1457 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@1a9413d5
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1457 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1a9413d5
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1450: [0,0,0,0,0,0,0,0,0,0,92,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1457 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@1a9413d5
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 90.0 in stage 43.0 (TID 1450). 6139 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 176.0 in stage 43.0 (TID 1458) (host.docker.internal, executor driver, partition 176, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 90.0 in stage 43.0 (TID 1450) in 80 ms on host.docker.internal (executor driver) (17/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 176.0 in stage 43.0 (TID 1458)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1457 with length 33
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 176-177
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_176,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_176
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1458 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@20dbd78a
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1458 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@20dbd78a
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1458 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@20dbd78a
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1458 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@20dbd78a
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1449: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,100,0,0,0]
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 89.0 in stage 43.0 (TID 1449). 6139 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 179.0 in stage 43.0 (TID 1459) (host.docker.internal, executor driver, partition 179, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  Executor:57 - Running task 179.0 in stage 43.0 (TID 1459)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 89.0 in stage 43.0 (TID 1449) in 100 ms on host.docker.internal (executor driver) (18/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 179-180
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1458 with length 33
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_179,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_179
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1459 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@35acd829
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1448: [0,0,0,0,0,0,92,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 86.0 in stage 43.0 (TID 1448). 6139 bytes result sent to driver
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1459 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@35acd829
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1459 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@35acd829
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 183.0 in stage 43.0 (TID 1460) (host.docker.internal, executor driver, partition 183, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  Executor:57 - Running task 183.0 in stage 43.0 (TID 1460)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 86.0 in stage 43.0 (TID 1448) in 121 ms on host.docker.internal (executor driver) (19/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1459 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@35acd829
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 183-184
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_183,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_183
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1460 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@47e4b0a2
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1460 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@47e4b0a2
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1460 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@47e4b0a2
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1458: [0,0,0,0,0,0,0,0,0,0,0,0,84,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 176.0 in stage 43.0 (TID 1458). 6139 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1459 with length 33
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 190.0 in stage 43.0 (TID 1461) (host.docker.internal, executor driver, partition 190, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 176.0 in stage 43.0 (TID 1458) in 28 ms on host.docker.internal (executor driver) (20/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 190.0 in stage 43.0 (TID 1461)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1460 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@47e4b0a2
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 190-191
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_190,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_190
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1461 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@759c8a81
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1461 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@759c8a81
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1461 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@759c8a81
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1457: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,92,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 169.0 in stage 43.0 (TID 1457). 6139 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 191.0 in stage 43.0 (TID 1462) (host.docker.internal, executor driver, partition 191, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 169.0 in stage 43.0 (TID 1457) in 49 ms on host.docker.internal (executor driver) (21/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 191.0 in stage 43.0 (TID 1462)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1461 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@759c8a81
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1460 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 191-192
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_191,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_191
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1462 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@61cc2db
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1462 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@61cc2db
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1462 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@61cc2db
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1456: [0,0,0,0,0,0,0,100,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 166.0 in stage 43.0 (TID 1456). 6096 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1461 with length 33
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 193.0 in stage 43.0 (TID 1463) (host.docker.internal, executor driver, partition 193, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 166.0 in stage 43.0 (TID 1456) in 65 ms on host.docker.internal (executor driver) (22/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 193.0 in stage 43.0 (TID 1463)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1462 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@61cc2db
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 193-194
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_193,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_193
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1463 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@47a34ab2
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1455: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,80,0,0]
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1463 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@47a34ab2
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1463 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@47a34ab2
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 164.0 in stage 43.0 (TID 1455). 6139 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 199.0 in stage 43.0 (TID 1464) (host.docker.internal, executor driver, partition 199, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1462 with length 33
2022-01-11 16:18:08 INFO  Executor:57 - Running task 199.0 in stage 43.0 (TID 1464)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 164.0 in stage 43.0 (TID 1455) in 83 ms on host.docker.internal (executor driver) (23/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1463 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@47a34ab2
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 199-200
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_8_1233_199,0)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Getting local shuffle block shuffle_8_1233_199
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1464 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@333a1380
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1454: [0,100,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 160.0 in stage 43.0 (TID 1454). 6139 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1464 acquired 16.0 MiB for org.apache.spark.unsafe.map.BytesToBytesMap@333a1380
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1464 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@333a1380
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 0.0 in stage 43.0 (TID 1465) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  Executor:57 - Running task 0.0 in stage 43.0 (TID 1465)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 160.0 in stage 43.0 (TID 1454) in 103 ms on host.docker.internal (executor driver) (24/200)
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1463 with length 33
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1464 release 16.0 MiB from org.apache.spark.unsafe.map.BytesToBytesMap@333a1380
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 0-1
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1465 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@66cec59b
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1465 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@66cec59b
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1465 with length 33
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1453: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,92,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 132.0 in stage 43.0 (TID 1453). 6182 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 1.0 in stage 43.0 (TID 1466) (host.docker.internal, executor driver, partition 1, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  Executor:57 - Running task 1.0 in stage 43.0 (TID 1466)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 132.0 in stage 43.0 (TID 1453) in 120 ms on host.docker.internal (executor driver) (25/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1464 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 1-2
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1465: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 0.0 in stage 43.0 (TID 1465). 6010 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 2.0 in stage 43.0 (TID 1467) (host.docker.internal, executor driver, partition 2, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 0.0 in stage 43.0 (TID 1465) in 14 ms on host.docker.internal (executor driver) (26/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 2.0 in stage 43.0 (TID 1467)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1466 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3e5c59dc
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1466 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3e5c59dc
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1466 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 2-3
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1467 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@512ac7b1
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1467 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@512ac7b1
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1467 with length 33
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1463: [0,0,0,0,0,0,0,0,0,91,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 193.0 in stage 43.0 (TID 1463). 6139 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 3.0 in stage 43.0 (TID 1468) (host.docker.internal, executor driver, partition 3, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 193.0 in stage 43.0 (TID 1463) in 40 ms on host.docker.internal (executor driver) (27/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 3.0 in stage 43.0 (TID 1468)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 3-4
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1468 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@62ae17a1
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1468 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@62ae17a1
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1468 with length 33
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1462: [0,0,0,0,0,0,0,0,0,0,0,0,0,92,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1389)
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 191.0 in stage 43.0 (TID 1462). 6139 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1389
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1389
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1400)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1400
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 4.0 in stage 43.0 (TID 1469) (host.docker.internal, executor driver, partition 4, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1400
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1467)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1467
2022-01-11 16:18:08 INFO  Executor:57 - Running task 4.0 in stage 43.0 (TID 1469)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 191.0 in stage 43.0 (TID 1462) in 60 ms on host.docker.internal (executor driver) (28/200)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1467
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1473)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1473
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1473
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1425)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1425
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1425
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1380)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1380
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1380
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1484)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1484
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1484
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1387)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1387
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1387
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1393)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1393
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1393
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1379)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1379
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1379
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1381)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1381
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1381
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1490)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1490
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1490
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1491)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1491
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1491
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1499)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1499
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1499
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1392)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1392
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1392
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1402)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1402
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1402
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1460)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1460
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1460
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1474)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1474
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1474
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 4-5
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1404)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1404
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1404
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1419)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1419
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1419
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1377)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1377
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1377
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1461: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,92,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1495)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1495
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1495
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 190.0 in stage 43.0 (TID 1461). 6182 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(70)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning broadcast 70
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 70
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG BlockManagerStorageEndpoint:61 - removing broadcast 70
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 5.0 in stage 43.0 (TID 1470) (host.docker.internal, executor driver, partition 5, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG BlockManager:61 - Removing broadcast 70
2022-01-11 16:18:08 INFO  Executor:57 - Running task 5.0 in stage 43.0 (TID 1470)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Removing block broadcast_70
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 190.0 in stage 43.0 (TID 1461) in 78 ms on host.docker.internal (executor driver) (29/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG MemoryStore:61 - Block broadcast_70 of size 50352 dropped from memory (free 2332267643)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1469 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3cf634e1
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1469 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3cf634e1
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1469 with length 33
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG BlockManager:61 - Removing block broadcast_70_piece0
2022-01-11 16:18:08 DEBUG MemoryStore:61 - Block broadcast_70_piece0 of size 22003 dropped from memory (free 2332289646)
2022-01-11 16:18:08 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_70_piece0 for BlockManagerId(driver, host.docker.internal, 57009, None)
2022-01-11 16:18:08 INFO  BlockManagerInfo:57 - Removed broadcast_70_piece0 on host.docker.internal:57009 in memory (size: 21.5 KiB, free: 2.2 GiB)
2022-01-11 16:18:08 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_70_piece0
2022-01-11 16:18:08 DEBUG BlockManager:61 - Told master about block broadcast_70_piece0
2022-01-11 16:18:08 DEBUG BlockManagerStorageEndpoint:61 - Done removing broadcast 70, response is 0
2022-01-11 16:18:08 DEBUG BlockManagerStorageEndpoint:61 - Sent response: 0 to host.docker.internal:56966
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned broadcast 70
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1501)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1501
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1501
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1500)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1500
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1500
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1479)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1479
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1479
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1420)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1420
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1420
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1472)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1472
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1472
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1453)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1453
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1453
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1493)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1493
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1493
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1388)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1388
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1388
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1418)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1418
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1418
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1470)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1470
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1470
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 5-6
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1468)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1468
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1468
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1454)
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1454
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1454
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1478)
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1478
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1478
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1494)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1494
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1460: [0,0,0,0,0,0,0,0,0,0,0,92,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,92,0,0,0,0]
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1494
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1497)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1497
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1497
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1462)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1462
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1462
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1378)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1378
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1378
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1422)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1422
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1422
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1390)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1390
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1390
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 183.0 in stage 43.0 (TID 1460). 6182 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1463)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1463
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1463
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1423)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1423
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1423
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1405)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1405
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1405
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1470 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@edc5aad
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1492)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1492
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1492
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1396)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1396
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1396
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 6.0 in stage 43.0 (TID 1471) (host.docker.internal, executor driver, partition 6, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1470 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@edc5aad
2022-01-11 16:18:08 INFO  Executor:57 - Running task 6.0 in stage 43.0 (TID 1471)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1456)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1456
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1470 with length 33
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 183.0 in stage 43.0 (TID 1460) in 102 ms on host.docker.internal (executor driver) (30/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1456
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1476)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1476
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1476
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1475)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1475
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1475
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1414)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1414
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1414
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1399)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1399
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1399
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1403)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1403
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1403
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1415)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1415
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1415
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(71)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning broadcast 71
2022-01-11 16:18:08 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 71
2022-01-11 16:18:08 DEBUG BlockManagerStorageEndpoint:61 - removing broadcast 71
2022-01-11 16:18:08 DEBUG BlockManager:61 - Removing broadcast 71
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG BlockManager:61 - Removing block broadcast_71_piece0
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MemoryStore:61 - Block broadcast_71_piece0 of size 23150 dropped from memory (free 2332312796)
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 6-7
2022-01-11 16:18:08 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_71_piece0 for BlockManagerId(driver, host.docker.internal, 57009, None)
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  BlockManagerInfo:57 - Removed broadcast_71_piece0 on host.docker.internal:57009 in memory (size: 22.6 KiB, free: 2.2 GiB)
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_71_piece0
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG BlockManager:61 - Told master about block broadcast_71_piece0
2022-01-11 16:18:08 DEBUG BlockManager:61 - Removing block broadcast_71
2022-01-11 16:18:08 DEBUG MemoryStore:61 - Block broadcast_71 of size 49360 dropped from memory (free 2332362156)
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1459: [80,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG BlockManagerStorageEndpoint:61 - Done removing broadcast 71, response is 0
2022-01-11 16:18:08 DEBUG BlockManagerStorageEndpoint:61 - Sent response: 0 to host.docker.internal:56966
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned broadcast 71
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 179.0 in stage 43.0 (TID 1459). 6182 bytes result sent to driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1469)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1469
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1469
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1401)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1401
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 8.0 in stage 43.0 (TID 1472) (host.docker.internal, executor driver, partition 8, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1401
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1471 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@6193df9a
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 179.0 in stage 43.0 (TID 1459) in 118 ms on host.docker.internal (executor driver) (31/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 8.0 in stage 43.0 (TID 1472)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1498)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1498
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1498
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1457)
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1471 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@6193df9a
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1457
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1457
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1471 with length 33
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1410)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1410
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1410
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1421)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1421
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1421
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1409)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1409
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1409
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1483)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1483
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1483
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1459)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1459
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1459
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1481)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1481
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1481
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1426)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1426
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1426
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1395)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1395
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1395
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1461)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1461
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1461
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1489)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1489
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1489
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1485)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1485
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1485
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1408)
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1470: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1408
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 8-9
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1408
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 5.0 in stage 43.0 (TID 1470). 6053 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1480)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1480
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1480
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1411)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1411
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1411
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1471)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1471
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1471
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1477)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1477
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1477
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1386)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1386
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1386
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1466)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1466
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1466
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1384)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1384
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1384
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1412)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1412
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1412
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 9.0 in stage 43.0 (TID 1473) (host.docker.internal, executor driver, partition 9, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1391)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1391
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1391
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 3 ms
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1486)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1486
2022-01-11 16:18:08 INFO  Executor:57 - Running task 9.0 in stage 43.0 (TID 1473)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 5.0 in stage 43.0 (TID 1470) in 31 ms on host.docker.internal (executor driver) (32/200)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1486
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(63)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning broadcast 63
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1469: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 63
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG BlockManagerStorageEndpoint:61 - removing broadcast 63
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 4.0 in stage 43.0 (TID 1469). 5967 bytes result sent to driver
2022-01-11 16:18:08 DEBUG BlockManager:61 - Removing broadcast 63
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1472 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7344ef15
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG BlockManager:61 - Removing block broadcast_63
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG MemoryStore:61 - Block broadcast_63 of size 14592 dropped from memory (free 2332114604)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG BlockManager:61 - Removing block broadcast_63_piece0
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 10.0 in stage 43.0 (TID 1474) (host.docker.internal, executor driver, partition 10, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG MemoryStore:61 - Block broadcast_63_piece0 of size 7214 dropped from memory (free 2332121818)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 4.0 in stage 43.0 (TID 1469) in 43 ms on host.docker.internal (executor driver) (33/200)
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1472 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7344ef15
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1472 with length 33
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_63_piece0 for BlockManagerId(driver, host.docker.internal, 57009, None)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 10.0 in stage 43.0 (TID 1474)
2022-01-11 16:18:08 INFO  BlockManagerInfo:57 - Removed broadcast_63_piece0 on host.docker.internal:57009 in memory (size: 7.0 KiB, free: 2.2 GiB)
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_63_piece0
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 9-10
2022-01-11 16:18:08 DEBUG BlockManager:61 - Told master about block broadcast_63_piece0
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG BlockManagerStorageEndpoint:61 - Done removing broadcast 63, response is 0
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned broadcast 63
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG BlockManagerStorageEndpoint:61 - Sent response: 0 to host.docker.internal:56966
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1452)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1452
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1452
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1487)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1487
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1487
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1413)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1413
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1413
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(64)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning broadcast 64
2022-01-11 16:18:08 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 64
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1468: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG BlockManagerStorageEndpoint:61 - removing broadcast 64
2022-01-11 16:18:08 DEBUG BlockManager:61 - Removing broadcast 64
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 3.0 in stage 43.0 (TID 1468). 6053 bytes result sent to driver
2022-01-11 16:18:08 DEBUG BlockManager:61 - Removing block broadcast_64
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1473 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@6ad2fa7a
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 10-11
2022-01-11 16:18:08 DEBUG MemoryStore:61 - Block broadcast_64 of size 13408 dropped from memory (free 2332135226)
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG BlockManager:61 - Removing block broadcast_64_piece0
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1473 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@6ad2fa7a
2022-01-11 16:18:08 DEBUG MemoryStore:61 - Block broadcast_64_piece0 of size 6763 dropped from memory (free 2332141989)
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1473 with length 33
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_64_piece0 for BlockManagerId(driver, host.docker.internal, 57009, None)
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 INFO  BlockManagerInfo:57 - Removed broadcast_64_piece0 on host.docker.internal:57009 in memory (size: 6.6 KiB, free: 2.2 GiB)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 11.0 in stage 43.0 (TID 1475) (host.docker.internal, executor driver, partition 11, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_64_piece0
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 3.0 in stage 43.0 (TID 1468) in 63 ms on host.docker.internal (executor driver) (34/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 11.0 in stage 43.0 (TID 1475)
2022-01-11 16:18:08 DEBUG BlockManager:61 - Told master about block broadcast_64_piece0
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG BlockManagerStorageEndpoint:61 - Done removing broadcast 64, response is 0
2022-01-11 16:18:08 DEBUG BlockManagerStorageEndpoint:61 - Sent response: 0 to host.docker.internal:56966
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned broadcast 64
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1407)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1407
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1407
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1474 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2bd48c52
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1496)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1496
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1496
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1385)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1385
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1385
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1467: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1394)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1394
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1474 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2bd48c52
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1394
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1474 with length 33
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 2.0 in stage 43.0 (TID 1467). 6010 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1465)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1465
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1465
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1458)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1458
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 11-12
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 12.0 in stage 43.0 (TID 1476) (host.docker.internal, executor driver, partition 12, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1458
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 2.0 in stage 43.0 (TID 1467) in 77 ms on host.docker.internal (executor driver) (35/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 12.0 in stage 43.0 (TID 1476)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1464)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1464
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1464
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1417)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1417
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1417
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1383)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1383
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1383
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1424)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1424
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1424
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1382)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1382
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1382
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1397)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1397
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1397
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1406)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1406
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1406
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1416)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1416
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1416
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1398)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1398
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1398
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1482)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1482
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1482
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1455)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1455
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1455
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1488)
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaning accumulator 1488
2022-01-11 16:18:08 DEBUG ContextCleaner:61 - Cleaned accumulator 1488
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1475 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5085fe7c
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1466: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 1.0 in stage 43.0 (TID 1466). 6010 bytes result sent to driver
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1475 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5085fe7c
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 12-13
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1475 with length 33
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 13.0 in stage 43.0 (TID 1477) (host.docker.internal, executor driver, partition 13, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 INFO  Executor:57 - Running task 13.0 in stage 43.0 (TID 1477)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 1.0 in stage 43.0 (TID 1466) in 89 ms on host.docker.internal (executor driver) (36/200)
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1476 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3ef9fa39
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1476 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3ef9fa39
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 13-14
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1476 with length 33
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1477 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2e857118
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1477 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2e857118
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1477 with length 33
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1464: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,99,0]
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 199.0 in stage 43.0 (TID 1464). 6182 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 14.0 in stage 43.0 (TID 1478) (host.docker.internal, executor driver, partition 14, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  Executor:57 - Running task 14.0 in stage 43.0 (TID 1478)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 199.0 in stage 43.0 (TID 1464) in 116 ms on host.docker.internal (executor driver) (37/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 14-15
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1477: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 13.0 in stage 43.0 (TID 1477). 5967 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 15.0 in stage 43.0 (TID 1479) (host.docker.internal, executor driver, partition 15, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1478 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@24a3453c
2022-01-11 16:18:08 INFO  Executor:57 - Running task 15.0 in stage 43.0 (TID 1479)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 13.0 in stage 43.0 (TID 1477) in 15 ms on host.docker.internal (executor driver) (38/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1478 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@24a3453c
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1478 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 15-16
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1476: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 12.0 in stage 43.0 (TID 1476). 6010 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 16.0 in stage 43.0 (TID 1480) (host.docker.internal, executor driver, partition 16, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 12.0 in stage 43.0 (TID 1476) in 28 ms on host.docker.internal (executor driver) (39/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 16.0 in stage 43.0 (TID 1480)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1479 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5cb05b75
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1479 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5cb05b75
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1479 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 16-17
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1475: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 11.0 in stage 43.0 (TID 1475). 6010 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 18.0 in stage 43.0 (TID 1481) (host.docker.internal, executor driver, partition 18, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1480 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@6e7490ec
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 11.0 in stage 43.0 (TID 1475) in 40 ms on host.docker.internal (executor driver) (40/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 18.0 in stage 43.0 (TID 1481)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1480 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@6e7490ec
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1480 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 18-19
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1474: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 10.0 in stage 43.0 (TID 1474). 6053 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 20.0 in stage 43.0 (TID 1482) (host.docker.internal, executor driver, partition 20, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 10.0 in stage 43.0 (TID 1474) in 53 ms on host.docker.internal (executor driver) (41/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 20.0 in stage 43.0 (TID 1482)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1481 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@57115e31
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1481 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@57115e31
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1481 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1473: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 20-21
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 9.0 in stage 43.0 (TID 1473). 5967 bytes result sent to driver
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 21.0 in stage 43.0 (TID 1483) (host.docker.internal, executor driver, partition 21, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 9.0 in stage 43.0 (TID 1473) in 63 ms on host.docker.internal (executor driver) (42/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 21.0 in stage 43.0 (TID 1483)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1482 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@176dbca3
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1482 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@176dbca3
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1482 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 21-22
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1472: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 8.0 in stage 43.0 (TID 1472). 5967 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 22.0 in stage 43.0 (TID 1484) (host.docker.internal, executor driver, partition 22, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Running task 22.0 in stage 43.0 (TID 1484)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 8.0 in stage 43.0 (TID 1472) in 76 ms on host.docker.internal (executor driver) (43/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1483 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@76fe34ea
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1483 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@76fe34ea
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1483 with length 33
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1471: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 6.0 in stage 43.0 (TID 1471). 6010 bytes result sent to driver
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 22-23
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 23.0 in stage 43.0 (TID 1485) (host.docker.internal, executor driver, partition 23, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 6.0 in stage 43.0 (TID 1471) in 89 ms on host.docker.internal (executor driver) (44/200)
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  Executor:57 - Running task 23.0 in stage 43.0 (TID 1485)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1484 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@29cf20d4
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1484 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@29cf20d4
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1484 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1483: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 23-24
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 21.0 in stage 43.0 (TID 1483). 5967 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 24.0 in stage 43.0 (TID 1486) (host.docker.internal, executor driver, partition 24, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Running task 24.0 in stage 43.0 (TID 1486)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 21.0 in stage 43.0 (TID 1483) in 15 ms on host.docker.internal (executor driver) (45/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1485 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@35f4adc8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1485 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@35f4adc8
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1485 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 24-25
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1486 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@15aa06f5
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1486 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@15aa06f5
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1482: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1486 with length 33
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 20.0 in stage 43.0 (TID 1482). 5967 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 25.0 in stage 43.0 (TID 1487) (host.docker.internal, executor driver, partition 25, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 20.0 in stage 43.0 (TID 1482) in 26 ms on host.docker.internal (executor driver) (46/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 25.0 in stage 43.0 (TID 1487)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 25-26
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1481: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 18.0 in stage 43.0 (TID 1481). 6053 bytes result sent to driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 26.0 in stage 43.0 (TID 1488) (host.docker.internal, executor driver, partition 26, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1487 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@25239993
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 18.0 in stage 43.0 (TID 1481) in 37 ms on host.docker.internal (executor driver) (47/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 26.0 in stage 43.0 (TID 1488)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1487 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@25239993
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1487 with length 33
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1480: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 16.0 in stage 43.0 (TID 1480). 5967 bytes result sent to driver
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 26-27
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 27.0 in stage 43.0 (TID 1489) (host.docker.internal, executor driver, partition 27, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 16.0 in stage 43.0 (TID 1480) in 49 ms on host.docker.internal (executor driver) (48/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 27.0 in stage 43.0 (TID 1489)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1488 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2591392
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1488 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2591392
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1479: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1488 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 15.0 in stage 43.0 (TID 1479). 5967 bytes result sent to driver
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 27-28
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 28.0 in stage 43.0 (TID 1490) (host.docker.internal, executor driver, partition 28, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 INFO  Executor:57 - Running task 28.0 in stage 43.0 (TID 1490)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 15.0 in stage 43.0 (TID 1479) in 60 ms on host.docker.internal (executor driver) (49/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1489 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@479d8341
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1489 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@479d8341
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1489 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 28-29
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1478: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 14.0 in stage 43.0 (TID 1478). 6010 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 30.0 in stage 43.0 (TID 1491) (host.docker.internal, executor driver, partition 30, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  Executor:57 - Running task 30.0 in stage 43.0 (TID 1491)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 14.0 in stage 43.0 (TID 1478) in 71 ms on host.docker.internal (executor driver) (50/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1490 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@e23251
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1490 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@e23251
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1490 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 30-31
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1489: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 27.0 in stage 43.0 (TID 1489). 6010 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 32.0 in stage 43.0 (TID 1492) (host.docker.internal, executor driver, partition 32, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 27.0 in stage 43.0 (TID 1489) in 16 ms on host.docker.internal (executor driver) (51/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 32.0 in stage 43.0 (TID 1492)
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1491 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4d17d456
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1491 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4d17d456
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1491 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 32-33
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1488: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 26.0 in stage 43.0 (TID 1488). 5967 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1492 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@11f183e7
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 33.0 in stage 43.0 (TID 1493) (host.docker.internal, executor driver, partition 33, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 26.0 in stage 43.0 (TID 1488) in 28 ms on host.docker.internal (executor driver) (52/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 33.0 in stage 43.0 (TID 1493)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1492 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@11f183e7
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1492 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1487: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 33-34
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 25.0 in stage 43.0 (TID 1487). 6053 bytes result sent to driver
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 34.0 in stage 43.0 (TID 1494) (host.docker.internal, executor driver, partition 34, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  Executor:57 - Running task 34.0 in stage 43.0 (TID 1494)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 25.0 in stage 43.0 (TID 1487) in 39 ms on host.docker.internal (executor driver) (53/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1493 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@139dc40c
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1493 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@139dc40c
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1493 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 34-35
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1486: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 24.0 in stage 43.0 (TID 1486). 5967 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 36.0 in stage 43.0 (TID 1495) (host.docker.internal, executor driver, partition 36, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 24.0 in stage 43.0 (TID 1486) in 52 ms on host.docker.internal (executor driver) (54/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 36.0 in stage 43.0 (TID 1495)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1494 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3e14ed7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1494 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3e14ed7
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1494 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 36-37
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1485: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 23.0 in stage 43.0 (TID 1485). 5967 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 37.0 in stage 43.0 (TID 1496) (host.docker.internal, executor driver, partition 37, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1495 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3d1b72c1
2022-01-11 16:18:08 INFO  Executor:57 - Running task 37.0 in stage 43.0 (TID 1496)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 23.0 in stage 43.0 (TID 1485) in 61 ms on host.docker.internal (executor driver) (55/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1495 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3d1b72c1
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1495 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 37-38
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1484: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1496 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@ea98181
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 22.0 in stage 43.0 (TID 1484). 6053 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1496 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@ea98181
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1496 with length 33
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 39.0 in stage 43.0 (TID 1497) (host.docker.internal, executor driver, partition 39, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 22.0 in stage 43.0 (TID 1484) in 74 ms on host.docker.internal (executor driver) (56/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 39.0 in stage 43.0 (TID 1497)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 39-40
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1495: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1497 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@553c2e58
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 36.0 in stage 43.0 (TID 1495). 6010 bytes result sent to driver
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1497 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@553c2e58
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1497 with length 33
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 40.0 in stage 43.0 (TID 1498) (host.docker.internal, executor driver, partition 40, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  Executor:57 - Running task 40.0 in stage 43.0 (TID 1498)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 36.0 in stage 43.0 (TID 1495) in 22 ms on host.docker.internal (executor driver) (57/200)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1494: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 34.0 in stage 43.0 (TID 1494). 6010 bytes result sent to driver
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 40-41
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 41.0 in stage 43.0 (TID 1499) (host.docker.internal, executor driver, partition 41, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 34.0 in stage 43.0 (TID 1494) in 31 ms on host.docker.internal (executor driver) (58/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 41.0 in stage 43.0 (TID 1499)
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1498 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@6bac6f87
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1498 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@6bac6f87
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1493: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 41-42
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1498 with length 33
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 33.0 in stage 43.0 (TID 1493). 5967 bytes result sent to driver
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 44.0 in stage 43.0 (TID 1500) (host.docker.internal, executor driver, partition 44, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  Executor:57 - Running task 44.0 in stage 43.0 (TID 1500)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 33.0 in stage 43.0 (TID 1493) in 41 ms on host.docker.internal (executor driver) (59/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1499 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@340a32ad
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1499 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@340a32ad
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1499 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 44-45
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1492: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 32.0 in stage 43.0 (TID 1492). 5967 bytes result sent to driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 45.0 in stage 43.0 (TID 1501) (host.docker.internal, executor driver, partition 45, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 32.0 in stage 43.0 (TID 1492) in 53 ms on host.docker.internal (executor driver) (60/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 45.0 in stage 43.0 (TID 1501)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1500 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@c58fbfe
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1500 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@c58fbfe
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1500 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1491: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 45-46
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 30.0 in stage 43.0 (TID 1491). 6010 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 46.0 in stage 43.0 (TID 1502) (host.docker.internal, executor driver, partition 46, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Running task 46.0 in stage 43.0 (TID 1502)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 30.0 in stage 43.0 (TID 1491) in 63 ms on host.docker.internal (executor driver) (61/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1501 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4bb9e920
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1501 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4bb9e920
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1501 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 46-47
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1490: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 28.0 in stage 43.0 (TID 1490). 6010 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 47.0 in stage 43.0 (TID 1503) (host.docker.internal, executor driver, partition 47, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 28.0 in stage 43.0 (TID 1490) in 74 ms on host.docker.internal (executor driver) (62/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 47.0 in stage 43.0 (TID 1503)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1502 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5e6dae59
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1502 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5e6dae59
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1502 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 47-48
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1503 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@dabd94c
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1501: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1503 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@dabd94c
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 45.0 in stage 43.0 (TID 1501). 5967 bytes result sent to driver
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1503 with length 33
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 49.0 in stage 43.0 (TID 1504) (host.docker.internal, executor driver, partition 49, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 45.0 in stage 43.0 (TID 1501) in 17 ms on host.docker.internal (executor driver) (63/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 49.0 in stage 43.0 (TID 1504)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1500: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 49-50
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 44.0 in stage 43.0 (TID 1500). 6010 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 50.0 in stage 43.0 (TID 1505) (host.docker.internal, executor driver, partition 50, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  Executor:57 - Running task 50.0 in stage 43.0 (TID 1505)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 44.0 in stage 43.0 (TID 1500) in 26 ms on host.docker.internal (executor driver) (64/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1504 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1e9d377e
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1504 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1e9d377e
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1504 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 50-51
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1499: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 41.0 in stage 43.0 (TID 1499). 5967 bytes result sent to driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 51.0 in stage 43.0 (TID 1506) (host.docker.internal, executor driver, partition 51, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  Executor:57 - Running task 51.0 in stage 43.0 (TID 1506)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 41.0 in stage 43.0 (TID 1499) in 37 ms on host.docker.internal (executor driver) (65/200)
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1505 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3d64da22
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1505 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3d64da22
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1505 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1498: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 51-52
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 40.0 in stage 43.0 (TID 1498). 5967 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 53.0 in stage 43.0 (TID 1507) (host.docker.internal, executor driver, partition 53, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Running task 53.0 in stage 43.0 (TID 1507)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 40.0 in stage 43.0 (TID 1498) in 45 ms on host.docker.internal (executor driver) (66/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1506 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@8aa48c3
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1506 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@8aa48c3
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1506 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 53-54
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1497: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 39.0 in stage 43.0 (TID 1497). 6010 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 54.0 in stage 43.0 (TID 1508) (host.docker.internal, executor driver, partition 54, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 39.0 in stage 43.0 (TID 1497) in 56 ms on host.docker.internal (executor driver) (67/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 54.0 in stage 43.0 (TID 1508)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1507 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@58989d13
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1507 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@58989d13
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1507 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1496: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 54-55
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 37.0 in stage 43.0 (TID 1496). 5967 bytes result sent to driver
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 55.0 in stage 43.0 (TID 1509) (host.docker.internal, executor driver, partition 55, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 37.0 in stage 43.0 (TID 1496) in 71 ms on host.docker.internal (executor driver) (68/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 55.0 in stage 43.0 (TID 1509)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1508 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7e08f4c5
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1508 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7e08f4c5
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1508 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 55-56
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1507: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1509 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@72f1f7bb
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 53.0 in stage 43.0 (TID 1507). 6010 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1509 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@72f1f7bb
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1509 with length 33
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 56.0 in stage 43.0 (TID 1510) (host.docker.internal, executor driver, partition 56, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 53.0 in stage 43.0 (TID 1507) in 16 ms on host.docker.internal (executor driver) (69/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 56.0 in stage 43.0 (TID 1510)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1506: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 51.0 in stage 43.0 (TID 1506). 6010 bytes result sent to driver
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 56-57
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 57.0 in stage 43.0 (TID 1511) (host.docker.internal, executor driver, partition 57, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 INFO  Executor:57 - Running task 57.0 in stage 43.0 (TID 1511)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 51.0 in stage 43.0 (TID 1506) in 27 ms on host.docker.internal (executor driver) (70/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1510 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3ffebc20
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1510 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3ffebc20
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 57-58
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1510 with length 33
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1505: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 50.0 in stage 43.0 (TID 1505). 5967 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 58.0 in stage 43.0 (TID 1512) (host.docker.internal, executor driver, partition 58, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 50.0 in stage 43.0 (TID 1505) in 36 ms on host.docker.internal (executor driver) (71/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 58.0 in stage 43.0 (TID 1512)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1511 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5c1978a7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1511 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5c1978a7
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1511 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 58-59
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1504: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 49.0 in stage 43.0 (TID 1504). 5967 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1512 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@d54e104
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 59.0 in stage 43.0 (TID 1513) (host.docker.internal, executor driver, partition 59, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 49.0 in stage 43.0 (TID 1504) in 48 ms on host.docker.internal (executor driver) (72/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Running task 59.0 in stage 43.0 (TID 1513)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1512 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@d54e104
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1512 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1503: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 59-60
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 47.0 in stage 43.0 (TID 1503). 6010 bytes result sent to driver
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 60.0 in stage 43.0 (TID 1514) (host.docker.internal, executor driver, partition 60, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 47.0 in stage 43.0 (TID 1503) in 58 ms on host.docker.internal (executor driver) (73/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 60.0 in stage 43.0 (TID 1514)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1513 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4844d63c
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1513 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4844d63c
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1513 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 60-61
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1502: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 46.0 in stage 43.0 (TID 1502). 5967 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1514 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2457ad6b
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 61.0 in stage 43.0 (TID 1515) (host.docker.internal, executor driver, partition 61, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 46.0 in stage 43.0 (TID 1502) in 68 ms on host.docker.internal (executor driver) (74/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 61.0 in stage 43.0 (TID 1515)
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1514 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2457ad6b
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1514 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 61-62
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1513: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 59.0 in stage 43.0 (TID 1513). 5967 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 62.0 in stage 43.0 (TID 1516) (host.docker.internal, executor driver, partition 62, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 59.0 in stage 43.0 (TID 1513) in 15 ms on host.docker.internal (executor driver) (75/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 62.0 in stage 43.0 (TID 1516)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1515 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3ca9dcee
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1515 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3ca9dcee
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1515 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1512: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 62-63
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 58.0 in stage 43.0 (TID 1512). 6010 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 64.0 in stage 43.0 (TID 1517) (host.docker.internal, executor driver, partition 64, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 58.0 in stage 43.0 (TID 1512) in 26 ms on host.docker.internal (executor driver) (76/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 64.0 in stage 43.0 (TID 1517)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1516 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@35b82515
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1516 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@35b82515
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1516 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 64-65
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1511: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 57.0 in stage 43.0 (TID 1511). 5967 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 65.0 in stage 43.0 (TID 1518) (host.docker.internal, executor driver, partition 65, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Running task 65.0 in stage 43.0 (TID 1518)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 57.0 in stage 43.0 (TID 1511) in 36 ms on host.docker.internal (executor driver) (77/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1517 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3954a0c0
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1517 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3954a0c0
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1517 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 65-66
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1518 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@41c468f0
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1510: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1518 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@41c468f0
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1518 with length 33
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 56.0 in stage 43.0 (TID 1510). 6010 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 66.0 in stage 43.0 (TID 1519) (host.docker.internal, executor driver, partition 66, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  Executor:57 - Running task 66.0 in stage 43.0 (TID 1519)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 56.0 in stage 43.0 (TID 1510) in 47 ms on host.docker.internal (executor driver) (78/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 66-67
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1509: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 55.0 in stage 43.0 (TID 1509). 6010 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 67.0 in stage 43.0 (TID 1520) (host.docker.internal, executor driver, partition 67, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 55.0 in stage 43.0 (TID 1509) in 60 ms on host.docker.internal (executor driver) (79/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 67.0 in stage 43.0 (TID 1520)
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1519 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@61cd133c
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1519 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@61cd133c
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1519 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 67-68
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1508: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 54.0 in stage 43.0 (TID 1508). 5967 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 68.0 in stage 43.0 (TID 1521) (host.docker.internal, executor driver, partition 68, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 54.0 in stage 43.0 (TID 1508) in 71 ms on host.docker.internal (executor driver) (80/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 68.0 in stage 43.0 (TID 1521)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1520 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@27583e31
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1520 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@27583e31
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1520 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 68-69
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1519: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 66.0 in stage 43.0 (TID 1519). 6053 bytes result sent to driver
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1521 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@63a1905e
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 69.0 in stage 43.0 (TID 1522) (host.docker.internal, executor driver, partition 69, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1521 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@63a1905e
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 66.0 in stage 43.0 (TID 1519) in 19 ms on host.docker.internal (executor driver) (81/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 69.0 in stage 43.0 (TID 1522)
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1521 with length 33
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1518: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 65.0 in stage 43.0 (TID 1518). 5967 bytes result sent to driver
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 69-70
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 70.0 in stage 43.0 (TID 1523) (host.docker.internal, executor driver, partition 70, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  Executor:57 - Running task 70.0 in stage 43.0 (TID 1523)
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 65.0 in stage 43.0 (TID 1518) in 30 ms on host.docker.internal (executor driver) (82/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1522 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5050d57b
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1517: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 70-71
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1522 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5050d57b
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 64.0 in stage 43.0 (TID 1517). 5967 bytes result sent to driver
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1522 with length 33
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 71.0 in stage 43.0 (TID 1524) (host.docker.internal, executor driver, partition 71, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 64.0 in stage 43.0 (TID 1517) in 40 ms on host.docker.internal (executor driver) (83/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 71.0 in stage 43.0 (TID 1524)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1523 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@47b21913
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1523 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@47b21913
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1523 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 71-72
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1516: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 62.0 in stage 43.0 (TID 1516). 6053 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 72.0 in stage 43.0 (TID 1525) (host.docker.internal, executor driver, partition 72, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 62.0 in stage 43.0 (TID 1516) in 51 ms on host.docker.internal (executor driver) (84/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 72.0 in stage 43.0 (TID 1525)
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1524 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2b52d5ff
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1524 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2b52d5ff
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1524 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1515: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 72-73
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 61.0 in stage 43.0 (TID 1515). 6010 bytes result sent to driver
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 75.0 in stage 43.0 (TID 1526) (host.docker.internal, executor driver, partition 75, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 61.0 in stage 43.0 (TID 1515) in 61 ms on host.docker.internal (executor driver) (85/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 INFO  Executor:57 - Running task 75.0 in stage 43.0 (TID 1526)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1525 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7f6e7c42
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1525 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7f6e7c42
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1525 with length 33
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1514: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 60.0 in stage 43.0 (TID 1514). 5967 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 75-76
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 76.0 in stage 43.0 (TID 1527) (host.docker.internal, executor driver, partition 76, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 INFO  Executor:57 - Running task 76.0 in stage 43.0 (TID 1527)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 60.0 in stage 43.0 (TID 1514) in 71 ms on host.docker.internal (executor driver) (86/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1526 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@736c7262
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1526 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@736c7262
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1525: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1526 with length 33
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 76-77
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 72.0 in stage 43.0 (TID 1525). 6010 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 77.0 in stage 43.0 (TID 1528) (host.docker.internal, executor driver, partition 77, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  Executor:57 - Running task 77.0 in stage 43.0 (TID 1528)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 72.0 in stage 43.0 (TID 1525) in 15 ms on host.docker.internal (executor driver) (87/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1527 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5f14b0b3
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1527 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5f14b0b3
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1527 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1524: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 77-78
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 71.0 in stage 43.0 (TID 1524). 6010 bytes result sent to driver
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 78.0 in stage 43.0 (TID 1529) (host.docker.internal, executor driver, partition 78, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 71.0 in stage 43.0 (TID 1524) in 27 ms on host.docker.internal (executor driver) (88/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 78.0 in stage 43.0 (TID 1529)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1528 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@317c8468
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1528 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@317c8468
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1528 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 78-79
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1523: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 70.0 in stage 43.0 (TID 1523). 5967 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 79.0 in stage 43.0 (TID 1530) (host.docker.internal, executor driver, partition 79, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  Executor:57 - Running task 79.0 in stage 43.0 (TID 1530)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 70.0 in stage 43.0 (TID 1523) in 39 ms on host.docker.internal (executor driver) (89/200)
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1529 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@c50a830
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1529 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@c50a830
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1529 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 79-80
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1522: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1530 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5777a648
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 69.0 in stage 43.0 (TID 1522). 6010 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1530 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5777a648
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 80.0 in stage 43.0 (TID 1531) (host.docker.internal, executor driver, partition 80, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1530 with length 33
2022-01-11 16:18:08 INFO  Executor:57 - Running task 80.0 in stage 43.0 (TID 1531)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 69.0 in stage 43.0 (TID 1522) in 51 ms on host.docker.internal (executor driver) (90/200)
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 80-81
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1521: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 68.0 in stage 43.0 (TID 1521). 6010 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 81.0 in stage 43.0 (TID 1532) (host.docker.internal, executor driver, partition 81, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Running task 81.0 in stage 43.0 (TID 1532)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 68.0 in stage 43.0 (TID 1521) in 64 ms on host.docker.internal (executor driver) (91/200)
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1531 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@650c4b6d
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1531 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@650c4b6d
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1531 with length 33
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 81-82
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1532 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@37424764
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1532 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@37424764
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1532 with length 33
2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1520: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 INFO  Executor:57 - Finished task 67.0 in stage 43.0 (TID 1520). 6010 bytes result sent to driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 82.0 in stage 43.0 (TID 1533) (host.docker.internal, executor driver, partition 82, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 67.0 in stage 43.0 (TID 1520) in 77 ms on host.docker.internal (executor driver) (92/200)
2022-01-11 16:18:08 INFO  Executor:57 - Running task 82.0 in stage 43.0 (TID 1533)
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:08 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 82-83
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:08 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:08 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:08 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1531: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:08 INFO  Executor:57 - Finished task 80.0 in stage 43.0 (TID 1531). 5967 bytes result sent to driver
2022-01-11 16:18:08 DEBUG TaskMemoryManager:228 - Task 1533 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@75a202a1
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:08 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:08 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:08 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:08 INFO  TaskSetManager:57 - Starting task 83.0 in stage 43.0 (TID 1534) (host.docker.internal, executor driver, partition 83, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:08 DEBUG TaskMemoryManager:237 - Task 1533 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@75a202a1
2022-01-11 16:18:08 INFO  Executor:57 - Running task 83.0 in stage 43.0 (TID 1534)
2022-01-11 16:18:08 INFO  TaskSetManager:57 - Finished task 80.0 in stage 43.0 (TID 1531) in 22 ms on host.docker.internal (executor driver) (93/200)
2022-01-11 16:18:08 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1533 with length 33
2022-01-11 16:18:08 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:08 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 83-84
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1530: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 79.0 in stage 43.0 (TID 1530). 6053 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 84.0 in stage 43.0 (TID 1535) (host.docker.internal, executor driver, partition 84, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Running task 84.0 in stage 43.0 (TID 1535)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 79.0 in stage 43.0 (TID 1530) in 34 ms on host.docker.internal (executor driver) (94/200)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1534 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@bb264f0
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1534 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@bb264f0
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1534 with length 33
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1529: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 78.0 in stage 43.0 (TID 1529). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 84-85
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 85.0 in stage 43.0 (TID 1536) (host.docker.internal, executor driver, partition 85, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 78.0 in stage 43.0 (TID 1529) in 47 ms on host.docker.internal (executor driver) (95/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 85.0 in stage 43.0 (TID 1536)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1535 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@41f9cc10
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1535 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@41f9cc10
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1535 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 85-86
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1536 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@e3973e6
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1528: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1536 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@e3973e6
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1536 with length 33
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 77.0 in stage 43.0 (TID 1528). 5967 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 87.0 in stage 43.0 (TID 1537) (host.docker.internal, executor driver, partition 87, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 77.0 in stage 43.0 (TID 1528) in 59 ms on host.docker.internal (executor driver) (96/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 87.0 in stage 43.0 (TID 1537)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 87-88
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1537 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2ccf259c
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1527: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1537 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2ccf259c
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1537 with length 33
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 76.0 in stage 43.0 (TID 1527). 6053 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 88.0 in stage 43.0 (TID 1538) (host.docker.internal, executor driver, partition 88, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  Executor:57 - Running task 88.0 in stage 43.0 (TID 1538)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 76.0 in stage 43.0 (TID 1527) in 72 ms on host.docker.internal (executor driver) (97/200)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1526: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 88-89
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 75.0 in stage 43.0 (TID 1526). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 91.0 in stage 43.0 (TID 1539) (host.docker.internal, executor driver, partition 91, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 75.0 in stage 43.0 (TID 1526) in 83 ms on host.docker.internal (executor driver) (98/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 91.0 in stage 43.0 (TID 1539)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1538 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@44bf651d
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1538 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@44bf651d
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1538 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 91-92
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1537: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1539 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@649a03f5
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 87.0 in stage 43.0 (TID 1537). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1539 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@649a03f5
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1539 with length 33
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 92.0 in stage 43.0 (TID 1540) (host.docker.internal, executor driver, partition 92, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 87.0 in stage 43.0 (TID 1537) in 21 ms on host.docker.internal (executor driver) (99/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 92.0 in stage 43.0 (TID 1540)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1536: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 92-93
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 85.0 in stage 43.0 (TID 1536). 5967 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 93.0 in stage 43.0 (TID 1541) (host.docker.internal, executor driver, partition 93, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 85.0 in stage 43.0 (TID 1536) in 35 ms on host.docker.internal (executor driver) (100/200)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Running task 93.0 in stage 43.0 (TID 1541)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1540 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1e5ef81
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1540 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1e5ef81
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1540 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1535: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 93-94
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 84.0 in stage 43.0 (TID 1535). 5967 bytes result sent to driver
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 94.0 in stage 43.0 (TID 1542) (host.docker.internal, executor driver, partition 94, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 84.0 in stage 43.0 (TID 1535) in 46 ms on host.docker.internal (executor driver) (101/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 94.0 in stage 43.0 (TID 1542)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1541 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@54e08e
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1541 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@54e08e
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1541 with length 33
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1534: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 83.0 in stage 43.0 (TID 1534). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 94-95
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 95.0 in stage 43.0 (TID 1543) (host.docker.internal, executor driver, partition 95, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  Executor:57 - Running task 95.0 in stage 43.0 (TID 1543)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 83.0 in stage 43.0 (TID 1534) in 57 ms on host.docker.internal (executor driver) (102/200)
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1542 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@78621d75
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 95-96
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1533: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1542 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@78621d75
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 82.0 in stage 43.0 (TID 1533). 5967 bytes result sent to driver
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1542 with length 33
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 96.0 in stage 43.0 (TID 1544) (host.docker.internal, executor driver, partition 96, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Running task 96.0 in stage 43.0 (TID 1544)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 82.0 in stage 43.0 (TID 1533) in 70 ms on host.docker.internal (executor driver) (103/200)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1543 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@54c7897d
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1543 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@54c7897d
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1543 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1532: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 96-97
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 81.0 in stage 43.0 (TID 1532). 5967 bytes result sent to driver
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 97.0 in stage 43.0 (TID 1545) (host.docker.internal, executor driver, partition 97, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 81.0 in stage 43.0 (TID 1532) in 81 ms on host.docker.internal (executor driver) (104/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 97.0 in stage 43.0 (TID 1545)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1544 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@69cbbfab
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1544 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@69cbbfab
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1544 with length 33
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1543: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 95.0 in stage 43.0 (TID 1543). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 98.0 in stage 43.0 (TID 1546) (host.docker.internal, executor driver, partition 98, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 INFO  Executor:57 - Running task 98.0 in stage 43.0 (TID 1546)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 95.0 in stage 43.0 (TID 1543) in 16 ms on host.docker.internal (executor driver) (105/200)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 97-98
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 98-99
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1542: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1545 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4f4b8c9d
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 94.0 in stage 43.0 (TID 1542). 5967 bytes result sent to driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1545 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4f4b8c9d
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1545 with length 33
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 99.0 in stage 43.0 (TID 1547) (host.docker.internal, executor driver, partition 99, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 94.0 in stage 43.0 (TID 1542) in 25 ms on host.docker.internal (executor driver) (106/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 99.0 in stage 43.0 (TID 1547)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1546 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7249191b
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1546 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7249191b
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1546 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1541: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 99-100
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 93.0 in stage 43.0 (TID 1541). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 100.0 in stage 43.0 (TID 1548) (host.docker.internal, executor driver, partition 100, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  Executor:57 - Running task 100.0 in stage 43.0 (TID 1548)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 93.0 in stage 43.0 (TID 1541) in 36 ms on host.docker.internal (executor driver) (107/200)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1547 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7c153aa6
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1547 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7c153aa6
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1547 with length 33
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1540: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 100-101
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 92.0 in stage 43.0 (TID 1540). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 101.0 in stage 43.0 (TID 1549) (host.docker.internal, executor driver, partition 101, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  Executor:57 - Running task 101.0 in stage 43.0 (TID 1549)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 92.0 in stage 43.0 (TID 1540) in 48 ms on host.docker.internal (executor driver) (108/200)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1548 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@36f6b2a8
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1548 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@36f6b2a8
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1548 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 101-102
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1539: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 91.0 in stage 43.0 (TID 1539). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 102.0 in stage 43.0 (TID 1550) (host.docker.internal, executor driver, partition 102, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 91.0 in stage 43.0 (TID 1539) in 61 ms on host.docker.internal (executor driver) (109/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 102.0 in stage 43.0 (TID 1550)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1549 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@d8cd49c
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1549 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@d8cd49c
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1549 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 102-103
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1538: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 88.0 in stage 43.0 (TID 1538). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1550 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1b8f081e
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 103.0 in stage 43.0 (TID 1551) (host.docker.internal, executor driver, partition 103, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  Executor:57 - Running task 103.0 in stage 43.0 (TID 1551)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 88.0 in stage 43.0 (TID 1538) in 74 ms on host.docker.internal (executor driver) (110/200)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1550 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1b8f081e
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1550 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1549: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 103-104
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 101.0 in stage 43.0 (TID 1549). 5967 bytes result sent to driver
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 104.0 in stage 43.0 (TID 1552) (host.docker.internal, executor driver, partition 104, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 101.0 in stage 43.0 (TID 1549) in 17 ms on host.docker.internal (executor driver) (111/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 104.0 in stage 43.0 (TID 1552)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1551 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@56723627
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1551 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@56723627
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1551 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 104-105
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1548: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 100.0 in stage 43.0 (TID 1548). 5967 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 105.0 in stage 43.0 (TID 1553) (host.docker.internal, executor driver, partition 105, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  Executor:57 - Running task 105.0 in stage 43.0 (TID 1553)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 100.0 in stage 43.0 (TID 1548) in 30 ms on host.docker.internal (executor driver) (112/200)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1552 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@427d2518
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1552 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@427d2518
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1552 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 105-106
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1547: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 99.0 in stage 43.0 (TID 1547). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 106.0 in stage 43.0 (TID 1554) (host.docker.internal, executor driver, partition 106, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Running task 106.0 in stage 43.0 (TID 1554)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 99.0 in stage 43.0 (TID 1547) in 40 ms on host.docker.internal (executor driver) (113/200)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1553 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@641ee642
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1553 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@641ee642
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1553 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 106-107
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1546: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 98.0 in stage 43.0 (TID 1546). 5967 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 107.0 in stage 43.0 (TID 1555) (host.docker.internal, executor driver, partition 107, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  Executor:57 - Running task 107.0 in stage 43.0 (TID 1555)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 98.0 in stage 43.0 (TID 1546) in 52 ms on host.docker.internal (executor driver) (114/200)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1554 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@72f5dc6e
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1554 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@72f5dc6e
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1554 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 107-108
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1545: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 97.0 in stage 43.0 (TID 1545). 5967 bytes result sent to driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 109.0 in stage 43.0 (TID 1556) (host.docker.internal, executor driver, partition 109, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Running task 109.0 in stage 43.0 (TID 1556)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 97.0 in stage 43.0 (TID 1545) in 61 ms on host.docker.internal (executor driver) (115/200)
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1555 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2514710
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1555 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2514710
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1555 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1544: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 109-110
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 96.0 in stage 43.0 (TID 1544). 6010 bytes result sent to driver
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 110.0 in stage 43.0 (TID 1557) (host.docker.internal, executor driver, partition 110, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  Executor:57 - Running task 110.0 in stage 43.0 (TID 1557)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 96.0 in stage 43.0 (TID 1544) in 69 ms on host.docker.internal (executor driver) (116/200)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1556 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@52a49f48
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1556 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@52a49f48
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1556 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 110-111
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1555: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 107.0 in stage 43.0 (TID 1555). 5967 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 111.0 in stage 43.0 (TID 1558) (host.docker.internal, executor driver, partition 111, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 107.0 in stage 43.0 (TID 1555) in 14 ms on host.docker.internal (executor driver) (117/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 111.0 in stage 43.0 (TID 1558)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1557 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@25972a59
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1557 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@25972a59
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1557 with length 33
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1554: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 106.0 in stage 43.0 (TID 1554). 5967 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 111-112
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 112.0 in stage 43.0 (TID 1559) (host.docker.internal, executor driver, partition 112, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  Executor:57 - Running task 112.0 in stage 43.0 (TID 1559)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 106.0 in stage 43.0 (TID 1554) in 26 ms on host.docker.internal (executor driver) (118/200)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1558 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1486e898
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1553: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1558 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1486e898
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1558 with length 33
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 105.0 in stage 43.0 (TID 1553). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 112-113
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 113.0 in stage 43.0 (TID 1560) (host.docker.internal, executor driver, partition 113, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 105.0 in stage 43.0 (TID 1553) in 35 ms on host.docker.internal (executor driver) (119/200)
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  Executor:57 - Running task 113.0 in stage 43.0 (TID 1560)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1559 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@14f4d5c2
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 113-114
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1559 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@14f4d5c2
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1559 with length 33
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1552: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 104.0 in stage 43.0 (TID 1552). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1560 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@22dd5674
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 114.0 in stage 43.0 (TID 1561) (host.docker.internal, executor driver, partition 114, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 104.0 in stage 43.0 (TID 1552) in 47 ms on host.docker.internal (executor driver) (120/200)
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1560 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@22dd5674
2022-01-11 16:18:09 INFO  Executor:57 - Running task 114.0 in stage 43.0 (TID 1561)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1560 with length 33
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1551: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 114-115
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 103.0 in stage 43.0 (TID 1551). 5967 bytes result sent to driver
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 116.0 in stage 43.0 (TID 1562) (host.docker.internal, executor driver, partition 116, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 103.0 in stage 43.0 (TID 1551) in 57 ms on host.docker.internal (executor driver) (121/200)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 INFO  Executor:57 - Running task 116.0 in stage 43.0 (TID 1562)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1561 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@56fa7258
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1561 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@56fa7258
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1561 with length 33
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1550: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 102.0 in stage 43.0 (TID 1550). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 116-117
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 117.0 in stage 43.0 (TID 1563) (host.docker.internal, executor driver, partition 117, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 102.0 in stage 43.0 (TID 1550) in 67 ms on host.docker.internal (executor driver) (122/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 117.0 in stage 43.0 (TID 1563)
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1562 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2606e0b0
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1562 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2606e0b0
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1562 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 117-118
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1561: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 114.0 in stage 43.0 (TID 1561). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1563 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@70f30397
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 118.0 in stage 43.0 (TID 1564) (host.docker.internal, executor driver, partition 118, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  Executor:57 - Running task 118.0 in stage 43.0 (TID 1564)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 114.0 in stage 43.0 (TID 1561) in 16 ms on host.docker.internal (executor driver) (123/200)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1563 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@70f30397
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1563 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 118-119
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1560: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 113.0 in stage 43.0 (TID 1560). 5967 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 119.0 in stage 43.0 (TID 1565) (host.docker.internal, executor driver, partition 119, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 113.0 in stage 43.0 (TID 1560) in 28 ms on host.docker.internal (executor driver) (124/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 119.0 in stage 43.0 (TID 1565)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1564 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@48ef2dae
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1564 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@48ef2dae
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1564 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 119-120
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1565 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@77c7ac4b
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1559: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1565 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@77c7ac4b
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1565 with length 33
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 112.0 in stage 43.0 (TID 1559). 6053 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 120.0 in stage 43.0 (TID 1566) (host.docker.internal, executor driver, partition 120, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 112.0 in stage 43.0 (TID 1559) in 40 ms on host.docker.internal (executor driver) (125/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 120.0 in stage 43.0 (TID 1566)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 120-121
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1558: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 111.0 in stage 43.0 (TID 1558). 5967 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 121.0 in stage 43.0 (TID 1567) (host.docker.internal, executor driver, partition 121, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 111.0 in stage 43.0 (TID 1558) in 52 ms on host.docker.internal (executor driver) (126/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 121.0 in stage 43.0 (TID 1567)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1566 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3fc8e704
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1566 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3fc8e704
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1566 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1557: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 121-122
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 110.0 in stage 43.0 (TID 1557). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 122.0 in stage 43.0 (TID 1568) (host.docker.internal, executor driver, partition 122, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  Executor:57 - Running task 122.0 in stage 43.0 (TID 1568)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 110.0 in stage 43.0 (TID 1557) in 63 ms on host.docker.internal (executor driver) (127/200)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1567 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4f74fc82
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1567 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4f74fc82
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1567 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 122-123
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1556: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1568 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2a1b6975
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 109.0 in stage 43.0 (TID 1556). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1568 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2a1b6975
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1568 with length 33
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 123.0 in stage 43.0 (TID 1569) (host.docker.internal, executor driver, partition 123, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 109.0 in stage 43.0 (TID 1556) in 77 ms on host.docker.internal (executor driver) (128/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 123.0 in stage 43.0 (TID 1569)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1567: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 123-124
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 121.0 in stage 43.0 (TID 1567). 6010 bytes result sent to driver
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 124.0 in stage 43.0 (TID 1570) (host.docker.internal, executor driver, partition 124, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Running task 124.0 in stage 43.0 (TID 1570)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 121.0 in stage 43.0 (TID 1567) in 21 ms on host.docker.internal (executor driver) (129/200)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1569 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@4bee0a46
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1569 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@4bee0a46
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1569 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1566: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 124-125
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 120.0 in stage 43.0 (TID 1566). 6010 bytes result sent to driver
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 125.0 in stage 43.0 (TID 1571) (host.docker.internal, executor driver, partition 125, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 120.0 in stage 43.0 (TID 1566) in 35 ms on host.docker.internal (executor driver) (130/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 125.0 in stage 43.0 (TID 1571)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1570 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3ab440c5
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1570 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3ab440c5
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1570 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1565: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 125-126
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 119.0 in stage 43.0 (TID 1565). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 126.0 in stage 43.0 (TID 1572) (host.docker.internal, executor driver, partition 126, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 119.0 in stage 43.0 (TID 1565) in 50 ms on host.docker.internal (executor driver) (131/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 126.0 in stage 43.0 (TID 1572)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1571 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3e47a1c
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1571 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3e47a1c
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1571 with length 33
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1564: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 118.0 in stage 43.0 (TID 1564). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 127.0 in stage 43.0 (TID 1573) (host.docker.internal, executor driver, partition 127, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 126-127
2022-01-11 16:18:09 INFO  Executor:57 - Running task 127.0 in stage 43.0 (TID 1573)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 118.0 in stage 43.0 (TID 1564) in 60 ms on host.docker.internal (executor driver) (132/200)
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1572 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@38bb0556
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 127-128
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1563: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1572 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@38bb0556
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1572 with length 33
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 117.0 in stage 43.0 (TID 1563). 5967 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 128.0 in stage 43.0 (TID 1574) (host.docker.internal, executor driver, partition 128, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 117.0 in stage 43.0 (TID 1563) in 75 ms on host.docker.internal (executor driver) (133/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 128.0 in stage 43.0 (TID 1574)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1573 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@362cb694
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1573 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@362cb694
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1573 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 128-129
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1562: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 116.0 in stage 43.0 (TID 1562). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 129.0 in stage 43.0 (TID 1575) (host.docker.internal, executor driver, partition 129, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Running task 129.0 in stage 43.0 (TID 1575)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 116.0 in stage 43.0 (TID 1562) in 86 ms on host.docker.internal (executor driver) (134/200)
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1574 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2cf8896f
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1574 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2cf8896f
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1574 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 129-130
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1573: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 127.0 in stage 43.0 (TID 1573). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1575 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@447cfb5f
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1575 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@447cfb5f
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 130.0 in stage 43.0 (TID 1576) (host.docker.internal, executor driver, partition 130, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1575 with length 33
2022-01-11 16:18:09 INFO  Executor:57 - Running task 130.0 in stage 43.0 (TID 1576)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 127.0 in stage 43.0 (TID 1573) in 24 ms on host.docker.internal (executor driver) (135/200)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 130-131
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1572: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1576 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2df67f93
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 126.0 in stage 43.0 (TID 1572). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1576 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2df67f93
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1576 with length 33
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 131.0 in stage 43.0 (TID 1577) (host.docker.internal, executor driver, partition 131, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  Executor:57 - Running task 131.0 in stage 43.0 (TID 1577)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 126.0 in stage 43.0 (TID 1572) in 38 ms on host.docker.internal (executor driver) (136/200)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 131-132
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1571: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 125.0 in stage 43.0 (TID 1571). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 133.0 in stage 43.0 (TID 1578) (host.docker.internal, executor driver, partition 133, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1577 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@473431f7
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 125.0 in stage 43.0 (TID 1571) in 52 ms on host.docker.internal (executor driver) (137/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 133.0 in stage 43.0 (TID 1578)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1577 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@473431f7
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1577 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1570: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 133-134
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 124.0 in stage 43.0 (TID 1570). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 134.0 in stage 43.0 (TID 1579) (host.docker.internal, executor driver, partition 134, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Running task 134.0 in stage 43.0 (TID 1579)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 124.0 in stage 43.0 (TID 1570) in 64 ms on host.docker.internal (executor driver) (138/200)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1578 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2c928593
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1578 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2c928593
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1578 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 134-135
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1569: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1579 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@56863f4a
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 123.0 in stage 43.0 (TID 1569). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1579 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@56863f4a
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1579 with length 33
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 135.0 in stage 43.0 (TID 1580) (host.docker.internal, executor driver, partition 135, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  Executor:57 - Running task 135.0 in stage 43.0 (TID 1580)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 123.0 in stage 43.0 (TID 1569) in 77 ms on host.docker.internal (executor driver) (139/200)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 135-136
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1568: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 122.0 in stage 43.0 (TID 1568). 5967 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 136.0 in stage 43.0 (TID 1581) (host.docker.internal, executor driver, partition 136, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  Executor:57 - Running task 136.0 in stage 43.0 (TID 1581)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 122.0 in stage 43.0 (TID 1568) in 92 ms on host.docker.internal (executor driver) (140/200)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1580 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@71ef4795
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1580 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@71ef4795
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1580 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1579: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 136-137
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 134.0 in stage 43.0 (TID 1579). 6010 bytes result sent to driver
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 137.0 in stage 43.0 (TID 1582) (host.docker.internal, executor driver, partition 137, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 134.0 in stage 43.0 (TID 1579) in 20 ms on host.docker.internal (executor driver) (141/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 137.0 in stage 43.0 (TID 1582)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1581 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@291ae339
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1581 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@291ae339
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1581 with length 33
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 137-138
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1578: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 133.0 in stage 43.0 (TID 1578). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 138.0 in stage 43.0 (TID 1583) (host.docker.internal, executor driver, partition 138, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 133.0 in stage 43.0 (TID 1578) in 33 ms on host.docker.internal (executor driver) (142/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 138.0 in stage 43.0 (TID 1583)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1582 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2f732a55
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1582 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2f732a55
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1582 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1577: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 138-139
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 131.0 in stage 43.0 (TID 1577). 6010 bytes result sent to driver
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 139.0 in stage 43.0 (TID 1584) (host.docker.internal, executor driver, partition 139, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  Executor:57 - Running task 139.0 in stage 43.0 (TID 1584)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 131.0 in stage 43.0 (TID 1577) in 47 ms on host.docker.internal (executor driver) (143/200)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1583 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2a084b70
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1583 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2a084b70
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1576: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1583 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 130.0 in stage 43.0 (TID 1576). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 139-140
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 140.0 in stage 43.0 (TID 1585) (host.docker.internal, executor driver, partition 140, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  Executor:57 - Running task 140.0 in stage 43.0 (TID 1585)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 130.0 in stage 43.0 (TID 1576) in 62 ms on host.docker.internal (executor driver) (144/200)
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1584 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@36a4c80d
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1584 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@36a4c80d
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1584 with length 33
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 140-141
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1575: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1585 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@e13216a
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 129.0 in stage 43.0 (TID 1575). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1585 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@e13216a
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1585 with length 33
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 141.0 in stage 43.0 (TID 1586) (host.docker.internal, executor driver, partition 141, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 129.0 in stage 43.0 (TID 1575) in 77 ms on host.docker.internal (executor driver) (145/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 141.0 in stage 43.0 (TID 1586)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 141-142
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1574: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1586 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@bc1f5c7
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 128.0 in stage 43.0 (TID 1574). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1586 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@bc1f5c7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1586 with length 33
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 142.0 in stage 43.0 (TID 1587) (host.docker.internal, executor driver, partition 142, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  Executor:57 - Running task 142.0 in stage 43.0 (TID 1587)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 128.0 in stage 43.0 (TID 1574) in 92 ms on host.docker.internal (executor driver) (146/200)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1585: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 140.0 in stage 43.0 (TID 1585). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 142-143
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 143.0 in stage 43.0 (TID 1588) (host.docker.internal, executor driver, partition 143, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  Executor:57 - Running task 143.0 in stage 43.0 (TID 1588)
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 140.0 in stage 43.0 (TID 1585) in 21 ms on host.docker.internal (executor driver) (147/200)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1587 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@299a0db7
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1587 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@299a0db7
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 143-144
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1587 with length 33
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1584: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 139.0 in stage 43.0 (TID 1584). 5967 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 144.0 in stage 43.0 (TID 1589) (host.docker.internal, executor driver, partition 144, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  Executor:57 - Running task 144.0 in stage 43.0 (TID 1589)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 139.0 in stage 43.0 (TID 1584) in 33 ms on host.docker.internal (executor driver) (148/200)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1588 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@ee4f71d
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1588 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@ee4f71d
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1588 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 144-145
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1583: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 138.0 in stage 43.0 (TID 1583). 5967 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 145.0 in stage 43.0 (TID 1590) (host.docker.internal, executor driver, partition 145, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Running task 145.0 in stage 43.0 (TID 1590)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 138.0 in stage 43.0 (TID 1583) in 46 ms on host.docker.internal (executor driver) (149/200)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1589 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5dc47b6
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1589 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5dc47b6
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1589 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 145-146
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1582: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 137.0 in stage 43.0 (TID 1582). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1590 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@24b5358
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 146.0 in stage 43.0 (TID 1591) (host.docker.internal, executor driver, partition 146, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Running task 146.0 in stage 43.0 (TID 1591)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 137.0 in stage 43.0 (TID 1582) in 61 ms on host.docker.internal (executor driver) (150/200)
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1590 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@24b5358
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1590 with length 33
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1581: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 136.0 in stage 43.0 (TID 1581). 5967 bytes result sent to driver
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 146-147
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 147.0 in stage 43.0 (TID 1592) (host.docker.internal, executor driver, partition 147, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 136.0 in stage 43.0 (TID 1581) in 73 ms on host.docker.internal (executor driver) (151/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 147.0 in stage 43.0 (TID 1592)
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1591 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@11c18eea
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1591 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@11c18eea
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1591 with length 33
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 147-148
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1580: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 135.0 in stage 43.0 (TID 1580). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 148.0 in stage 43.0 (TID 1593) (host.docker.internal, executor driver, partition 148, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 135.0 in stage 43.0 (TID 1580) in 87 ms on host.docker.internal (executor driver) (152/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 148.0 in stage 43.0 (TID 1593)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1592 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@16e095df
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1592 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@16e095df
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1592 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1591: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 148-149
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 146.0 in stage 43.0 (TID 1591). 5967 bytes result sent to driver
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 149.0 in stage 43.0 (TID 1594) (host.docker.internal, executor driver, partition 149, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  Executor:57 - Running task 149.0 in stage 43.0 (TID 1594)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 146.0 in stage 43.0 (TID 1591) in 23 ms on host.docker.internal (executor driver) (153/200)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1593 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@23b0deea
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1593 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@23b0deea
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1593 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 149-150
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1590: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 145.0 in stage 43.0 (TID 1590). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 150.0 in stage 43.0 (TID 1595) (host.docker.internal, executor driver, partition 150, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 145.0 in stage 43.0 (TID 1590) in 40 ms on host.docker.internal (executor driver) (154/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 150.0 in stage 43.0 (TID 1595)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1594 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1b53e71f
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1594 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1b53e71f
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1594 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1589: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 150-151
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 144.0 in stage 43.0 (TID 1589). 5967 bytes result sent to driver
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 151.0 in stage 43.0 (TID 1596) (host.docker.internal, executor driver, partition 151, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  Executor:57 - Running task 151.0 in stage 43.0 (TID 1596)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 144.0 in stage 43.0 (TID 1589) in 54 ms on host.docker.internal (executor driver) (155/200)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1595 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1b8267cf
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1595 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1b8267cf
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1595 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 151-152
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1588: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 143.0 in stage 43.0 (TID 1588). 5967 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 152.0 in stage 43.0 (TID 1597) (host.docker.internal, executor driver, partition 152, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 143.0 in stage 43.0 (TID 1588) in 69 ms on host.docker.internal (executor driver) (156/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 152.0 in stage 43.0 (TID 1597)
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1596 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@61630893
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1596 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@61630893
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1596 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1587: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 152-153
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 142.0 in stage 43.0 (TID 1587). 5967 bytes result sent to driver
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 153.0 in stage 43.0 (TID 1598) (host.docker.internal, executor driver, partition 153, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 142.0 in stage 43.0 (TID 1587) in 82 ms on host.docker.internal (executor driver) (157/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 153.0 in stage 43.0 (TID 1598)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1597 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1cf0f4d9
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1597 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1cf0f4d9
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1597 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 153-154
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1586: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 141.0 in stage 43.0 (TID 1586). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 154.0 in stage 43.0 (TID 1599) (host.docker.internal, executor driver, partition 154, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Running task 154.0 in stage 43.0 (TID 1599)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 141.0 in stage 43.0 (TID 1586) in 97 ms on host.docker.internal (executor driver) (158/200)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1598 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@513d55ba
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1598 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@513d55ba
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1598 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1597: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 154-155
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 152.0 in stage 43.0 (TID 1597). 5967 bytes result sent to driver
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 155.0 in stage 43.0 (TID 1600) (host.docker.internal, executor driver, partition 155, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  Executor:57 - Running task 155.0 in stage 43.0 (TID 1600)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 152.0 in stage 43.0 (TID 1597) in 24 ms on host.docker.internal (executor driver) (159/200)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1599 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@57538842
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1599 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@57538842
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1599 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 155-156
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1596: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 151.0 in stage 43.0 (TID 1596). 6053 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 156.0 in stage 43.0 (TID 1601) (host.docker.internal, executor driver, partition 156, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 151.0 in stage 43.0 (TID 1596) in 40 ms on host.docker.internal (executor driver) (160/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 156.0 in stage 43.0 (TID 1601)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1600 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@36ee9be8
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1600 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@36ee9be8
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1600 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1595: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 156-157
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 150.0 in stage 43.0 (TID 1595). 6010 bytes result sent to driver
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 157.0 in stage 43.0 (TID 1602) (host.docker.internal, executor driver, partition 157, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  Executor:57 - Running task 157.0 in stage 43.0 (TID 1602)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 150.0 in stage 43.0 (TID 1595) in 55 ms on host.docker.internal (executor driver) (161/200)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1601 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@381f9e40
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1601 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@381f9e40
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1601 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 157-158
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1594: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 149.0 in stage 43.0 (TID 1594). 6053 bytes result sent to driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 158.0 in stage 43.0 (TID 1603) (host.docker.internal, executor driver, partition 158, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1602 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@64506098
2022-01-11 16:18:09 INFO  Executor:57 - Running task 158.0 in stage 43.0 (TID 1603)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 149.0 in stage 43.0 (TID 1594) in 69 ms on host.docker.internal (executor driver) (162/200)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1602 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@64506098
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1602 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 158-159
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1593: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 148.0 in stage 43.0 (TID 1593). 5967 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 159.0 in stage 43.0 (TID 1604) (host.docker.internal, executor driver, partition 159, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Running task 159.0 in stage 43.0 (TID 1604)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 148.0 in stage 43.0 (TID 1593) in 87 ms on host.docker.internal (executor driver) (163/200)
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1603 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@270e7942
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1603 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@270e7942
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1603 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1592: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 159-160
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 147.0 in stage 43.0 (TID 1592). 6053 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 161.0 in stage 43.0 (TID 1605) (host.docker.internal, executor driver, partition 161, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  Executor:57 - Running task 161.0 in stage 43.0 (TID 1605)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 147.0 in stage 43.0 (TID 1592) in 100 ms on host.docker.internal (executor driver) (164/200)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1604 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@44b25d9f
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1604 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@44b25d9f
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1604 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1603: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 161-162
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 158.0 in stage 43.0 (TID 1603). 5967 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 162.0 in stage 43.0 (TID 1606) (host.docker.internal, executor driver, partition 162, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 158.0 in stage 43.0 (TID 1603) in 20 ms on host.docker.internal (executor driver) (165/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 162.0 in stage 43.0 (TID 1606)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1605 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7c4271cb
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1605 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7c4271cb
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1605 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 162-163
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1602: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1606 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@35d84af3
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 157.0 in stage 43.0 (TID 1602). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1606 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@35d84af3
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 163.0 in stage 43.0 (TID 1607) (host.docker.internal, executor driver, partition 163, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1606 with length 33
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 157.0 in stage 43.0 (TID 1602) in 35 ms on host.docker.internal (executor driver) (166/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 163.0 in stage 43.0 (TID 1607)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1601: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 156.0 in stage 43.0 (TID 1601). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 163-164
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 165.0 in stage 43.0 (TID 1608) (host.docker.internal, executor driver, partition 165, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 INFO  Executor:57 - Running task 165.0 in stage 43.0 (TID 1608)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 156.0 in stage 43.0 (TID 1601) in 48 ms on host.docker.internal (executor driver) (167/200)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1607 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3b01eabb
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1607 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3b01eabb
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1607 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 165-166
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1600: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 155.0 in stage 43.0 (TID 1600). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 167.0 in stage 43.0 (TID 1609) (host.docker.internal, executor driver, partition 167, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Running task 167.0 in stage 43.0 (TID 1609)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 155.0 in stage 43.0 (TID 1600) in 61 ms on host.docker.internal (executor driver) (168/200)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1608 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@292fedf9
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1608 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@292fedf9
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1608 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 167-168
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1599: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 154.0 in stage 43.0 (TID 1599). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 168.0 in stage 43.0 (TID 1610) (host.docker.internal, executor driver, partition 168, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 154.0 in stage 43.0 (TID 1599) in 77 ms on host.docker.internal (executor driver) (169/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 168.0 in stage 43.0 (TID 1610)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1609 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1eb62788
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1609 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1eb62788
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1609 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1598: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 168-169
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 153.0 in stage 43.0 (TID 1598). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 170.0 in stage 43.0 (TID 1611) (host.docker.internal, executor driver, partition 170, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 153.0 in stage 43.0 (TID 1598) in 91 ms on host.docker.internal (executor driver) (170/200)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Running task 170.0 in stage 43.0 (TID 1611)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1610 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@43691d96
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1610 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@43691d96
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1610 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 170-171
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1609: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 167.0 in stage 43.0 (TID 1609). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 171.0 in stage 43.0 (TID 1612) (host.docker.internal, executor driver, partition 171, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1611 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@5d39d919
2022-01-11 16:18:09 INFO  Executor:57 - Running task 171.0 in stage 43.0 (TID 1612)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 167.0 in stage 43.0 (TID 1609) in 20 ms on host.docker.internal (executor driver) (171/200)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1611 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@5d39d919
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1611 with length 33
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1608: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 165.0 in stage 43.0 (TID 1608). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 171-172
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 172.0 in stage 43.0 (TID 1613) (host.docker.internal, executor driver, partition 172, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  Executor:57 - Running task 172.0 in stage 43.0 (TID 1613)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 165.0 in stage 43.0 (TID 1608) in 31 ms on host.docker.internal (executor driver) (172/200)
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1612 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@420859bb
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1612 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@420859bb
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1612 with length 33
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1607: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 172-173
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 163.0 in stage 43.0 (TID 1607). 5967 bytes result sent to driver
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 173.0 in stage 43.0 (TID 1614) (host.docker.internal, executor driver, partition 173, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  Executor:57 - Running task 173.0 in stage 43.0 (TID 1614)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 163.0 in stage 43.0 (TID 1607) in 43 ms on host.docker.internal (executor driver) (173/200)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1613 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@522226c9
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1613 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@522226c9
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1613 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1606: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 173-174
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 162.0 in stage 43.0 (TID 1606). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 174.0 in stage 43.0 (TID 1615) (host.docker.internal, executor driver, partition 174, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 162.0 in stage 43.0 (TID 1606) in 57 ms on host.docker.internal (executor driver) (174/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 174.0 in stage 43.0 (TID 1615)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1614 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2cf81fa4
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1614 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2cf81fa4
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1614 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 174-175
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1605: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 161.0 in stage 43.0 (TID 1605). 5967 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1615 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@3c392c2a
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 175.0 in stage 43.0 (TID 1616) (host.docker.internal, executor driver, partition 175, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Running task 175.0 in stage 43.0 (TID 1616)
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1615 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@3c392c2a
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 161.0 in stage 43.0 (TID 1605) in 70 ms on host.docker.internal (executor driver) (175/200)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1615 with length 33
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 175-176
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1604: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 159.0 in stage 43.0 (TID 1604). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 177.0 in stage 43.0 (TID 1617) (host.docker.internal, executor driver, partition 177, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 159.0 in stage 43.0 (TID 1604) in 85 ms on host.docker.internal (executor driver) (176/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 177.0 in stage 43.0 (TID 1617)
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1616 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@73dc049b
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1616 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@73dc049b
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1616 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1615: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 177-178
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 174.0 in stage 43.0 (TID 1615). 6010 bytes result sent to driver
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 178.0 in stage 43.0 (TID 1618) (host.docker.internal, executor driver, partition 178, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  Executor:57 - Running task 178.0 in stage 43.0 (TID 1618)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 174.0 in stage 43.0 (TID 1615) in 20 ms on host.docker.internal (executor driver) (177/200)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1617 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@e973058
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1617 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@e973058
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1617 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 178-179
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1614: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 173.0 in stage 43.0 (TID 1614). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1618 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1c78592a
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 180.0 in stage 43.0 (TID 1619) (host.docker.internal, executor driver, partition 180, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 173.0 in stage 43.0 (TID 1614) in 34 ms on host.docker.internal (executor driver) (178/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 180.0 in stage 43.0 (TID 1619)
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1618 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1c78592a
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1618 with length 33
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 180-181
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1613: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 172.0 in stage 43.0 (TID 1613). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1619 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@78682f7b
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 181.0 in stage 43.0 (TID 1620) (host.docker.internal, executor driver, partition 181, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 172.0 in stage 43.0 (TID 1613) in 46 ms on host.docker.internal (executor driver) (179/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 181.0 in stage 43.0 (TID 1620)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1619 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@78682f7b
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1619 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 181-182
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1612: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 171.0 in stage 43.0 (TID 1612). 5967 bytes result sent to driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 182.0 in stage 43.0 (TID 1621) (host.docker.internal, executor driver, partition 182, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1620 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7837e4e3
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 171.0 in stage 43.0 (TID 1612) in 59 ms on host.docker.internal (executor driver) (180/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 182.0 in stage 43.0 (TID 1621)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1620 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7837e4e3
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1620 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 182-183
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1611: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 170.0 in stage 43.0 (TID 1611). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1621 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@1ca9f039
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 184.0 in stage 43.0 (TID 1622) (host.docker.internal, executor driver, partition 184, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1621 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@1ca9f039
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 170.0 in stage 43.0 (TID 1611) in 73 ms on host.docker.internal (executor driver) (181/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 184.0 in stage 43.0 (TID 1622)
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1621 with length 33
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1610: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 168.0 in stage 43.0 (TID 1610). 5967 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 185.0 in stage 43.0 (TID 1623) (host.docker.internal, executor driver, partition 185, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 168.0 in stage 43.0 (TID 1610) in 83 ms on host.docker.internal (executor driver) (182/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 185.0 in stage 43.0 (TID 1623)
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 184-185
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1622 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@53807a78
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 185-186
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1621: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1622 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@53807a78
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 182.0 in stage 43.0 (TID 1621). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1622 with length 33
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 186.0 in stage 43.0 (TID 1624) (host.docker.internal, executor driver, partition 186, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1623 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@35e9628b
2022-01-11 16:18:09 INFO  Executor:57 - Running task 186.0 in stage 43.0 (TID 1624)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 182.0 in stage 43.0 (TID 1621) in 18 ms on host.docker.internal (executor driver) (183/200)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1623 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@35e9628b
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1623 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 186-187
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1620: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 181.0 in stage 43.0 (TID 1620). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 187.0 in stage 43.0 (TID 1625) (host.docker.internal, executor driver, partition 187, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1624 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@332f9247
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 181.0 in stage 43.0 (TID 1620) in 30 ms on host.docker.internal (executor driver) (184/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 187.0 in stage 43.0 (TID 1625)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1624 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@332f9247
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1624 with length 33
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1619: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 180.0 in stage 43.0 (TID 1619). 5967 bytes result sent to driver
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 187-188
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 188.0 in stage 43.0 (TID 1626) (host.docker.internal, executor driver, partition 188, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 180.0 in stage 43.0 (TID 1619) in 41 ms on host.docker.internal (executor driver) (185/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 188.0 in stage 43.0 (TID 1626)
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1618: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1625 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@42623f83
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 188-189
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 178.0 in stage 43.0 (TID 1618). 5967 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1625 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@42623f83
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1625 with length 33
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 189.0 in stage 43.0 (TID 1627) (host.docker.internal, executor driver, partition 189, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 178.0 in stage 43.0 (TID 1618) in 54 ms on host.docker.internal (executor driver) (186/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 189.0 in stage 43.0 (TID 1627)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1626 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@7d15d73e
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1626 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@7d15d73e
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1626 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1617: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 189-190
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 177.0 in stage 43.0 (TID 1617). 6010 bytes result sent to driver
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 192.0 in stage 43.0 (TID 1628) (host.docker.internal, executor driver, partition 192, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Running task 192.0 in stage 43.0 (TID 1628)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 177.0 in stage 43.0 (TID 1617) in 67 ms on host.docker.internal (executor driver) (187/200)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1627 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@23624232
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1627 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@23624232
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1627 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1616: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 192-193
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 175.0 in stage 43.0 (TID 1616). 6010 bytes result sent to driver
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 194.0 in stage 43.0 (TID 1629) (host.docker.internal, executor driver, partition 194, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 175.0 in stage 43.0 (TID 1616) in 79 ms on host.docker.internal (executor driver) (188/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 194.0 in stage 43.0 (TID 1629)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1628 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@324ae012
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1628 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@324ae012
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1628 with length 33
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1627: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 189.0 in stage 43.0 (TID 1627). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 194-195
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 195.0 in stage 43.0 (TID 1630) (host.docker.internal, executor driver, partition 195, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:09 INFO  Executor:57 - Running task 195.0 in stage 43.0 (TID 1630)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 189.0 in stage 43.0 (TID 1627) in 19 ms on host.docker.internal (executor driver) (189/200)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1629 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@28321743
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1629 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@28321743
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1626: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1629 with length 33
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 188.0 in stage 43.0 (TID 1626). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 196.0 in stage 43.0 (TID 1631) (host.docker.internal, executor driver, partition 196, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  Executor:57 - Running task 196.0 in stage 43.0 (TID 1631)
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 188.0 in stage 43.0 (TID 1626) in 29 ms on host.docker.internal (executor driver) (190/200)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 195-196
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1630 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@2d6995b2
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 196-197
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1630 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@2d6995b2
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1630 with length 33
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1625: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 187.0 in stage 43.0 (TID 1625). 5967 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1631 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@221f2cf9
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 197.0 in stage 43.0 (TID 1632) (host.docker.internal, executor driver, partition 197, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 INFO  Executor:57 - Running task 197.0 in stage 43.0 (TID 1632)
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 187.0 in stage 43.0 (TID 1625) in 40 ms on host.docker.internal (executor driver) (191/200)
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1631 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@221f2cf9
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1631 with length 33
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 197-198
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1624: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 186.0 in stage 43.0 (TID 1624). 6053 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1632 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@729ea0f8
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Moving to ANY after waiting for 0ms
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 198.0 in stage 43.0 (TID 1633) (host.docker.internal, executor driver, partition 198, PROCESS_LOCAL, 4442 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 186.0 in stage 43.0 (TID 1624) in 56 ms on host.docker.internal (executor driver) (192/200)
2022-01-11 16:18:09 INFO  Executor:57 - Running task 198.0 in stage 43.0 (TID 1633)
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1632 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@729ea0f8
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1632 with length 33
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 8
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 8
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 8, mappers 0-1, partitions 198-199
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: 
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1623: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 INFO  Executor:57 - Finished task 185.0 in stage 43.0 (TID 1623). 5967 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 7
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_43.0, runningTasks: 7
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for null:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */
/* 032 */     if (true) {
/* 033 */       mutableStateArray_0[0].setNullAt(0);
/* 034 */     } else {
/* 035 */       mutableStateArray_0[0].write(0, -1.0);
/* 036 */     }
/* 037 */     return (mutableStateArray_0[0].getRow());
/* 038 */   }
/* 039 */
/* 040 */
/* 041 */ }

2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level NO_PREF
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, int, true],input[1, int, true],input[2, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */
/* 049 */     boolean isNull_2 = i.isNullAt(2);
/* 050 */     UTF8String value_2 = isNull_2 ?
/* 051 */     null : (i.getUTF8String(2));
/* 052 */     if (isNull_2) {
/* 053 */       mutableStateArray_0[0].setNullAt(2);
/* 054 */     } else {
/* 055 */       mutableStateArray_0[0].write(2, value_2);
/* 056 */     }
/* 057 */     return (mutableStateArray_0[0].getRow());
/* 058 */   }
/* 059 */
/* 060 */
/* 061 */ }

2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 185.0 in stage 43.0 (TID 1623) in 68 ms on host.docker.internal (executor driver) (193/200)
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1633 acquired 256.0 KiB for org.apache.spark.unsafe.map.BytesToBytesMap@409ac212
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for input[0, double, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     double value_0 = isNull_0 ?
/* 033 */     -1.0 : (i.getDouble(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1633 release 256.0 KiB from org.apache.spark.unsafe.map.BytesToBytesMap@409ac212
2022-01-11 16:18:09 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 1633 with length 33
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1622: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 184.0 in stage 43.0 (TID 1622). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 6
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 184.0 in stage 43.0 (TID 1622) in 78 ms on host.docker.internal (executor driver) (194/200)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1633: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 198.0 in stage 43.0 (TID 1633). 5967 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 5
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 198.0 in stage 43.0 (TID 1633) in 19 ms on host.docker.internal (executor driver) (195/200)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1632: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 197.0 in stage 43.0 (TID 1632). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 4
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 197.0 in stage 43.0 (TID 1632) in 33 ms on host.docker.internal (executor driver) (196/200)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1631: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 196.0 in stage 43.0 (TID 1631). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 3
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 196.0 in stage 43.0 (TID 1631) in 44 ms on host.docker.internal (executor driver) (197/200)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1630: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 195.0 in stage 43.0 (TID 1630). 5967 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 2
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 195.0 in stage 43.0 (TID 1630) in 56 ms on host.docker.internal (executor driver) (198/200)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1629: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 194.0 in stage 43.0 (TID 1629). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (43, 0) -> 1
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 194.0 in stage 43.0 (TID 1629) in 67 ms on host.docker.internal (executor driver) (199/200)
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 1628: [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 192.0 in stage 43.0 (TID 1628). 6010 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - removing (43, 0) from stageTCMP
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 192.0 in stage 43.0 (TID 1628) in 77 ms on host.docker.internal (executor driver) (200/200)
2022-01-11 16:18:09 INFO  TaskSchedulerImpl:57 - Removed TaskSet 43.0, whose tasks have all completed, from pool 
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-11 16:18:09 INFO  DAGScheduler:57 - ShuffleMapStage 43 (save at Load.java:11) finished in 1.382 s
2022-01-11 16:18:09 INFO  DAGScheduler:57 - looking for newly runnable stages
2022-01-11 16:18:09 INFO  DAGScheduler:57 - running: Set()
2022-01-11 16:18:09 INFO  DAGScheduler:57 - waiting: Set(ResultStage 44)
2022-01-11 16:18:09 INFO  DAGScheduler:57 - failed: Set()
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Increasing epoch to 10
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - submitStage(ResultStage 44 (name=save at Load.java:11;jobs=29))
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - missing: List()
2022-01-11 16:18:09 INFO  DAGScheduler:57 - Submitting ResultStage 44 (CoalescedRDD[173] at save at Load.java:11), which has no missing parents
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 44)
2022-01-11 16:18:09 INFO  MemoryStore:57 - Block broadcast_73 stored as values in memory (estimated size 205.2 KiB, free 2.2 GiB)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Put block broadcast_73 locally took 0 ms
2022-01-11 16:18:09 DEBUG BlockManager:61 - Putting block broadcast_73 without replication took 0 ms
2022-01-11 16:18:09 INFO  MemoryStore:57 - Block broadcast_73_piece0 stored as bytes in memory (estimated size 77.6 KiB, free 2.2 GiB)
2022-01-11 16:18:09 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_73_piece0 for BlockManagerId(driver, host.docker.internal, 57009, None)
2022-01-11 16:18:09 INFO  BlockManagerInfo:57 - Added broadcast_73_piece0 in memory on host.docker.internal:57009 (size: 77.6 KiB, free: 2.2 GiB)
2022-01-11 16:18:09 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_73_piece0
2022-01-11 16:18:09 DEBUG BlockManager:61 - Told master about block broadcast_73_piece0
2022-01-11 16:18:09 DEBUG BlockManager:61 - Put block broadcast_73_piece0 locally took 0 ms
2022-01-11 16:18:09 DEBUG BlockManager:61 - Putting block broadcast_73_piece0 without replication took 0 ms
2022-01-11 16:18:09 INFO  SparkContext:57 - Created broadcast 73 from broadcast at DAGScheduler.scala:1388
2022-01-11 16:18:09 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 44 (CoalescedRDD[173] at save at Load.java:11) (first 15 tasks are for partitions Vector(0))
2022-01-11 16:18:09 INFO  TaskSchedulerImpl:57 - Adding task set 44.0 with 1 tasks resource profile 0
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Epoch for TaskSet 44.0: 10
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 44.0: NODE_LOCAL, ANY
2022-01-11 16:18:09 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_44.0, runningTasks: 0
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Starting task 0.0 in stage 44.0 (TID 1634) (host.docker.internal, executor driver, partition 0, NODE_LOCAL, 5625 bytes) taskResourceAssignments Map()
2022-01-11 16:18:09 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
2022-01-11 16:18:09 INFO  Executor:57 - Running task 0.0 in stage 44.0 (TID 1634)
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (44, 0) -> 1
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local block broadcast_73
2022-01-11 16:18:09 DEBUG BlockManager:61 - Level for block broadcast_73 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-11 16:18:09 DEBUG PathOutputCommitterFactory:149 - Looking for committer factory for path file:/C:/Users/Rahul Kabothula/Intellij Maven Projects/retail_db/result/task5_result
2022-01-11 16:18:09 DEBUG PathOutputCommitterFactory:164 - No scheme-specific factory defined in mapreduce.outputcommitter.factory.scheme.file
2022-01-11 16:18:09 DEBUG PathOutputCommitterFactory:174 - No output committer factory defined, defaulting to FileOutputCommitterFactory
2022-01-11 16:18:09 DEBUG PathOutputCommitterFactory:132 - Creating FileOutputCommitter for path file:/C:/Users/Rahul Kabothula/Intellij Maven Projects/retail_db/result/task5_result and context TaskAttemptContextImpl{JobContextImpl{jobId=job_202201111618086924156779749415335_0044}; taskId=attempt_202201111618086924156779749415335_0044_m_000000_1634, status=''}
2022-01-11 16:18:09 DEBUG PathOutputCommitter:74 - Instantiating committer FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_202201111618086924156779749415335_0044}; taskId=attempt_202201111618086924156779749415335_0044_m_000000_1634, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@f0a6d2}; outputPath=null, workPath=null, algorithmVersion=0, skipCleanup=false, ignoreCleanupFailures=false} with output path file:/C:/Users/Rahul Kabothula/Intellij Maven Projects/retail_db/result/task5_result and job context TaskAttemptContextImpl{JobContextImpl{jobId=job_202201111618086924156779749415335_0044}; taskId=attempt_202201111618086924156779749415335_0044_m_000000_1634, status=''}
2022-01-11 16:18:09 INFO  FileOutputCommitter:140 - File Output Committer Algorithm version is 1
2022-01-11 16:18:09 INFO  FileOutputCommitter:155 - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2022-01-11 16:18:09 INFO  SQLHadoopMapReduceCommitProtocol:57 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2022-01-11 16:18:09 DEBUG FileSystem:538 - NativeIO.createDirectoryWithMode error, path = C:\Users\Rahul Kabothula\Intellij Maven Projects\retail_db\result\task5_result\_temporary\0\_temporary\attempt_202201111618086924156779749415335_0044_m_000000_1634, mode = 755
183: Cannot create a file when that file already exists.

	at org.apache.hadoop.io.nativeio.NativeIO$Windows.createDirectoryWithMode0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.createDirectoryWithMode(NativeIO.java:560)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:587)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:559)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:316)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:351)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:401)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:464)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)
	at org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)
	at org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)
	at org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)
	at org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)
	at org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2022-01-11 16:18:09 DEBUG FileSystem:538 - NativeIO.createDirectoryWithMode error, path = C:\Users\Rahul Kabothula\Intellij Maven Projects\retail_db\result\task5_result\_temporary\0\_temporary\attempt_202201111618086924156779749415335_0044_m_000000_1634, mode = 755
183: Cannot create a file when that file already exists.

	at org.apache.hadoop.io.nativeio.NativeIO$Windows.createDirectoryWithMode0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.createDirectoryWithMode(NativeIO.java:560)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:587)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:559)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:316)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:351)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:405)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:464)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStream(CodecStreams.scala:81)
	at org.apache.spark.sql.execution.datasources.CodecStreams$.createOutputStreamWriter(CodecStreams.scala:92)
	at org.apache.spark.sql.execution.datasources.csv.CsvOutputWriter.<init>(CsvOutputWriter.scala:38)
	at org.apache.spark.sql.execution.datasources.csv.CSVFileFormat$$anon$1.newInstance(CSVFileFormat.scala:84)
	at org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.newOutputWriter(FileFormatDataWriter.scala:126)
	at org.apache.spark.sql.execution.datasources.SingleDirectoryDataWriter.<init>(FileFormatDataWriter.scala:111)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:269)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:210)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 0-1
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1459_0,179)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1459_0
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@14067e17
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@14067e17
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@14067e17
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@14067e17
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 1-2
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1454_1,160)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1454_1
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@43290eb1
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@43290eb1
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@43290eb1
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@43290eb1
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 2-3
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1444_2,52)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1444_2
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@21293025
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@21293025
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@21293025
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@21293025
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 3-4
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1441_3,42)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1441_3
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@1cb7d30f
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@1cb7d30f
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@1cb7d30f
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@1cb7d30f
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 4-5
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1452_4,115)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1452_4
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@3be6f048
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@3be6f048
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@3be6f048
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@3be6f048
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 5-6
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1440_5,38)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1440_5
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@30b12d03
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@30b12d03
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@30b12d03
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@30b12d03
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 6-7
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1448_6,86)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1448_6
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@58719b28
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@58719b28
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@58719b28
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@58719b28
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 7-8
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1456_7,166)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1456_7
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@7a7c1482
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@7a7c1482
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@7a7c1482
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@7a7c1482
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 8-9
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1437_8,29)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1437_8
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@7614cf35
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@7614cf35
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@7614cf35
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@7614cf35
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 9-10
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1463_9,193)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1463_9
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@4f742dc1
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@4f742dc1
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@4f742dc1
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@4f742dc1
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 10-11
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1450_10,90)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1450_10
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@1b0847dc
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@1b0847dc
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@1b0847dc
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@1b0847dc
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 11-12
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1460_11,183)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1460_11
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@14a983b
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@14a983b
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@14a983b
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@14a983b
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 12-13
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1458_12,176)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1458_12
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@51f78240
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@51f78240
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@51f78240
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@51f78240
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 13-14
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1462_13,191)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1462_13
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@3f83b79a
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@3f83b79a
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@3f83b79a
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@3f83b79a
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 14-15
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1451_14,108)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1451_14
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@66ec2111
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@66ec2111
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@66ec2111
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@66ec2111
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 15-16
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1461_15,190)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1461_15
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@33b2e6b7
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@33b2e6b7
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@33b2e6b7
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@33b2e6b7
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 16-17
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1442_16,43)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1442_16
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@5eba9703
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@5eba9703
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@5eba9703
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@5eba9703
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 17-18
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1457_17,169)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1457_17
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 4 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@7ca7c429
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@7ca7c429
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@7ca7c429
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@7ca7c429
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 18-19
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1445_18,63)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1445_18
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@7b448605
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@7b448605
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@7b448605
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@7b448605
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 19-20
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1447_19,74)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1447_19
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@5fe75084
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@5fe75084
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@5fe75084
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@5fe75084
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 20-21
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1437_20,29)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1437_20
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@556fd6f4
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@556fd6f4
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@556fd6f4
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@556fd6f4
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 21-22
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1438_21,31)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1438_21
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@17abc6fc
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@17abc6fc
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@17abc6fc
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@17abc6fc
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 22-23
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1434_22,7)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1434_22
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@48800ea2
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@48800ea2
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@48800ea2
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@48800ea2
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 23-24
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1446_23,73)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1446_23
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@2d860446
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@2d860446
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@2d860446
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@2d860446
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 24-25
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1453_24,132)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1453_24
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@6f5bf74
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@6f5bf74
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@6f5bf74
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@6f5bf74
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 25-26
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1435_25,17)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1435_25
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@4fa00570
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@4fa00570
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@4fa00570
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@4fa00570
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 26-27
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1436_26,19)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1436_26
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@79df738
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@79df738
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@79df738
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@79df738
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 27-28
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1439_27,35)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1439_27
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@1aa467b9
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@1aa467b9
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@1aa467b9
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@1aa467b9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 28-29
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1460_28,183)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1460_28
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@31016586
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@31016586
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@31016586
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@31016586
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 29-30
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1449_29,89)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1449_29
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@7e456d53
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@7e456d53
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@7e456d53
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@7e456d53
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 30-31
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1455_30,164)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1455_30
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@16896194
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@16896194
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@16896194
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@16896194
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 31-32
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1464_31,199)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1464_31
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 0 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@2fa95553
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@2fa95553
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@2fa95553
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@2fa95553
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 9
2022-01-11 16:18:09 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 9, mappers 0-200, partitions 32-33
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (97.0 B) non-empty blocks including 1 (97.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-11 16:18:09 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_9_1443_32,48)
2022-01-11 16:18:09 DEBUG BlockManager:61 - Getting local shuffle block shuffle_9_1443_32
2022-01-11 16:18:09 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-11 16:18:09 DEBUG GenerateOrdering:61 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     boolean isNull_0 = a.isNullAt(0);
/* 018 */     int value_0 = isNull_0 ?
/* 019 */     -1 : (a.getInt(0));
/* 020 */     boolean isNull_1 = b.isNullAt(0);
/* 021 */     int value_1 = isNull_1 ?
/* 022 */     -1 : (b.getInt(0));
/* 023 */     if (isNull_0 && isNull_1) {
/* 024 */       // Nothing
/* 025 */     } else if (isNull_0) {
/* 026 */       return -1;
/* 027 */     } else if (isNull_1) {
/* 028 */       return 1;
/* 029 */     } else {
/* 030 */       int comp = (value_0 > value_1 ? 1 : value_0 < value_1 ? -1 : 0);
/* 031 */       if (comp != 0) {
/* 032 */         return comp;
/* 033 */       }
/* 034 */     }
/* 035 */
/* 036 */     return 0;
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */ }

2022-01-11 16:18:09 DEBUG GenerateUnsafeProjection:61 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 64.0 KiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@15be3875
2022-01-11 16:18:09 DEBUG TaskMemoryManager:228 - Task 1634 acquired 16.0 MiB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@15be3875
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 16.0 MiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@15be3875
2022-01-11 16:18:09 DEBUG TaskMemoryManager:237 - Task 1634 release 64.0 KiB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@15be3875
2022-01-11 16:18:09 DEBUG OutputCommitCoordinator:61 - Commit allowed for stage=44.0, partition=0, task attempt 0
2022-01-11 16:18:09 INFO  FileOutputCommitter:593 - Saved output of task 'attempt_202201111618086924156779749415335_0044_m_000000_1634' to file:/C:/Users/Rahul Kabothula/Intellij Maven Projects/retail_db/result/task5_result/_temporary/0/task_202201111618086924156779749415335_0044_m_000000
2022-01-11 16:18:09 INFO  SparkHadoopMapRedUtil:57 - attempt_202201111618086924156779749415335_0044_m_000000_1634: Committed
2022-01-11 16:18:09 INFO  Executor:57 - Finished task 0.0 in stage 44.0 (TID 1634). 7814 bytes result sent to driver
2022-01-11 16:18:09 DEBUG ExecutorMetricsPoller:61 - removing (44, 0) from stageTCMP
2022-01-11 16:18:09 INFO  TaskSetManager:57 - Finished task 0.0 in stage 44.0 (TID 1634) in 174 ms on host.docker.internal (executor driver) (1/1)
2022-01-11 16:18:09 INFO  TaskSchedulerImpl:57 - Removed TaskSet 44.0, whose tasks have all completed, from pool 
2022-01-11 16:18:09 INFO  DAGScheduler:57 - ResultStage 44 (save at Load.java:11) finished in 0.193 s
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - After removal of stage 44, remaining stages = 2
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - After removal of stage 43, remaining stages = 1
2022-01-11 16:18:09 DEBUG DAGScheduler:61 - After removal of stage 42, remaining stages = 0
2022-01-11 16:18:09 INFO  DAGScheduler:57 - Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
2022-01-11 16:18:09 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 44: Stage finished
2022-01-11 16:18:09 DEBUG SQLHadoopMapReduceCommitProtocol:61 - onTaskCommit(org.apache.spark.internal.io.FileCommitProtocol$TaskCommitMessage@695a5945)
2022-01-11 16:18:09 INFO  DAGScheduler:57 - Job 29 finished: save at Load.java:11, took 1.580476 s
2022-01-11 16:18:09 DEBUG FileOutputCommitter:456 - Merging data from DeprecatedRawLocalFileStatus{path=file:/C:/Users/Rahul Kabothula/Intellij Maven Projects/retail_db/result/task5_result/_temporary/0/task_202201111618086924156779749415335_0044_m_000000; isDirectory=true; modification_time=1641898089732; access_time=1641898089732; owner=; group=; permission=rwxrwxrwx; isSymlink=false; hasAcl=false; isEncrypted=false; isErasureCoded=false} to file:/C:/Users/Rahul Kabothula/Intellij Maven Projects/retail_db/result/task5_result
2022-01-11 16:18:09 DEBUG FileOutputCommitter:456 - Merging data from DeprecatedRawLocalFileStatus{path=file:/C:/Users/Rahul Kabothula/Intellij Maven Projects/retail_db/result/task5_result/_temporary/0/task_202201111618086924156779749415335_0044_m_000000/part-00000-d3ac98cc-08f3-47e4-981d-794ea42ac96d-c000.csv; isDirectory=false; length=1226; replication=1; blocksize=33554432; modification_time=1641898089863; access_time=1641898089866; owner=; group=; permission=rw-rw-rw-; isSymlink=false; hasAcl=false; isEncrypted=false; isErasureCoded=false} to file:/C:/Users/Rahul Kabothula/Intellij Maven Projects/retail_db/result/task5_result/part-00000-d3ac98cc-08f3-47e4-981d-794ea42ac96d-c000.csv
2022-01-11 16:18:09 DEBUG FileSystem:538 - NativeIO.createDirectoryWithMode error, path = C:\Users\Rahul Kabothula\Intellij Maven Projects\retail_db\result\task5_result, mode = 755
183: Cannot create a file when that file already exists.

	at org.apache.hadoop.io.nativeio.NativeIO$Windows.createDirectoryWithMode0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.createDirectoryWithMode(NativeIO.java:560)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:587)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:559)
	at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:705)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:456)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:975)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:437)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:375)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitJob(HadoopMapReduceCommitProtocol.scala:182)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:220)
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:188)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)
	at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:132)
	at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:131)
	at org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:989)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:989)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:438)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:415)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:293)
	at Load.write_data(Load.java:11)
	at App.main(App.java:63)
2022-01-11 16:18:09 DEBUG FileSystem:538 - NativeIO.createDirectoryWithMode error, path = C:\Users\Rahul Kabothula\Intellij Maven Projects\retail_db\result\task5_result, mode = 755
183: Cannot create a file when that file already exists.

	at org.apache.hadoop.io.nativeio.NativeIO$Windows.createDirectoryWithMode0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.createDirectoryWithMode(NativeIO.java:560)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:587)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:559)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:316)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:351)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:401)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:464)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:975)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:437)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:375)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitJob(HadoopMapReduceCommitProtocol.scala:182)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:220)
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:188)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)
	at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:132)
	at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:131)
	at org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:989)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:989)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:438)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:415)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:293)
	at Load.write_data(Load.java:11)
	at App.main(App.java:63)
2022-01-11 16:18:09 DEBUG FileSystem:538 - NativeIO.createDirectoryWithMode error, path = C:\Users\Rahul Kabothula\Intellij Maven Projects\retail_db\result\task5_result, mode = 755
183: Cannot create a file when that file already exists.

	at org.apache.hadoop.io.nativeio.NativeIO$Windows.createDirectoryWithMode0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.createDirectoryWithMode(NativeIO.java:560)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:534)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:587)
	at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:559)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:316)
	at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:351)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:405)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:464)
	at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:443)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1118)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1098)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:987)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:975)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:437)
	at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:375)
	at org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.commitJob(HadoopMapReduceCommitProtocol.scala:182)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:220)
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:188)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:108)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:106)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:131)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:180)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:218)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:215)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:176)
	at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:132)
	at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:131)
	at org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:989)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:989)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:438)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:415)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:293)
	at Load.write_data(Load.java:11)
	at App.main(App.java:63)
2022-01-11 16:18:09 DEBUG SQLHadoopMapReduceCommitProtocol:61 - Committing files staged for absolute locations Map()
2022-01-11 16:18:09 DEBUG SQLHadoopMapReduceCommitProtocol:61 - Create absolute parent directories: Set()
2022-01-11 16:18:09 INFO  FileFormatWriter:57 - Write Job 0f45aafe-1bb1-43fb-bfde-f339eca5af79 committed.
2022-01-11 16:18:09 INFO  FileFormatWriter:57 - Finished processing stats for write job 0f45aafe-1bb1-43fb-bfde-f339eca5af79.
2022-01-11 16:18:09 INFO  App:64 - ------------------Loaded data Successfully----------------------
2022-01-11 16:18:09 INFO  SparkContext:57 - Invoking stop() from shutdown hook
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:212 - stopping Server@c6634d{STARTED}[9.4.40.v20210413]
2022-01-11 16:18:09 DEBUG Server:433 - doStop Server@c6634d{STOPPING}[9.4.40.v20210413]
2022-01-11 16:18:09 DEBUG QueuedThreadPool:1038 - ran SparkUI-41-acceptor-0@7c447c76-ServerConnector@3b90a30a{HTTP/1.1, (http/1.1)}{0.0.0.0:4040} in QueuedThreadPool[SparkUI]@6de0f580{STARTED,8<=8<=200,i=3,r=-1,q=0}[ReservedThreadExecutor@67110f71{s=0/8,p=0}]
2022-01-11 16:18:09 DEBUG AbstractHandlerContainer:167 - Graceful shutdown Server@c6634d{STOPPING}[9.4.40.v20210413] by 
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:212 - stopping Spark@3b90a30a{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:212 - stopping SelectorManager@Spark@3b90a30a{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:212 - stopping ManagedSelector@75308740{STARTED} id=3 keys=0 selected=0 updates=0
2022-01-11 16:18:09 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$CloseConnections@1b8c79a4 on ManagedSelector@75308740{STOPPING} id=3 keys=0 selected=0 updates=0
2022-01-11 16:18:09 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@75308740{STOPPING} id=3 keys=0 selected=0 updates=1
2022-01-11 16:18:09 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@127fb367 woken with none selected
2022-01-11 16:18:09 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@127fb367 woken up from select, 0/0/0 selected
2022-01-11 16:18:09 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@127fb367 processing 0 keys, 1 updates
2022-01-11 16:18:09 DEBUG ManagedSelector:558 - updateable 1
2022-01-11 16:18:09 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$CloseConnections@1b8c79a4
2022-01-11 16:18:09 DEBUG ManagedSelector:996 - Closing 0 connections on ManagedSelector@75308740{STOPPING} id=3 keys=0 selected=0 updates=0
2022-01-11 16:18:09 DEBUG ManagedSelector:587 - updates 0
2022-01-11 16:18:09 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$StopSelector@5905482c on ManagedSelector@75308740{STOPPING} id=3 keys=0 selected=0 updates=0
2022-01-11 16:18:09 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@127fb367 waiting with 0 keys
2022-01-11 16:18:09 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@75308740{STOPPING} id=3 keys=0 selected=0 updates=1
2022-01-11 16:18:09 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@127fb367 woken with none selected
2022-01-11 16:18:09 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@127fb367 woken up from select, 0/0/0 selected
2022-01-11 16:18:09 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@127fb367 processing 0 keys, 1 updates
2022-01-11 16:18:09 DEBUG ManagedSelector:558 - updateable 1
2022-01-11 16:18:09 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$StopSelector@5905482c
2022-01-11 16:18:09 DEBUG ManagedSelector:587 - updates 0
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:212 - stopping EatWhatYouKill@7ee3d262/SelectorProducer@396e6d9/PRODUCING/p=false/QueuedThreadPool[SparkUI]@6de0f580{STARTED,8<=8<=200,i=4,r=-1,q=0}[ReservedThreadExecutor@67110f71{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-11T16:18:09.9307469+05:30
2022-01-11 16:18:09 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.io.ManagedSelector$$Lambda$470/0x0000000800536840@5c20aab9 in QueuedThreadPool[SparkUI]@6de0f580{STARTED,8<=8<=200,i=4,r=-1,q=0}[ReservedThreadExecutor@67110f71{s=0/8,p=0}]
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:224 - STOPPED EatWhatYouKill@7ee3d262/SelectorProducer@396e6d9/IDLE/p=false/QueuedThreadPool[SparkUI]@6de0f580{STARTED,8<=8<=200,i=4,r=-1,q=0}[ReservedThreadExecutor@67110f71{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-11T16:18:09.9317462+05:30
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:224 - STOPPED ManagedSelector@75308740{STOPPED} id=3 keys=-1 selected=-1 updates=0
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:212 - stopping ManagedSelector@4efc25fc{STARTED} id=2 keys=0 selected=0 updates=0
2022-01-11 16:18:09 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$CloseConnections@7d6fb364 on ManagedSelector@4efc25fc{STOPPING} id=2 keys=0 selected=0 updates=0
2022-01-11 16:18:09 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@4efc25fc{STOPPING} id=2 keys=0 selected=0 updates=1
2022-01-11 16:18:09 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@9024eb0 woken with none selected
2022-01-11 16:18:09 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@9024eb0 woken up from select, 0/0/0 selected
2022-01-11 16:18:09 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@9024eb0 processing 0 keys, 1 updates
2022-01-11 16:18:09 DEBUG ManagedSelector:558 - updateable 1
2022-01-11 16:18:09 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$CloseConnections@7d6fb364
2022-01-11 16:18:09 DEBUG ManagedSelector:996 - Closing 0 connections on ManagedSelector@4efc25fc{STOPPING} id=2 keys=0 selected=0 updates=0
2022-01-11 16:18:09 DEBUG ManagedSelector:587 - updates 0
2022-01-11 16:18:09 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$StopSelector@556a434 on ManagedSelector@4efc25fc{STOPPING} id=2 keys=0 selected=0 updates=0
2022-01-11 16:18:09 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@9024eb0 waiting with 0 keys
2022-01-11 16:18:09 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@4efc25fc{STOPPING} id=2 keys=0 selected=0 updates=1
2022-01-11 16:18:09 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@9024eb0 woken with none selected
2022-01-11 16:18:09 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@9024eb0 woken up from select, 0/0/0 selected
2022-01-11 16:18:09 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@9024eb0 processing 0 keys, 1 updates
2022-01-11 16:18:09 DEBUG ManagedSelector:558 - updateable 1
2022-01-11 16:18:09 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$StopSelector@556a434
2022-01-11 16:18:09 DEBUG ManagedSelector:587 - updates 0
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:212 - stopping EatWhatYouKill@499683c4/SelectorProducer@25da615a/PRODUCING/p=false/QueuedThreadPool[SparkUI]@6de0f580{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@67110f71{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-11T16:18:09.9337456+05:30
2022-01-11 16:18:09 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.io.ManagedSelector$$Lambda$470/0x0000000800536840@d74bac4 in QueuedThreadPool[SparkUI]@6de0f580{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@67110f71{s=0/8,p=0}]
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:224 - STOPPED EatWhatYouKill@499683c4/SelectorProducer@25da615a/IDLE/p=false/QueuedThreadPool[SparkUI]@6de0f580{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@67110f71{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-11T16:18:09.9337456+05:30
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:224 - STOPPED ManagedSelector@4efc25fc{STOPPED} id=2 keys=-1 selected=-1 updates=0
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:212 - stopping ManagedSelector@2e23c180{STARTED} id=1 keys=0 selected=0 updates=0
2022-01-11 16:18:09 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$CloseConnections@5f191ff3 on ManagedSelector@2e23c180{STOPPING} id=1 keys=0 selected=0 updates=0
2022-01-11 16:18:09 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@2e23c180{STOPPING} id=1 keys=0 selected=0 updates=1
2022-01-11 16:18:09 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@4cad1b21 woken with none selected
2022-01-11 16:18:09 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@4cad1b21 woken up from select, 0/0/0 selected
2022-01-11 16:18:09 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@4cad1b21 processing 0 keys, 1 updates
2022-01-11 16:18:09 DEBUG ManagedSelector:558 - updateable 1
2022-01-11 16:18:09 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$CloseConnections@5f191ff3
2022-01-11 16:18:09 DEBUG ManagedSelector:996 - Closing 0 connections on ManagedSelector@2e23c180{STOPPING} id=1 keys=0 selected=0 updates=0
2022-01-11 16:18:09 DEBUG ManagedSelector:587 - updates 0
2022-01-11 16:18:09 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$StopSelector@2cae6814 on ManagedSelector@2e23c180{STOPPING} id=1 keys=0 selected=0 updates=0
2022-01-11 16:18:09 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@4cad1b21 waiting with 0 keys
2022-01-11 16:18:09 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@2e23c180{STOPPING} id=1 keys=0 selected=0 updates=1
2022-01-11 16:18:09 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@4cad1b21 woken with none selected
2022-01-11 16:18:09 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@4cad1b21 woken up from select, 0/0/0 selected
2022-01-11 16:18:09 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@4cad1b21 processing 0 keys, 1 updates
2022-01-11 16:18:09 DEBUG ManagedSelector:558 - updateable 1
2022-01-11 16:18:09 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$StopSelector@2cae6814
2022-01-11 16:18:09 DEBUG ManagedSelector:587 - updates 0
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:212 - stopping EatWhatYouKill@173f73e7/SelectorProducer@43a51d00/PRODUCING/p=false/QueuedThreadPool[SparkUI]@6de0f580{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@67110f71{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-11T16:18:09.9369676+05:30
2022-01-11 16:18:09 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.io.ManagedSelector$$Lambda$470/0x0000000800536840@5176d279 in QueuedThreadPool[SparkUI]@6de0f580{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@67110f71{s=0/8,p=0}]
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:224 - STOPPED EatWhatYouKill@173f73e7/SelectorProducer@43a51d00/IDLE/p=false/QueuedThreadPool[SparkUI]@6de0f580{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@67110f71{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-11T16:18:09.9369676+05:30
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:224 - STOPPED ManagedSelector@2e23c180{STOPPED} id=1 keys=-1 selected=-1 updates=0
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:212 - stopping ManagedSelector@363a3d15{STARTED} id=0 keys=0 selected=0 updates=0
2022-01-11 16:18:09 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$CloseConnections@2c5a0a76 on ManagedSelector@363a3d15{STOPPING} id=0 keys=0 selected=0 updates=0
2022-01-11 16:18:09 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@363a3d15{STOPPING} id=0 keys=0 selected=0 updates=1
2022-01-11 16:18:09 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@7c3c3ee0 woken with none selected
2022-01-11 16:18:09 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@7c3c3ee0 woken up from select, 0/0/0 selected
2022-01-11 16:18:09 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@7c3c3ee0 processing 0 keys, 1 updates
2022-01-11 16:18:09 DEBUG ManagedSelector:558 - updateable 1
2022-01-11 16:18:09 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$CloseConnections@2c5a0a76
2022-01-11 16:18:09 DEBUG ManagedSelector:996 - Closing 0 connections on ManagedSelector@363a3d15{STOPPING} id=0 keys=0 selected=0 updates=0
2022-01-11 16:18:09 DEBUG ManagedSelector:587 - updates 0
2022-01-11 16:18:09 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$StopSelector@1c9d7ccd on ManagedSelector@363a3d15{STOPPING} id=0 keys=0 selected=0 updates=0
2022-01-11 16:18:09 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@7c3c3ee0 waiting with 0 keys
2022-01-11 16:18:09 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@363a3d15{STOPPING} id=0 keys=0 selected=0 updates=1
2022-01-11 16:18:09 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@7c3c3ee0 woken with none selected
2022-01-11 16:18:09 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@7c3c3ee0 woken up from select, 0/0/0 selected
2022-01-11 16:18:09 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@7c3c3ee0 processing 0 keys, 1 updates
2022-01-11 16:18:09 DEBUG ManagedSelector:558 - updateable 1
2022-01-11 16:18:09 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$StopSelector@1c9d7ccd
2022-01-11 16:18:09 DEBUG ManagedSelector:587 - updates 0
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:212 - stopping EatWhatYouKill@446c3920/SelectorProducer@41fed14f/PRODUCING/p=false/QueuedThreadPool[SparkUI]@6de0f580{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@67110f71{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-11T16:18:09.9389667+05:30
2022-01-11 16:18:09 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.io.ManagedSelector$$Lambda$470/0x0000000800536840@e48bf9a in QueuedThreadPool[SparkUI]@6de0f580{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@67110f71{s=0/8,p=0}]
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:224 - STOPPED EatWhatYouKill@446c3920/SelectorProducer@41fed14f/IDLE/p=false/QueuedThreadPool[SparkUI]@6de0f580{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@67110f71{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-11T16:18:09.9389667+05:30
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:224 - STOPPED ManagedSelector@363a3d15{STOPPED} id=0 keys=-1 selected=-1 updates=0
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:224 - STOPPED SelectorManager@Spark@3b90a30a{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:212 - stopping HttpConnectionFactory@70f31322[HTTP/1.1]
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:224 - STOPPED HttpConnectionFactory@70f31322[HTTP/1.1]
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:212 - stopping ScheduledExecutorScheduler@69fa8e76{STARTED}
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:224 - STOPPED ScheduledExecutorScheduler@69fa8e76{STOPPED}
2022-01-11 16:18:09 INFO  AbstractConnector:381 - Stopped Spark@3b90a30a{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:224 - STOPPED Spark@3b90a30a{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-01-11 16:18:09 DEBUG AbstractHandler:107 - stopping Server@c6634d{STOPPING}[9.4.40.v20210413]
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:212 - stopping ContextHandlerCollection@4cb0a000{STARTED}
2022-01-11 16:18:09 DEBUG AbstractHandler:107 - stopping ContextHandlerCollection@4cb0a000{STOPPING}
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:224 - STOPPED ContextHandlerCollection@4cb0a000{STOPPED}
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:212 - stopping ErrorHandler@29528a22{STARTED}
2022-01-11 16:18:09 DEBUG AbstractHandler:107 - stopping ErrorHandler@29528a22{STOPPING}
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:224 - STOPPED ErrorHandler@29528a22{STOPPED}
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:212 - stopping QueuedThreadPool[SparkUI]@6de0f580{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@67110f71{s=0/8,p=0}]
2022-01-11 16:18:09 DEBUG QueuedThreadPool:224 - Stopping QueuedThreadPool[SparkUI]@6de0f580{STOPPING,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@67110f71{s=0/8,p=0}]
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:212 - stopping ReservedThreadExecutor@67110f71{s=0/8,p=0}
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:224 - STOPPED ReservedThreadExecutor@67110f71{s=-1/8,p=0}
2022-01-11 16:18:09 DEBUG QueuedThreadPool:317 - Waiting for Thread[SparkUI-38,5,main] for 14999
2022-01-11 16:18:09 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$460/0x000000080051dc40@134eec91 in QueuedThreadPool[SparkUI]@6de0f580{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-11 16:18:09 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$460/0x000000080051dc40@134eec91 in QueuedThreadPool[SparkUI]@6de0f580{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-11 16:18:09 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$460/0x000000080051dc40@134eec91 in QueuedThreadPool[SparkUI]@6de0f580{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-11 16:18:09 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$460/0x000000080051dc40@134eec91 in QueuedThreadPool[SparkUI]@6de0f580{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-11 16:18:09 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$460/0x000000080051dc40@134eec91 in QueuedThreadPool[SparkUI]@6de0f580{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-11 16:18:09 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$460/0x000000080051dc40@134eec91 in QueuedThreadPool[SparkUI]@6de0f580{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-11 16:18:09 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$460/0x000000080051dc40@134eec91 in QueuedThreadPool[SparkUI]@6de0f580{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-11 16:18:09 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$460/0x000000080051dc40@134eec91 in QueuedThreadPool[SparkUI]@6de0f580{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-11 16:18:09 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$460/0x000000080051dc40@134eec91 in QueuedThreadPool[SparkUI]@6de0f580{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-11 16:18:09 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$460/0x000000080051dc40@134eec91 in QueuedThreadPool[SparkUI]@6de0f580{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-11 16:18:09 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$460/0x000000080051dc40@134eec91 in QueuedThreadPool[SparkUI]@6de0f580{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-11 16:18:09 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$460/0x000000080051dc40@134eec91 in QueuedThreadPool[SparkUI]@6de0f580{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-11 16:18:09 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$460/0x000000080051dc40@134eec91 in QueuedThreadPool[SparkUI]@6de0f580{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-11 16:18:09 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$460/0x000000080051dc40@134eec91 in QueuedThreadPool[SparkUI]@6de0f580{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-11 16:18:09 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$460/0x000000080051dc40@134eec91 in QueuedThreadPool[SparkUI]@6de0f580{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-11 16:18:09 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-38,5,main] exited for QueuedThreadPool[SparkUI]@6de0f580{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-11 16:18:09 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-42,5,main] exited for QueuedThreadPool[SparkUI]@6de0f580{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-11 16:18:09 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-39,5,main] exited for QueuedThreadPool[SparkUI]@6de0f580{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-11 16:18:09 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-43,5,main] exited for QueuedThreadPool[SparkUI]@6de0f580{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-11 16:18:09 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-41,5,main] exited for QueuedThreadPool[SparkUI]@6de0f580{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-11 16:18:09 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-40,5,main] exited for QueuedThreadPool[SparkUI]@6de0f580{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-11 16:18:09 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$460/0x000000080051dc40@134eec91 in QueuedThreadPool[SparkUI]@6de0f580{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-11 16:18:09 DEBUG QueuedThreadPool:317 - Waiting for Thread[SparkUI-37,5,main] for 14998
2022-01-11 16:18:09 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-37,5,main] exited for QueuedThreadPool[SparkUI]@6de0f580{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-11 16:18:09 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-44,5,main] exited for QueuedThreadPool[SparkUI]@6de0f580{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-11 16:18:09 DEBUG QueuedThreadPool:317 - Waiting for Thread[SparkUI-44,5,main] for 14997
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:224 - STOPPED QueuedThreadPool[SparkUI]@6de0f580{STOPPED,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-11 16:18:09 DEBUG AbstractLifeCycle:224 - STOPPED Server@c6634d{STOPPED}[9.4.40.v20210413]
2022-01-11 16:18:09 INFO  SparkUI:57 - Stopped Spark web UI at http://host.docker.internal:4040
2022-01-11 16:18:09 INFO  MapOutputTrackerMasterEndpoint:57 - MapOutputTrackerMasterEndpoint stopped!
2022-01-11 16:18:11 INFO  MemoryStore:57 - MemoryStore cleared
2022-01-11 16:18:11 INFO  BlockManager:57 - BlockManager stopped
2022-01-11 16:18:11 INFO  BlockManagerMaster:57 - BlockManagerMaster stopped
2022-01-11 16:18:11 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:57 - OutputCommitCoordinator stopped!
2022-01-11 16:18:11 INFO  SparkContext:57 - Successfully stopped SparkContext
2022-01-11 16:18:11 INFO  ShutdownHookManager:57 - Shutdown hook called
2022-01-11 16:18:11 INFO  ShutdownHookManager:57 - Deleting directory C:\Users\Rahul Kabothula\AppData\Local\Temp\spark-dd9e69df-f95c-4307-ba56-859bde9b2703
2022-01-11 16:18:11 DEBUG ShutdownHookManager:97 - Completed shutdown in 1.468 seconds; Timeouts: 0
2022-01-11 16:18:11 DEBUG ShutdownHookManager:154 - ShutdownHookManger completed shutdown.
