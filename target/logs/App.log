2022-01-12 15:09:47 INFO  SparkContext:57 - Running Spark version 3.1.2
2022-01-12 15:09:47 DEBUG MutableMetricsFactory:43 - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of successful kerberos logins and latency (milliseconds)"})
2022-01-12 15:09:47 DEBUG MutableMetricsFactory:43 - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={"Rate of failed kerberos logins and latency (milliseconds)"})
2022-01-12 15:09:47 DEBUG MutableMetricsFactory:43 - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={"GetGroups"})
2022-01-12 15:09:47 DEBUG MutableMetricsFactory:43 - field private org.apache.hadoop.metrics2.lib.MutableGaugeLong org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailuresTotal with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since startup"})
2022-01-12 15:09:47 DEBUG MutableMetricsFactory:43 - field private org.apache.hadoop.metrics2.lib.MutableGaugeInt org.apache.hadoop.security.UserGroupInformation$UgiMetrics.renewalFailures with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName="Ops", always=false, valueName="Time", about="", interval=10, type=DEFAULT, value={"Renewal failures since last successful login"})
2022-01-12 15:09:47 DEBUG MetricsSystemImpl:231 - UgiMetrics, User and group related metrics
2022-01-12 15:09:47 DEBUG SecurityUtil:124 - Setting hadoop.security.token.service.use_ip to true
2022-01-12 15:09:47 DEBUG Groups:449 -  Creating new Groups object
2022-01-12 15:09:47 DEBUG NativeCodeLoader:44 - Trying to load the custom-built native-hadoop library...
2022-01-12 15:09:47 DEBUG NativeCodeLoader:48 - Loaded the native-hadoop library
2022-01-12 15:09:47 DEBUG JniBasedUnixGroupsMapping:50 - Using JniBasedUnixGroupsMapping for Group resolution
2022-01-12 15:09:47 DEBUG JniBasedUnixGroupsMappingWithFallback:45 - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
2022-01-12 15:09:47 DEBUG Groups:151 - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2022-01-12 15:09:47 DEBUG UserGroupInformation:254 - hadoop login
2022-01-12 15:09:47 DEBUG UserGroupInformation:187 - hadoop login commit
2022-01-12 15:09:47 DEBUG UserGroupInformation:215 - using local user:NTUserPrincipal: Rahul Kabothula
2022-01-12 15:09:47 DEBUG UserGroupInformation:221 - Using user: "NTUserPrincipal: Rahul Kabothula" with name Rahul Kabothula
2022-01-12 15:09:47 DEBUG UserGroupInformation:235 - User entry: "Rahul Kabothula"
2022-01-12 15:09:47 DEBUG UserGroupInformation:766 - UGI loginUser:Rahul Kabothula (auth:SIMPLE)
2022-01-12 15:09:47 INFO  ResourceUtils:57 - ==============================================================
2022-01-12 15:09:47 INFO  ResourceUtils:57 - No custom resources configured for spark.driver.
2022-01-12 15:09:47 INFO  ResourceUtils:57 - ==============================================================
2022-01-12 15:09:47 INFO  SparkContext:57 - Submitted application: 36a8e928-596d-405a-8adf-cf95744d9fb6
2022-01-12 15:09:47 INFO  ResourceProfile:57 - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2022-01-12 15:09:47 INFO  ResourceProfile:57 - Limiting resource is cpu
2022-01-12 15:09:47 INFO  ResourceProfileManager:57 - Added ResourceProfile id: 0
2022-01-12 15:09:47 INFO  SecurityManager:57 - Changing view acls to: Rahul Kabothula
2022-01-12 15:09:47 INFO  SecurityManager:57 - Changing modify acls to: Rahul Kabothula
2022-01-12 15:09:47 INFO  SecurityManager:57 - Changing view acls groups to: 
2022-01-12 15:09:47 INFO  SecurityManager:57 - Changing modify acls groups to: 
2022-01-12 15:09:47 INFO  SecurityManager:57 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Rahul Kabothula); groups with view permissions: Set(); users  with modify permissions: Set(Rahul Kabothula); groups with modify permissions: Set()
2022-01-12 15:09:48 DEBUG InternalLoggerFactory:45 - Using SLF4J as the default logging framework
2022-01-12 15:09:48 DEBUG InternalThreadLocalMap:56 - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2022-01-12 15:09:48 DEBUG InternalThreadLocalMap:59 - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2022-01-12 15:09:48 DEBUG MultithreadEventLoopGroup:44 - -Dio.netty.eventLoopThreads: 16
2022-01-12 15:09:48 DEBUG NioEventLoop:106 - -Dio.netty.noKeySetOptimization: false
2022-01-12 15:09:48 DEBUG NioEventLoop:107 - -Dio.netty.selectorAutoRebuildThreshold: 512
2022-01-12 15:09:48 DEBUG PlatformDependent:1015 - Platform: Windows
2022-01-12 15:09:48 DEBUG PlatformDependent0:408 - -Dio.netty.noUnsafe: false
2022-01-12 15:09:48 DEBUG PlatformDependent0:876 - Java version: 11
2022-01-12 15:09:48 DEBUG PlatformDependent0:125 - sun.misc.Unsafe.theUnsafe: available
2022-01-12 15:09:48 DEBUG PlatformDependent0:149 - sun.misc.Unsafe.copyMemory: available
2022-01-12 15:09:48 DEBUG PlatformDependent0:187 - java.nio.Buffer.address: available
2022-01-12 15:09:48 DEBUG PlatformDependent0:261 - direct buffer constructor: unavailable
java.lang.UnsupportedOperationException: Reflective setAccessible(true) disabled
	at io.netty.util.internal.ReflectionUtil.trySetAccessible(ReflectionUtil.java:31)
	at io.netty.util.internal.PlatformDependent0$4.run(PlatformDependent0.java:233)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:227)
	at io.netty.util.internal.PlatformDependent.isAndroid(PlatformDependent.java:289)
	at io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:92)
	at io.netty.channel.nio.NioEventLoop.newTaskQueue0(NioEventLoop.java:279)
	at io.netty.channel.nio.NioEventLoop.newTaskQueue(NioEventLoop.java:150)
	at io.netty.channel.nio.NioEventLoop.<init>(NioEventLoop.java:138)
	at io.netty.channel.nio.NioEventLoopGroup.newChild(NioEventLoopGroup.java:146)
	at io.netty.channel.nio.NioEventLoopGroup.newChild(NioEventLoopGroup.java:37)
	at io.netty.util.concurrent.MultithreadEventExecutorGroup.<init>(MultithreadEventExecutorGroup.java:84)
	at io.netty.util.concurrent.MultithreadEventExecutorGroup.<init>(MultithreadEventExecutorGroup.java:58)
	at io.netty.util.concurrent.MultithreadEventExecutorGroup.<init>(MultithreadEventExecutorGroup.java:47)
	at io.netty.channel.MultithreadEventLoopGroup.<init>(MultithreadEventLoopGroup.java:59)
	at io.netty.channel.nio.NioEventLoopGroup.<init>(NioEventLoopGroup.java:86)
	at io.netty.channel.nio.NioEventLoopGroup.<init>(NioEventLoopGroup.java:81)
	at io.netty.channel.nio.NioEventLoopGroup.<init>(NioEventLoopGroup.java:68)
	at org.apache.spark.network.util.NettyUtils.createEventLoop(NettyUtils.java:66)
	at org.apache.spark.network.client.TransportClientFactory.<init>(TransportClientFactory.java:106)
	at org.apache.spark.network.TransportContext.createClientFactory(TransportContext.java:142)
	at org.apache.spark.rpc.netty.NettyRpcEnv.<init>(NettyRpcEnv.scala:77)
	at org.apache.spark.rpc.netty.NettyRpcEnvFactory.create(NettyRpcEnv.scala:493)
	at org.apache.spark.rpc.RpcEnv$.create(RpcEnv.scala:57)
	at org.apache.spark.SparkEnv$.create(SparkEnv.scala:266)
	at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:189)
	at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:277)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:458)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2672)
	at org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:945)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:939)
	at Util.getSparkSession(Util.java:12)
	at Datasets.<init>(Datasets.java:6)
	at LoadTesting.<init>(LoadTesting.java:8)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:250)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:260)
	at org.junit.runners.BlockJUnit4ClassRunner$2.runReflectiveCall(BlockJUnit4ClassRunner.java:309)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:235)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:54)
2022-01-12 15:09:48 DEBUG PlatformDependent0:326 - java.nio.Bits.unaligned: available, true
2022-01-12 15:09:48 DEBUG PlatformDependent0:385 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable
java.lang.IllegalAccessException: class io.netty.util.internal.PlatformDependent0$6 cannot access class jdk.internal.misc.Unsafe (in module java.base) because module java.base does not export jdk.internal.misc to unnamed module @19e7a160
	at java.base/jdk.internal.reflect.Reflection.newIllegalAccessException(Reflection.java:361)
	at java.base/java.lang.reflect.AccessibleObject.checkAccess(AccessibleObject.java:591)
	at java.base/java.lang.reflect.Method.invoke(Method.java:558)
	at io.netty.util.internal.PlatformDependent0$6.run(PlatformDependent0.java:347)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at io.netty.util.internal.PlatformDependent0.<clinit>(PlatformDependent0.java:338)
	at io.netty.util.internal.PlatformDependent.isAndroid(PlatformDependent.java:289)
	at io.netty.util.internal.PlatformDependent.<clinit>(PlatformDependent.java:92)
	at io.netty.channel.nio.NioEventLoop.newTaskQueue0(NioEventLoop.java:279)
	at io.netty.channel.nio.NioEventLoop.newTaskQueue(NioEventLoop.java:150)
	at io.netty.channel.nio.NioEventLoop.<init>(NioEventLoop.java:138)
	at io.netty.channel.nio.NioEventLoopGroup.newChild(NioEventLoopGroup.java:146)
	at io.netty.channel.nio.NioEventLoopGroup.newChild(NioEventLoopGroup.java:37)
	at io.netty.util.concurrent.MultithreadEventExecutorGroup.<init>(MultithreadEventExecutorGroup.java:84)
	at io.netty.util.concurrent.MultithreadEventExecutorGroup.<init>(MultithreadEventExecutorGroup.java:58)
	at io.netty.util.concurrent.MultithreadEventExecutorGroup.<init>(MultithreadEventExecutorGroup.java:47)
	at io.netty.channel.MultithreadEventLoopGroup.<init>(MultithreadEventLoopGroup.java:59)
	at io.netty.channel.nio.NioEventLoopGroup.<init>(NioEventLoopGroup.java:86)
	at io.netty.channel.nio.NioEventLoopGroup.<init>(NioEventLoopGroup.java:81)
	at io.netty.channel.nio.NioEventLoopGroup.<init>(NioEventLoopGroup.java:68)
	at org.apache.spark.network.util.NettyUtils.createEventLoop(NettyUtils.java:66)
	at org.apache.spark.network.client.TransportClientFactory.<init>(TransportClientFactory.java:106)
	at org.apache.spark.network.TransportContext.createClientFactory(TransportContext.java:142)
	at org.apache.spark.rpc.netty.NettyRpcEnv.<init>(NettyRpcEnv.scala:77)
	at org.apache.spark.rpc.netty.NettyRpcEnvFactory.create(NettyRpcEnv.scala:493)
	at org.apache.spark.rpc.RpcEnv$.create(RpcEnv.scala:57)
	at org.apache.spark.SparkEnv$.create(SparkEnv.scala:266)
	at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:189)
	at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:277)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:458)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2672)
	at org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$2(SparkSession.scala:945)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:939)
	at Util.getSparkSession(Util.java:12)
	at Datasets.<init>(Datasets.java:6)
	at LoadTesting.<init>(LoadTesting.java:8)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:250)
	at org.junit.runners.BlockJUnit4ClassRunner.createTest(BlockJUnit4ClassRunner.java:260)
	at org.junit.runners.BlockJUnit4ClassRunner$2.runReflectiveCall(BlockJUnit4ClassRunner.java:309)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:235)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:54)
2022-01-12 15:09:48 DEBUG PlatformDependent0:398 - java.nio.DirectByteBuffer.<init>(long, int): unavailable
2022-01-12 15:09:48 DEBUG PlatformDependent:1058 - sun.misc.Unsafe: available
2022-01-12 15:09:48 DEBUG PlatformDependent:1158 - maxDirectMemory: 4227858432 bytes (maybe)
2022-01-12 15:09:48 DEBUG PlatformDependent:1177 - -Dio.netty.tmpdir: C:\Users\RAHULK~1\AppData\Local\Temp (java.io.tmpdir)
2022-01-12 15:09:48 DEBUG PlatformDependent:1256 - -Dio.netty.bitMode: 64 (sun.arch.data.model)
2022-01-12 15:09:48 DEBUG PlatformDependent:177 - -Dio.netty.maxDirectMemory: -1 bytes
2022-01-12 15:09:48 DEBUG PlatformDependent:184 - -Dio.netty.uninitializedArrayAllocationThreshold: -1
2022-01-12 15:09:48 DEBUG CleanerJava9:71 - java.nio.ByteBuffer.cleaner(): available
2022-01-12 15:09:48 DEBUG PlatformDependent:204 - -Dio.netty.noPreferDirect: false
2022-01-12 15:09:48 DEBUG PlatformDependent:919 - org.jctools-core.MpscChunkedArrayQueue: available
2022-01-12 15:09:48 DEBUG ResourceLeakDetector:130 - -Dio.netty.leakDetection.level: simple
2022-01-12 15:09:48 DEBUG ResourceLeakDetector:131 - -Dio.netty.leakDetection.targetRecords: 4
2022-01-12 15:09:48 DEBUG PooledByteBufAllocator:156 - -Dio.netty.allocator.numHeapArenas: 16
2022-01-12 15:09:48 DEBUG PooledByteBufAllocator:157 - -Dio.netty.allocator.numDirectArenas: 16
2022-01-12 15:09:48 DEBUG PooledByteBufAllocator:159 - -Dio.netty.allocator.pageSize: 8192
2022-01-12 15:09:48 DEBUG PooledByteBufAllocator:164 - -Dio.netty.allocator.maxOrder: 11
2022-01-12 15:09:48 DEBUG PooledByteBufAllocator:168 - -Dio.netty.allocator.chunkSize: 16777216
2022-01-12 15:09:48 DEBUG PooledByteBufAllocator:169 - -Dio.netty.allocator.tinyCacheSize: 512
2022-01-12 15:09:48 DEBUG PooledByteBufAllocator:170 - -Dio.netty.allocator.smallCacheSize: 256
2022-01-12 15:09:48 DEBUG PooledByteBufAllocator:171 - -Dio.netty.allocator.normalCacheSize: 64
2022-01-12 15:09:48 DEBUG PooledByteBufAllocator:172 - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2022-01-12 15:09:48 DEBUG PooledByteBufAllocator:173 - -Dio.netty.allocator.cacheTrimInterval: 8192
2022-01-12 15:09:48 DEBUG PooledByteBufAllocator:174 - -Dio.netty.allocator.cacheTrimIntervalMillis: 0
2022-01-12 15:09:48 DEBUG PooledByteBufAllocator:175 - -Dio.netty.allocator.useCacheForAllThreads: true
2022-01-12 15:09:48 DEBUG PooledByteBufAllocator:176 - -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
2022-01-12 15:09:48 DEBUG DefaultChannelId:79 - -Dio.netty.processId: 16796 (auto-detected)
2022-01-12 15:09:48 DEBUG NetUtil:139 - -Djava.net.preferIPv4Stack: false
2022-01-12 15:09:48 DEBUG NetUtil:140 - -Djava.net.preferIPv6Addresses: false
2022-01-12 15:09:48 DEBUG NetUtil:224 - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
2022-01-12 15:09:48 DEBUG NetUtil:289 - Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
2022-01-12 15:09:48 DEBUG DefaultChannelId:101 - -Dio.netty.machineId: 58:6c:25:ff:fe:22:7e:af (auto-detected)
2022-01-12 15:09:48 DEBUG ByteBufUtil:86 - -Dio.netty.allocator.type: pooled
2022-01-12 15:09:48 DEBUG ByteBufUtil:95 - -Dio.netty.threadLocalDirectBufferSize: 0
2022-01-12 15:09:48 DEBUG ByteBufUtil:98 - -Dio.netty.maxThreadLocalCharBufferSize: 16384
2022-01-12 15:09:48 DEBUG TransportServer:153 - Shuffle server started on port: 64105
2022-01-12 15:09:48 INFO  Utils:57 - Successfully started service 'sparkDriver' on port 64105.
2022-01-12 15:09:48 DEBUG SparkEnv:61 - Using serializer: class org.apache.spark.serializer.JavaSerializer
2022-01-12 15:09:48 INFO  SparkEnv:57 - Registering MapOutputTracker
2022-01-12 15:09:48 DEBUG MapOutputTrackerMasterEndpoint:61 - init
2022-01-12 15:09:49 INFO  SparkEnv:57 - Registering BlockManagerMaster
2022-01-12 15:09:49 INFO  BlockManagerMasterEndpoint:57 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022-01-12 15:09:49 INFO  BlockManagerMasterEndpoint:57 - BlockManagerMasterEndpoint up
2022-01-12 15:09:49 INFO  SparkEnv:57 - Registering BlockManagerMasterHeartbeat
2022-01-12 15:09:49 INFO  DiskBlockManager:57 - Created local directory at C:\Users\Rahul Kabothula\AppData\Local\Temp\blockmgr-a13738c4-3f71-40bd-b7e2-76df61097383
2022-01-12 15:09:49 DEBUG DiskBlockManager:61 - Adding shutdown hook
2022-01-12 15:09:49 DEBUG ShutdownHookManager:61 - Adding shutdown hook
2022-01-12 15:09:49 INFO  MemoryStore:57 - MemoryStore started with capacity 2.2 GiB
2022-01-12 15:09:49 INFO  SparkEnv:57 - Registering OutputCommitCoordinator
2022-01-12 15:09:49 DEBUG OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:61 - init
2022-01-12 15:09:49 DEBUG SecurityManager:61 - Created SSL options for ui: SSLOptions{enabled=false, port=None, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2022-01-12 15:09:49 DEBUG log:159 - Logging to org.slf4j.impl.Log4jLoggerAdapter(org.sparkproject.jetty.util.log) via org.sparkproject.jetty.util.log.Slf4jLog
2022-01-12 15:09:49 INFO  log:169 - Logging initialized @3975ms to org.sparkproject.jetty.util.log.Slf4jLog
2022-01-12 15:09:49 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@21f8e55f
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@1ffcf674{/,null,STOPPED} added {ServletHandler@c808207{STOPPED},MANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@c808207{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-5f18f9d2==org.apache.spark.ui.JettyUtils$$anon$1@84970c87{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@c808207{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-5f18f9d2,POJO}
2022-01-12 15:09:49 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@38018b62
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@ce9b9a9{/,null,STOPPED} added {ServletHandler@4ad3d266{STOPPED},MANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@4ad3d266{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-3533df16==org.apache.spark.ui.JettyUtils$$anon$1@97e65117{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@4ad3d266{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-3533df16,POJO}
2022-01-12 15:09:49 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@270b6b5e
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@7e94d093{/,null,STOPPED} added {ServletHandler@7c6189d5{STOPPED},MANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@7c6189d5{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-4248e66b==org.apache.spark.ui.JettyUtils$$anon$1@630fdb4d{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@7c6189d5{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-4248e66b,POJO}
2022-01-12 15:09:49 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@3e6534e7
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@66ad7bf0{/,null,STOPPED} added {ServletHandler@167279d1{STOPPED},MANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@167279d1{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-138caeca==org.apache.spark.ui.JettyUtils$$anon$1@6982c97d{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@167279d1{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-138caeca,POJO}
2022-01-12 15:09:49 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@778db7c5
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@681e144{/,null,STOPPED} added {ServletHandler@2875b016{STOPPED},MANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@2875b016{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-72ee5d84==org.apache.spark.ui.JettyUtils$$anon$1@f0b5d4f4{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@2875b016{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-72ee5d84,POJO}
2022-01-12 15:09:49 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@68c7ef83
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@6145b81e{/,null,STOPPED} added {ServletHandler@64355120{STOPPED},MANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@64355120{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-64b7225f==org.apache.spark.ui.JettyUtils$$anon$1@eaf84292{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@64355120{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-64b7225f,POJO}
2022-01-12 15:09:49 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@7f92b990
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@31e04b13{/,null,STOPPED} added {ServletHandler@6c1832aa{STOPPED},MANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@6c1832aa{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-4beeb0e==org.apache.spark.ui.JettyUtils$$anon$1@1e13221b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@6c1832aa{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-4beeb0e,POJO}
2022-01-12 15:09:49 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@6e8a9c30
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@5d01ea21{/,null,STOPPED} added {ServletHandler@70211e49{STOPPED},MANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@70211e49{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-3b46dd8==org.apache.spark.ui.JettyUtils$$anon$1@e6651759{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@70211e49{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-3b46dd8,POJO}
2022-01-12 15:09:49 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@6be7bf6d
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@134c370e{/,null,STOPPED} added {ServletHandler@33364212{STOPPED},MANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@33364212{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-2216effc==org.apache.spark.ui.JettyUtils$$anon$1@8e1382b1{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@33364212{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-2216effc,POJO}
2022-01-12 15:09:49 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@745c2004
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@6da9dc6{/,null,STOPPED} added {ServletHandler@7fd69dd{STOPPED},MANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@7fd69dd{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-12010fd1==org.apache.spark.ui.JettyUtils$$anon$1@241eef93{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@7fd69dd{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-12010fd1,POJO}
2022-01-12 15:09:49 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@661c46bc
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@37864b77{/,null,STOPPED} added {ServletHandler@2b98b3bb{STOPPED},MANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@2b98b3bb{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-540b0448==org.apache.spark.ui.JettyUtils$$anon$1@3021d7c7{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@2b98b3bb{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-540b0448,POJO}
2022-01-12 15:09:49 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@50a691d3
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@557eb543{/,null,STOPPED} added {ServletHandler@3b95d13c{STOPPED},MANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@3b95d13c{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-3730ab42==org.apache.spark.ui.JettyUtils$$anon$1@187154e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@3b95d13c{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-3730ab42,POJO}
2022-01-12 15:09:49 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@7308ffff
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@6601cc93{/,null,STOPPED} added {ServletHandler@54d901aa{STOPPED},MANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@54d901aa{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-63716833==org.apache.spark.ui.JettyUtils$$anon$1@6c5eff27{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@54d901aa{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-63716833,POJO}
2022-01-12 15:09:49 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@573284a5
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@3fbfbf84{/,null,STOPPED} added {ServletHandler@23f72d88{STOPPED},MANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@23f72d88{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-4bafe935==org.apache.spark.ui.JettyUtils$$anon$1@9d8d4f57{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@23f72d88{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-4bafe935,POJO}
2022-01-12 15:09:49 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@288cdaab
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@23b3aa8c{/,null,STOPPED} added {ServletHandler@99407c2{STOPPED},MANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@99407c2{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-6c796cc1==org.apache.spark.ui.JettyUtils$$anon$1@57fb7e98{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@99407c2{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-6c796cc1,POJO}
2022-01-12 15:09:49 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@226eba67
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@1cb7936c{/,null,STOPPED} added {ServletHandler@35342d2f{STOPPED},MANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@35342d2f{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-128c502c==org.apache.spark.ui.JettyUtils$$anon$1@3487c106{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@35342d2f{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-128c502c,POJO}
2022-01-12 15:09:49 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@3c4262d1
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@100c567f{/,null,STOPPED} added {ServletHandler@30c0d731{STOPPED},MANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@30c0d731{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-6d5037a9==org.apache.spark.ui.JettyUtils$$anon$1@88f73293{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@30c0d731{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-6d5037a9,POJO}
2022-01-12 15:09:49 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@422b8438
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@30669dac{/,null,STOPPED} added {ServletHandler@629adce{STOPPED},MANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@629adce{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-6a282fdd==org.apache.spark.ui.JettyUtils$$anon$1@e596ef93{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@629adce{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-6a282fdd,POJO}
2022-01-12 15:09:49 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@70331432
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@3bbf9027{/,null,STOPPED} added {ServletHandler@10c2064a{STOPPED},MANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@10c2064a{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-70e13fa==org.apache.spark.ui.JettyUtils$$anon$1@675b379b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@10c2064a{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-70e13fa,POJO}
2022-01-12 15:09:49 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@6ff415ad
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@280d9edc{/,null,STOPPED} added {ServletHandler@28fd3dc1{STOPPED},MANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@28fd3dc1{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-5f9b6ae7==org.apache.spark.ui.JettyUtils$$anon$1@94787125{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@28fd3dc1{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-5f9b6ae7,POJO}
2022-01-12 15:09:49 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@5432c277
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@15e0fe05{/,null,STOPPED} added {ServletHandler@1128620c{STOPPED},MANAGED}
2022-01-12 15:09:49 DEBUG PreEncodedHttpField:61 - HttpField encoders loaded: []
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@1128620c{STOPPED} added {org.sparkproject.jetty.servlet.DefaultServlet-68f32020==org.sparkproject.jetty.servlet.DefaultServlet@10113d3{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@1128620c{STOPPED} added {[/]=>org.sparkproject.jetty.servlet.DefaultServlet-68f32020,POJO}
2022-01-12 15:09:49 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@22590e3e
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@53dad875{/,null,STOPPED} added {ServletHandler@5f780a86{STOPPED},MANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@5f780a86{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$2-446c3920==org.apache.spark.ui.JettyUtils$$anon$2@c6d6b6de{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@5f780a86{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-446c3920,POJO}
2022-01-12 15:09:49 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@118102ee
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@48cd9a2c{/,null,STOPPED} added {ServletHandler@771d1ffb{STOPPED},MANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@771d1ffb{STOPPED} added {org.glassfish.jersey.servlet.ServletContainer-41fed14f==org.glassfish.jersey.servlet.ServletContainer@c694ca49{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@771d1ffb{STOPPED} added {[/*]=>org.glassfish.jersey.servlet.ServletContainer-41fed14f,POJO}
2022-01-12 15:09:49 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@7e736350
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@36b310aa{/,null,STOPPED} added {ServletHandler@76c387f9{STOPPED},MANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@76c387f9{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$2-3874b815==org.apache.spark.ui.JettyUtils$$anon$2@31c25889{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@76c387f9{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-3874b815,POJO}
2022-01-12 15:09:49 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@736048ed
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@1976f537{/,null,STOPPED} added {ServletHandler@45f421c{STOPPED},MANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@45f421c{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$2-1816e24a==org.apache.spark.ui.JettyUtils$$anon$2@57e06133{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@45f421c{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$2-1816e24a,POJO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - QueuedThreadPool[qtp239648666]@e48bf9a{STOPPED,8<=0<=200,i=0,r=-1,q=0}[NO_TRY] added {org.sparkproject.jetty.util.thread.ThreadPoolBudget@4aaae508,POJO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - Server@4c59e45e{STOPPED}[9.4.40.v20210413] added {QueuedThreadPool[SparkUI]@e48bf9a{STOPPED,8<=0<=200,i=0,r=-1,q=0}[NO_TRY],AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - Server@4c59e45e{STOPPED}[9.4.40.v20210413] added {ErrorHandler@5a00eb1e{STOPPED},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - Server@4c59e45e{STOPPED}[9.4.40.v20210413] added {ContextHandlerCollection@39c1fe0b{STOPPED},MANAGED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting Server@4c59e45e{STOPPED}[9.4.40.v20210413]
2022-01-12 15:09:49 INFO  Server:375 - jetty-9.4.40.v20210413; built: 2021-04-13T20:42:42.668Z; git: b881a572662e1943a14ae12e7e1207989f218b74; jvm 11.0.6+8-LTS
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting Server@4c59e45e{STARTING}[9.4.40.v20210413]
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting QueuedThreadPool[SparkUI]@e48bf9a{STOPPED,8<=0<=200,i=0,r=-1,q=0}[NO_TRY]
2022-01-12 15:09:49 DEBUG ReservedThreadExecutor:85 - ReservedThreadExecutor@6fca5907{s=0/8,p=0}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - QueuedThreadPool[SparkUI]@e48bf9a{STARTING,8<=0<=200,i=0,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}] added {ReservedThreadExecutor@6fca5907{s=0/8,p=0},AUTO}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ReservedThreadExecutor@6fca5907{s=0/8,p=0}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4131ms ReservedThreadExecutor@6fca5907{s=0/8,p=0}
2022-01-12 15:09:49 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-37,5,main]
2022-01-12 15:09:49 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-38,5,main]
2022-01-12 15:09:49 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-39,5,main]
2022-01-12 15:09:49 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-40,5,main]
2022-01-12 15:09:49 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@e48bf9a{STARTING,8<=3<=200,i=3,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}]
2022-01-12 15:09:49 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-41,5,main]
2022-01-12 15:09:49 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@e48bf9a{STARTING,8<=5<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}]
2022-01-12 15:09:49 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@e48bf9a{STARTING,8<=3<=200,i=3,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}]
2022-01-12 15:09:49 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-42,5,main]
2022-01-12 15:09:49 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@e48bf9a{STARTING,8<=4<=200,i=4,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}]
2022-01-12 15:09:49 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@e48bf9a{STARTING,8<=6<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}]
2022-01-12 15:09:49 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-43,5,main]
2022-01-12 15:09:49 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@e48bf9a{STARTING,8<=7<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}]
2022-01-12 15:09:49 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-44,5,main]
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4139ms QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}]
2022-01-12 15:09:49 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}]
2022-01-12 15:09:49 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}]
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ErrorHandler@5a00eb1e{STOPPED}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting ErrorHandler@5a00eb1e{STARTING}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4140ms ErrorHandler@5a00eb1e{STARTED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ContextHandlerCollection@39c1fe0b{STOPPED}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting ContextHandlerCollection@39c1fe0b{STARTING}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4140ms ContextHandlerCollection@39c1fe0b{STARTED}
2022-01-12 15:09:49 INFO  Server:415 - Started @4141ms
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4141ms Server@4c59e45e{STARTED}[9.4.40.v20210413]
2022-01-12 15:09:49 DEBUG JettyUtils:61 - Using requestHeaderSize: 8192
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - HttpConnectionFactory@4eb45fec[HTTP/1.1] added {HttpConfiguration@211febf3{32768/8192,8192/8192,https://:0,[]},POJO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServerConnector@1e530163{null, ()}{0.0.0.0:0} added {Server@4c59e45e{STARTED}[9.4.40.v20210413],UNMANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServerConnector@1e530163{null, ()}{0.0.0.0:0} added {QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}],UNMANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServerConnector@1e530163{null, ()}{0.0.0.0:0} added {ScheduledExecutorScheduler@14d8444b{STOPPED},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServerConnector@1e530163{null, ()}{0.0.0.0:0} added {org.sparkproject.jetty.io.ArrayByteBufferPool@71466383,POJO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServerConnector@1e530163{null, (http/1.1)}{0.0.0.0:0} added {HttpConnectionFactory@4eb45fec[HTTP/1.1],AUTO}
2022-01-12 15:09:49 DEBUG AbstractConnector:484 - ServerConnector@1e530163{HTTP/1.1, (http/1.1)}{0.0.0.0:0} added HttpConnectionFactory@4eb45fec[HTTP/1.1]
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServerConnector@1e530163{HTTP/1.1, (http/1.1)}{0.0.0.0:0} added {SelectorManager@ServerConnector@1e530163{HTTP/1.1, (http/1.1)}{0.0.0.0:0},MANAGED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ServerConnector@1e530163{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServerConnector@1e530163{HTTP/1.1, (http/1.1)}{0.0.0.0:4040} added {sun.nio.ch.ServerSocketChannelImpl[/0:0:0:0:0:0:0:0:4040],POJO}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ScheduledExecutorScheduler@14d8444b{STOPPED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4172ms ScheduledExecutorScheduler@14d8444b{STARTED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting HttpConnectionFactory@4eb45fec[HTTP/1.1]
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4172ms HttpConnectionFactory@4eb45fec[HTTP/1.1]
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting SelectorManager@ServerConnector@1e530163{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@3c35c345/SelectorProducer@ad9e63e/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:49.5689014+05:30 added {SelectorProducer@ad9e63e,POJO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@3c35c345/SelectorProducer@ad9e63e/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:49.5689014+05:30 added {QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}],UNMANAGED}
2022-01-12 15:09:49 DEBUG EatWhatYouKill:93 - EatWhatYouKill@3c35c345/SelectorProducer@ad9e63e/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:49.5689014+05:30 created
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ManagedSelector@7be7e15{STOPPED} id=0 keys=-1 selected=-1 updates=0 added {EatWhatYouKill@3c35c345/SelectorProducer@ad9e63e/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:49.5689014+05:30,MANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - SelectorManager@ServerConnector@1e530163{HTTP/1.1, (http/1.1)}{0.0.0.0:4040} added {ManagedSelector@7be7e15{STOPPED} id=0 keys=-1 selected=-1 updates=0,AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@3abfe845/SelectorProducer@7a0f244f/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:49.5689014+05:30 added {SelectorProducer@7a0f244f,POJO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@3abfe845/SelectorProducer@7a0f244f/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:49.5689014+05:30 added {QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}],UNMANAGED}
2022-01-12 15:09:49 DEBUG EatWhatYouKill:93 - EatWhatYouKill@3abfe845/SelectorProducer@7a0f244f/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:49.5689014+05:30 created
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ManagedSelector@3672276e{STOPPED} id=1 keys=-1 selected=-1 updates=0 added {EatWhatYouKill@3abfe845/SelectorProducer@7a0f244f/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:49.5689014+05:30,MANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - SelectorManager@ServerConnector@1e530163{HTTP/1.1, (http/1.1)}{0.0.0.0:4040} added {ManagedSelector@3672276e{STOPPED} id=1 keys=-1 selected=-1 updates=0,AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@4248b963/SelectorProducer@7f08caf/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:49.5689014+05:30 added {SelectorProducer@7f08caf,POJO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@4248b963/SelectorProducer@7f08caf/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:49.5689014+05:30 added {QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}],UNMANAGED}
2022-01-12 15:09:49 DEBUG EatWhatYouKill:93 - EatWhatYouKill@4248b963/SelectorProducer@7f08caf/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:49.5689014+05:30 created
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ManagedSelector@4defd42{STOPPED} id=2 keys=-1 selected=-1 updates=0 added {EatWhatYouKill@4248b963/SelectorProducer@7f08caf/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:49.5689014+05:30,MANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - SelectorManager@ServerConnector@1e530163{HTTP/1.1, (http/1.1)}{0.0.0.0:4040} added {ManagedSelector@4defd42{STOPPED} id=2 keys=-1 selected=-1 updates=0,AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@2330e3e0/SelectorProducer@24b4d544/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:49.5689014+05:30 added {SelectorProducer@24b4d544,POJO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@2330e3e0/SelectorProducer@24b4d544/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:49.5689014+05:30 added {QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}],UNMANAGED}
2022-01-12 15:09:49 DEBUG EatWhatYouKill:93 - EatWhatYouKill@2330e3e0/SelectorProducer@24b4d544/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:49.5689014+05:30 created
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ManagedSelector@27a2a089{STOPPED} id=3 keys=-1 selected=-1 updates=0 added {EatWhatYouKill@2330e3e0/SelectorProducer@24b4d544/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:49.5689014+05:30,MANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - SelectorManager@ServerConnector@1e530163{HTTP/1.1, (http/1.1)}{0.0.0.0:4040} added {ManagedSelector@27a2a089{STOPPED} id=3 keys=-1 selected=-1 updates=0,AUTO}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ManagedSelector@7be7e15{STOPPED} id=0 keys=-1 selected=-1 updates=0
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting EatWhatYouKill@3c35c345/SelectorProducer@ad9e63e/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:49.5689014+05:30
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4197ms EatWhatYouKill@3c35c345/SelectorProducer@ad9e63e/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:49.5689014+05:30
2022-01-12 15:09:49 DEBUG QueuedThreadPool:719 - queue org.sparkproject.jetty.io.ManagedSelector$$Lambda$472/0x0000000800546c40@72725ee1 startThread=0
2022-01-12 15:09:49 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.io.ManagedSelector$$Lambda$472/0x0000000800546c40@72725ee1 in QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}]
2022-01-12 15:09:49 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$Start@3a230001 on ManagedSelector@7be7e15{STARTING} id=0 keys=0 selected=0 updates=0
2022-01-12 15:09:49 DEBUG EatWhatYouKill:141 - EatWhatYouKill@3c35c345/SelectorProducer@ad9e63e/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:49.5689014+05:30 tryProduce false
2022-01-12 15:09:49 DEBUG ManagedSelector:558 - updateable 1
2022-01-12 15:09:49 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$Start@3a230001
2022-01-12 15:09:49 DEBUG ManagedSelector:587 - updates 0
2022-01-12 15:09:49 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@2b19042e waiting with 0 keys
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4204ms ManagedSelector@7be7e15{STARTED} id=0 keys=0 selected=0 updates=0
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ManagedSelector@3672276e{STOPPED} id=1 keys=-1 selected=-1 updates=0
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting EatWhatYouKill@3abfe845/SelectorProducer@7a0f244f/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:49.5853656+05:30
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4206ms EatWhatYouKill@3abfe845/SelectorProducer@7a0f244f/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:49.5853656+05:30
2022-01-12 15:09:49 DEBUG QueuedThreadPool:719 - queue org.sparkproject.jetty.io.ManagedSelector$$Lambda$472/0x0000000800546c40@5ac6c4f2 startThread=0
2022-01-12 15:09:49 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.io.ManagedSelector$$Lambda$472/0x0000000800546c40@5ac6c4f2 in QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}]
2022-01-12 15:09:49 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$Start@2aa6311a on ManagedSelector@3672276e{STARTING} id=1 keys=0 selected=0 updates=0
2022-01-12 15:09:49 DEBUG EatWhatYouKill:141 - EatWhatYouKill@3abfe845/SelectorProducer@7a0f244f/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:49.5853656+05:30 tryProduce false
2022-01-12 15:09:49 DEBUG ManagedSelector:558 - updateable 1
2022-01-12 15:09:49 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$Start@2aa6311a
2022-01-12 15:09:49 DEBUG ManagedSelector:587 - updates 0
2022-01-12 15:09:49 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@6f312f71 waiting with 0 keys
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4209ms ManagedSelector@3672276e{STARTED} id=1 keys=0 selected=0 updates=0
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ManagedSelector@4defd42{STOPPED} id=2 keys=-1 selected=-1 updates=0
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting EatWhatYouKill@4248b963/SelectorProducer@7f08caf/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:49.5853656+05:30
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4210ms EatWhatYouKill@4248b963/SelectorProducer@7f08caf/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:49.5853656+05:30
2022-01-12 15:09:49 DEBUG QueuedThreadPool:719 - queue org.sparkproject.jetty.io.ManagedSelector$$Lambda$472/0x0000000800546c40@61f39bb startThread=0
2022-01-12 15:09:49 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.io.ManagedSelector$$Lambda$472/0x0000000800546c40@61f39bb in QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}]
2022-01-12 15:09:49 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$Start@249e0271 on ManagedSelector@4defd42{STARTING} id=2 keys=0 selected=0 updates=0
2022-01-12 15:09:49 DEBUG EatWhatYouKill:141 - EatWhatYouKill@4248b963/SelectorProducer@7f08caf/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:49.5853656+05:30 tryProduce false
2022-01-12 15:09:49 DEBUG ManagedSelector:558 - updateable 1
2022-01-12 15:09:49 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$Start@249e0271
2022-01-12 15:09:49 DEBUG ManagedSelector:587 - updates 0
2022-01-12 15:09:49 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@92b4a1c waiting with 0 keys
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4212ms ManagedSelector@4defd42{STARTED} id=2 keys=0 selected=0 updates=0
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ManagedSelector@27a2a089{STOPPED} id=3 keys=-1 selected=-1 updates=0
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting EatWhatYouKill@2330e3e0/SelectorProducer@24b4d544/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:49.5853656+05:30
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4213ms EatWhatYouKill@2330e3e0/SelectorProducer@24b4d544/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:49.5853656+05:30
2022-01-12 15:09:49 DEBUG QueuedThreadPool:719 - queue org.sparkproject.jetty.io.ManagedSelector$$Lambda$472/0x0000000800546c40@2c0b4c83 startThread=0
2022-01-12 15:09:49 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$Start@78525ef9 on ManagedSelector@27a2a089{STARTING} id=3 keys=0 selected=0 updates=0
2022-01-12 15:09:49 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.io.ManagedSelector$$Lambda$472/0x0000000800546c40@2c0b4c83 in QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=4,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}]
2022-01-12 15:09:49 DEBUG EatWhatYouKill:141 - EatWhatYouKill@2330e3e0/SelectorProducer@24b4d544/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=4,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:49.597258+05:30 tryProduce false
2022-01-12 15:09:49 DEBUG ManagedSelector:558 - updateable 1
2022-01-12 15:09:49 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$Start@78525ef9
2022-01-12 15:09:49 DEBUG ManagedSelector:587 - updates 0
2022-01-12 15:09:49 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@6f20a6b6 waiting with 0 keys
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4216ms ManagedSelector@27a2a089{STARTED} id=3 keys=0 selected=0 updates=0
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4217ms SelectorManager@ServerConnector@1e530163{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServerConnector@1e530163{HTTP/1.1, (http/1.1)}{0.0.0.0:4040} added {acceptor-0@51b35e4e,POJO}
2022-01-12 15:09:49 DEBUG QueuedThreadPool:719 - queue acceptor-0@51b35e4e startThread=0
2022-01-12 15:09:49 DEBUG QueuedThreadPool:1035 - run acceptor-0@51b35e4e in QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=3,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}]
2022-01-12 15:09:49 INFO  AbstractConnector:331 - Started ServerConnector@1e530163{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4219ms ServerConnector@1e530163{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-01-12 15:09:49 INFO  Utils:57 - Successfully started service 'SparkUI' on port 4040.
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - Server@4c59e45e{STARTED}[9.4.40.v20210413] added {Spark@1e530163{HTTP/1.1, (http/1.1)}{0.0.0.0:4040},UNMANAGED}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@c808207{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-4acb2510==org.apache.spark.ui.HttpSecurityFilter@4acb2510{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@c808207{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-4acb2510,POJO}
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG GzipHandler:208 - GzipHandler@34f392be{STOPPED,min=32,inflate=-1} mime types IncludeExclude@4554de02{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@34f392be{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,STOPPED,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@34f392be{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,STOPPED,@Spark}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,STARTING,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ServletHandler@c808207{STOPPED}
2022-01-12 15:09:49 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-5f18f9d2[EMBEDDED:null]
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-5f18f9d2==org.apache.spark.ui.JettyUtils$$anon$1@84970c87{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-4acb2510=org.apache.spark.ui.HttpSecurityFilter-4acb2510==org.apache.spark.ui.HttpSecurityFilter@4acb2510{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-4acb2510]
2022-01-12 15:09:49 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:49 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-5f18f9d2=org.apache.spark.ui.JettyUtils$$anon$1-5f18f9d2==org.apache.spark.ui.JettyUtils$$anon$1@84970c87{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting ServletHandler@c808207{STARTING}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4249ms ServletHandler@c808207{STARTED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-4acb2510==org.apache.spark.ui.HttpSecurityFilter@4acb2510{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4252ms org.apache.spark.ui.HttpSecurityFilter-4acb2510==org.apache.spark.ui.HttpSecurityFilter@4acb2510{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@4867ab9f
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-5f18f9d2==org.apache.spark.ui.JettyUtils$$anon$1@84970c87{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4254ms org.apache.spark.ui.JettyUtils$$anon$1-5f18f9d2==org.apache.spark.ui.JettyUtils$$anon$1@84970c87{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-5f18f9d2
2022-01-12 15:09:49 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4256ms o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting GzipHandler@34f392be{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@34f392be{STARTING,min=32,inflate=-1} added {DeflaterPool@23eff5d1{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting GzipHandler@34f392be{STARTING,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@23eff5d1{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4259ms DeflaterPool@23eff5d1{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4259ms GzipHandler@34f392be{STARTED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@4ad3d266{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-7d199c68==org.apache.spark.ui.HttpSecurityFilter@7d199c68{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@4ad3d266{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-7d199c68,POJO}
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG GzipHandler:208 - GzipHandler@63411512{STOPPED,min=32,inflate=-1} mime types IncludeExclude@35cd68d4{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@63411512{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,STOPPED,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@63411512{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,STOPPED,@Spark}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,STARTING,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ServletHandler@4ad3d266{STOPPED}
2022-01-12 15:09:49 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-3533df16[EMBEDDED:null]
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-3533df16==org.apache.spark.ui.JettyUtils$$anon$1@97e65117{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-7d199c68=org.apache.spark.ui.HttpSecurityFilter-7d199c68==org.apache.spark.ui.HttpSecurityFilter@7d199c68{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-7d199c68]
2022-01-12 15:09:49 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:49 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-3533df16=org.apache.spark.ui.JettyUtils$$anon$1-3533df16==org.apache.spark.ui.JettyUtils$$anon$1@97e65117{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting ServletHandler@4ad3d266{STARTING}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4264ms ServletHandler@4ad3d266{STARTED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-7d199c68==org.apache.spark.ui.HttpSecurityFilter@7d199c68{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4265ms org.apache.spark.ui.HttpSecurityFilter-7d199c68==org.apache.spark.ui.HttpSecurityFilter@7d199c68{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@316a598d
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-3533df16==org.apache.spark.ui.JettyUtils$$anon$1@97e65117{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4266ms org.apache.spark.ui.JettyUtils$$anon$1-3533df16==org.apache.spark.ui.JettyUtils$$anon$1@97e65117{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-3533df16
2022-01-12 15:09:49 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4266ms o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting GzipHandler@63411512{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@63411512{STARTING,min=32,inflate=-1} added {DeflaterPool@216914{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting GzipHandler@63411512{STARTING,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@216914{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4267ms DeflaterPool@216914{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4267ms GzipHandler@63411512{STARTED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@7c6189d5{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-6ba30587==org.apache.spark.ui.HttpSecurityFilter@6ba30587{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@7c6189d5{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-6ba30587,POJO}
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG GzipHandler:208 - GzipHandler@35764bef{STOPPED,min=32,inflate=-1} mime types IncludeExclude@5633dafd{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@35764bef{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@35764bef{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,STOPPED,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@35764bef{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,STOPPED,@Spark}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,STARTING,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ServletHandler@7c6189d5{STOPPED}
2022-01-12 15:09:49 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-4248e66b[EMBEDDED:null]
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-4248e66b==org.apache.spark.ui.JettyUtils$$anon$1@630fdb4d{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-6ba30587=org.apache.spark.ui.HttpSecurityFilter-6ba30587==org.apache.spark.ui.HttpSecurityFilter@6ba30587{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-6ba30587]
2022-01-12 15:09:49 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:49 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-4248e66b=org.apache.spark.ui.JettyUtils$$anon$1-4248e66b==org.apache.spark.ui.JettyUtils$$anon$1@630fdb4d{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting ServletHandler@7c6189d5{STARTING}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4272ms ServletHandler@7c6189d5{STARTED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-6ba30587==org.apache.spark.ui.HttpSecurityFilter@6ba30587{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4272ms org.apache.spark.ui.HttpSecurityFilter-6ba30587==org.apache.spark.ui.HttpSecurityFilter@6ba30587{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@5d5160e6
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-4248e66b==org.apache.spark.ui.JettyUtils$$anon$1@630fdb4d{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4272ms org.apache.spark.ui.JettyUtils$$anon$1-4248e66b==org.apache.spark.ui.JettyUtils$$anon$1@630fdb4d{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-4248e66b
2022-01-12 15:09:49 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4273ms o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting GzipHandler@35764bef{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@35764bef{STARTING,min=32,inflate=-1} added {DeflaterPool@2eadc9f6{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting GzipHandler@35764bef{STARTING,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@2eadc9f6{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4273ms DeflaterPool@2eadc9f6{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4273ms GzipHandler@35764bef{STARTED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@167279d1{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-2903c6ff==org.apache.spark.ui.HttpSecurityFilter@2903c6ff{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@167279d1{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-2903c6ff,POJO}
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG GzipHandler:208 - GzipHandler@778d82e9{STOPPED,min=32,inflate=-1} mime types IncludeExclude@408e96d9{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@778d82e9{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@35764bef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@778d82e9{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,STOPPED,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@778d82e9{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,STOPPED,@Spark}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,STARTING,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ServletHandler@167279d1{STOPPED}
2022-01-12 15:09:49 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-138caeca[EMBEDDED:null]
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-138caeca==org.apache.spark.ui.JettyUtils$$anon$1@6982c97d{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-2903c6ff=org.apache.spark.ui.HttpSecurityFilter-2903c6ff==org.apache.spark.ui.HttpSecurityFilter@2903c6ff{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-2903c6ff]
2022-01-12 15:09:49 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:49 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-138caeca=org.apache.spark.ui.JettyUtils$$anon$1-138caeca==org.apache.spark.ui.JettyUtils$$anon$1@6982c97d{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting ServletHandler@167279d1{STARTING}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4279ms ServletHandler@167279d1{STARTED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-2903c6ff==org.apache.spark.ui.HttpSecurityFilter@2903c6ff{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4279ms org.apache.spark.ui.HttpSecurityFilter-2903c6ff==org.apache.spark.ui.HttpSecurityFilter@2903c6ff{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@59901c4d
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-138caeca==org.apache.spark.ui.JettyUtils$$anon$1@6982c97d{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4280ms org.apache.spark.ui.JettyUtils$$anon$1-138caeca==org.apache.spark.ui.JettyUtils$$anon$1@6982c97d{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-138caeca
2022-01-12 15:09:49 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4280ms o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting GzipHandler@778d82e9{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@778d82e9{STARTING,min=32,inflate=-1} added {DeflaterPool@168cd36b{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting GzipHandler@778d82e9{STARTING,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@168cd36b{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4281ms DeflaterPool@168cd36b{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4281ms GzipHandler@778d82e9{STARTED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@2875b016{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-d8d9199==org.apache.spark.ui.HttpSecurityFilter@d8d9199{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@2875b016{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-d8d9199,POJO}
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG GzipHandler:208 - GzipHandler@3901f6af{STOPPED,min=32,inflate=-1} mime types IncludeExclude@602ae7b6{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@3901f6af{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@681e144{/stages,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@35764bef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@778d82e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@3901f6af{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@681e144{/stages,null,STOPPED,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@3901f6af{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@681e144{/stages,null,STOPPED,@Spark}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@681e144{/stages,null,STARTING,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ServletHandler@2875b016{STOPPED}
2022-01-12 15:09:49 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-72ee5d84[EMBEDDED:null]
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-72ee5d84==org.apache.spark.ui.JettyUtils$$anon$1@f0b5d4f4{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-d8d9199=org.apache.spark.ui.HttpSecurityFilter-d8d9199==org.apache.spark.ui.HttpSecurityFilter@d8d9199{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-d8d9199]
2022-01-12 15:09:49 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:49 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-72ee5d84=org.apache.spark.ui.JettyUtils$$anon$1-72ee5d84==org.apache.spark.ui.JettyUtils$$anon$1@f0b5d4f4{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting ServletHandler@2875b016{STARTING}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4286ms ServletHandler@2875b016{STARTED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-d8d9199==org.apache.spark.ui.HttpSecurityFilter@d8d9199{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4287ms org.apache.spark.ui.HttpSecurityFilter-d8d9199==org.apache.spark.ui.HttpSecurityFilter@d8d9199{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@10cd6753
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-72ee5d84==org.apache.spark.ui.JettyUtils$$anon$1@f0b5d4f4{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4287ms org.apache.spark.ui.JettyUtils$$anon$1-72ee5d84==org.apache.spark.ui.JettyUtils$$anon$1@f0b5d4f4{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-72ee5d84
2022-01-12 15:09:49 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@681e144{/stages,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4287ms o.s.j.s.ServletContextHandler@681e144{/stages,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting GzipHandler@3901f6af{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@3901f6af{STARTING,min=32,inflate=-1} added {DeflaterPool@71ad3d8a{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting GzipHandler@3901f6af{STARTING,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@71ad3d8a{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4288ms DeflaterPool@71ad3d8a{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4288ms GzipHandler@3901f6af{STARTED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@64355120{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-47af099e==org.apache.spark.ui.HttpSecurityFilter@47af099e{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@64355120{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-47af099e,POJO}
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG GzipHandler:208 - GzipHandler@700f518a{STOPPED,min=32,inflate=-1} mime types IncludeExclude@b835727{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@700f518a{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@35764bef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@778d82e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@700f518a{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,STOPPED,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@3901f6af{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@681e144{/stages,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@700f518a{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,STOPPED,@Spark}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,STARTING,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ServletHandler@64355120{STOPPED}
2022-01-12 15:09:49 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-64b7225f[EMBEDDED:null]
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-64b7225f==org.apache.spark.ui.JettyUtils$$anon$1@eaf84292{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-47af099e=org.apache.spark.ui.HttpSecurityFilter-47af099e==org.apache.spark.ui.HttpSecurityFilter@47af099e{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-47af099e]
2022-01-12 15:09:49 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:49 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-64b7225f=org.apache.spark.ui.JettyUtils$$anon$1-64b7225f==org.apache.spark.ui.JettyUtils$$anon$1@eaf84292{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting ServletHandler@64355120{STARTING}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4292ms ServletHandler@64355120{STARTED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-47af099e==org.apache.spark.ui.HttpSecurityFilter@47af099e{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4292ms org.apache.spark.ui.HttpSecurityFilter-47af099e==org.apache.spark.ui.HttpSecurityFilter@47af099e{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@13da7ab0
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-64b7225f==org.apache.spark.ui.JettyUtils$$anon$1@eaf84292{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4293ms org.apache.spark.ui.JettyUtils$$anon$1-64b7225f==org.apache.spark.ui.JettyUtils$$anon$1@eaf84292{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-64b7225f
2022-01-12 15:09:49 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4293ms o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting GzipHandler@700f518a{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@700f518a{STARTING,min=32,inflate=-1} added {DeflaterPool@2c8662ac{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting GzipHandler@700f518a{STARTING,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@2c8662ac{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4294ms DeflaterPool@2c8662ac{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4294ms GzipHandler@700f518a{STARTED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@6c1832aa{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-260ff5b7==org.apache.spark.ui.HttpSecurityFilter@260ff5b7{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@6c1832aa{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-260ff5b7,POJO}
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG GzipHandler:208 - GzipHandler@3724b43e{STOPPED,min=32,inflate=-1} mime types IncludeExclude@77eb5790{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@3724b43e{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@35764bef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@778d82e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@700f518a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@3901f6af{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@681e144{/stages,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@3724b43e{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,STOPPED,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@3724b43e{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,STOPPED,@Spark}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,STARTING,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ServletHandler@6c1832aa{STOPPED}
2022-01-12 15:09:49 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-4beeb0e[EMBEDDED:null]
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-4beeb0e==org.apache.spark.ui.JettyUtils$$anon$1@1e13221b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-260ff5b7=org.apache.spark.ui.HttpSecurityFilter-260ff5b7==org.apache.spark.ui.HttpSecurityFilter@260ff5b7{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-260ff5b7]
2022-01-12 15:09:49 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:49 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-4beeb0e=org.apache.spark.ui.JettyUtils$$anon$1-4beeb0e==org.apache.spark.ui.JettyUtils$$anon$1@1e13221b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting ServletHandler@6c1832aa{STARTING}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4300ms ServletHandler@6c1832aa{STARTED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-260ff5b7==org.apache.spark.ui.HttpSecurityFilter@260ff5b7{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4300ms org.apache.spark.ui.HttpSecurityFilter-260ff5b7==org.apache.spark.ui.HttpSecurityFilter@260ff5b7{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@68e7c8c3
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-4beeb0e==org.apache.spark.ui.JettyUtils$$anon$1@1e13221b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4301ms org.apache.spark.ui.JettyUtils$$anon$1-4beeb0e==org.apache.spark.ui.JettyUtils$$anon$1@1e13221b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-4beeb0e
2022-01-12 15:09:49 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4301ms o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting GzipHandler@3724b43e{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@3724b43e{STARTING,min=32,inflate=-1} added {DeflaterPool@319c3a25{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting GzipHandler@3724b43e{STARTING,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@319c3a25{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4301ms DeflaterPool@319c3a25{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4301ms GzipHandler@3724b43e{STARTED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@70211e49{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-238bfd6c==org.apache.spark.ui.HttpSecurityFilter@238bfd6c{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@70211e49{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-238bfd6c,POJO}
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG GzipHandler:208 - GzipHandler@7139bd31{STOPPED,min=32,inflate=-1} mime types IncludeExclude@199bc830{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@7139bd31{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@5d01ea21{/stages/stage/json,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@35764bef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@7139bd31{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5d01ea21{/stages/stage/json,null,STOPPED,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@778d82e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@700f518a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@3901f6af{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@681e144{/stages,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@3724b43e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@7139bd31{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@5d01ea21{/stages/stage/json,null,STOPPED,@Spark}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@5d01ea21{/stages/stage/json,null,STARTING,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ServletHandler@70211e49{STOPPED}
2022-01-12 15:09:49 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-3b46dd8[EMBEDDED:null]
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-3b46dd8==org.apache.spark.ui.JettyUtils$$anon$1@e6651759{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-238bfd6c=org.apache.spark.ui.HttpSecurityFilter-238bfd6c==org.apache.spark.ui.HttpSecurityFilter@238bfd6c{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-238bfd6c]
2022-01-12 15:09:49 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:49 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-3b46dd8=org.apache.spark.ui.JettyUtils$$anon$1-3b46dd8==org.apache.spark.ui.JettyUtils$$anon$1@e6651759{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting ServletHandler@70211e49{STARTING}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4306ms ServletHandler@70211e49{STARTED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-238bfd6c==org.apache.spark.ui.HttpSecurityFilter@238bfd6c{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4306ms org.apache.spark.ui.HttpSecurityFilter-238bfd6c==org.apache.spark.ui.HttpSecurityFilter@238bfd6c{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@4b3fe06e
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-3b46dd8==org.apache.spark.ui.JettyUtils$$anon$1@e6651759{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4306ms org.apache.spark.ui.JettyUtils$$anon$1-3b46dd8==org.apache.spark.ui.JettyUtils$$anon$1@e6651759{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-3b46dd8
2022-01-12 15:09:49 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@5d01ea21{/stages/stage/json,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4307ms o.s.j.s.ServletContextHandler@5d01ea21{/stages/stage/json,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting GzipHandler@7139bd31{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@7139bd31{STARTING,min=32,inflate=-1} added {DeflaterPool@27b45ea{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting GzipHandler@7139bd31{STARTING,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@27b45ea{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4307ms DeflaterPool@27b45ea{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4307ms GzipHandler@7139bd31{STARTED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@33364212{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-3e17a0a1==org.apache.spark.ui.HttpSecurityFilter@3e17a0a1{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@33364212{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-3e17a0a1,POJO}
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG GzipHandler:208 - GzipHandler@790a251b{STOPPED,min=32,inflate=-1} mime types IncludeExclude@4d8286c4{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@790a251b{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@134c370e{/stages/pool,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@35764bef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@7139bd31{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5d01ea21{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@778d82e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@700f518a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@3901f6af{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@681e144{/stages,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@3724b43e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@790a251b{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@134c370e{/stages/pool,null,STOPPED,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@790a251b{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@134c370e{/stages/pool,null,STOPPED,@Spark}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@134c370e{/stages/pool,null,STARTING,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ServletHandler@33364212{STOPPED}
2022-01-12 15:09:49 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-2216effc[EMBEDDED:null]
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-2216effc==org.apache.spark.ui.JettyUtils$$anon$1@8e1382b1{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-3e17a0a1=org.apache.spark.ui.HttpSecurityFilter-3e17a0a1==org.apache.spark.ui.HttpSecurityFilter@3e17a0a1{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-3e17a0a1]
2022-01-12 15:09:49 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:49 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-2216effc=org.apache.spark.ui.JettyUtils$$anon$1-2216effc==org.apache.spark.ui.JettyUtils$$anon$1@8e1382b1{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting ServletHandler@33364212{STARTING}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4310ms ServletHandler@33364212{STARTED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-3e17a0a1==org.apache.spark.ui.HttpSecurityFilter@3e17a0a1{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4311ms org.apache.spark.ui.HttpSecurityFilter-3e17a0a1==org.apache.spark.ui.HttpSecurityFilter@3e17a0a1{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@150ede8b
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-2216effc==org.apache.spark.ui.JettyUtils$$anon$1@8e1382b1{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4311ms org.apache.spark.ui.JettyUtils$$anon$1-2216effc==org.apache.spark.ui.JettyUtils$$anon$1@8e1382b1{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-2216effc
2022-01-12 15:09:49 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@134c370e{/stages/pool,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4311ms o.s.j.s.ServletContextHandler@134c370e{/stages/pool,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting GzipHandler@790a251b{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@790a251b{STARTING,min=32,inflate=-1} added {DeflaterPool@161f6623{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting GzipHandler@790a251b{STARTING,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@161f6623{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4312ms DeflaterPool@161f6623{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4312ms GzipHandler@790a251b{STARTED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@7fd69dd{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-3e15bb06==org.apache.spark.ui.HttpSecurityFilter@3e15bb06{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@7fd69dd{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-3e15bb06,POJO}
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG GzipHandler:208 - GzipHandler@6778aea6{STOPPED,min=32,inflate=-1} mime types IncludeExclude@4e1ce44{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@6778aea6{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@6da9dc6{/stages/pool/json,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@35764bef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@7139bd31{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5d01ea21{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@778d82e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@700f518a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@3901f6af{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@681e144{/stages,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@3724b43e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@6778aea6{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6da9dc6{/stages/pool/json,null,STOPPED,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@790a251b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@134c370e{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@6778aea6{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@6da9dc6{/stages/pool/json,null,STOPPED,@Spark}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@6da9dc6{/stages/pool/json,null,STARTING,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ServletHandler@7fd69dd{STOPPED}
2022-01-12 15:09:49 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-12010fd1[EMBEDDED:null]
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-12010fd1==org.apache.spark.ui.JettyUtils$$anon$1@241eef93{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-3e15bb06=org.apache.spark.ui.HttpSecurityFilter-3e15bb06==org.apache.spark.ui.HttpSecurityFilter@3e15bb06{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-3e15bb06]
2022-01-12 15:09:49 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:49 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-12010fd1=org.apache.spark.ui.JettyUtils$$anon$1-12010fd1==org.apache.spark.ui.JettyUtils$$anon$1@241eef93{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting ServletHandler@7fd69dd{STARTING}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4317ms ServletHandler@7fd69dd{STARTED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-3e15bb06==org.apache.spark.ui.HttpSecurityFilter@3e15bb06{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4317ms org.apache.spark.ui.HttpSecurityFilter-3e15bb06==org.apache.spark.ui.HttpSecurityFilter@3e15bb06{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@69228e85
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-12010fd1==org.apache.spark.ui.JettyUtils$$anon$1@241eef93{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4318ms org.apache.spark.ui.JettyUtils$$anon$1-12010fd1==org.apache.spark.ui.JettyUtils$$anon$1@241eef93{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-12010fd1
2022-01-12 15:09:49 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@6da9dc6{/stages/pool/json,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4318ms o.s.j.s.ServletContextHandler@6da9dc6{/stages/pool/json,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting GzipHandler@6778aea6{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@6778aea6{STARTING,min=32,inflate=-1} added {DeflaterPool@7a7cc52c{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting GzipHandler@6778aea6{STARTING,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@7a7cc52c{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4319ms DeflaterPool@7a7cc52c{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4319ms GzipHandler@6778aea6{STARTED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@2b98b3bb{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-5853495b==org.apache.spark.ui.HttpSecurityFilter@5853495b{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@2b98b3bb{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-5853495b,POJO}
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG GzipHandler:208 - GzipHandler@524a2ffb{STOPPED,min=32,inflate=-1} mime types IncludeExclude@2f61d591{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@524a2ffb{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@37864b77{/storage,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@35764bef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@7139bd31{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5d01ea21{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@778d82e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@700f518a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@3901f6af{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@681e144{/stages,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@3724b43e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@524a2ffb{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@37864b77{/storage,null,STOPPED,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@6778aea6{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6da9dc6{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@790a251b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@134c370e{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@524a2ffb{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@37864b77{/storage,null,STOPPED,@Spark}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@37864b77{/storage,null,STARTING,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ServletHandler@2b98b3bb{STOPPED}
2022-01-12 15:09:49 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-540b0448[EMBEDDED:null]
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-540b0448==org.apache.spark.ui.JettyUtils$$anon$1@3021d7c7{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-5853495b=org.apache.spark.ui.HttpSecurityFilter-5853495b==org.apache.spark.ui.HttpSecurityFilter@5853495b{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-5853495b]
2022-01-12 15:09:49 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:49 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-540b0448=org.apache.spark.ui.JettyUtils$$anon$1-540b0448==org.apache.spark.ui.JettyUtils$$anon$1@3021d7c7{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting ServletHandler@2b98b3bb{STARTING}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4325ms ServletHandler@2b98b3bb{STARTED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-5853495b==org.apache.spark.ui.HttpSecurityFilter@5853495b{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4325ms org.apache.spark.ui.HttpSecurityFilter-5853495b==org.apache.spark.ui.HttpSecurityFilter@5853495b{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@332820f4
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-540b0448==org.apache.spark.ui.JettyUtils$$anon$1@3021d7c7{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4325ms org.apache.spark.ui.JettyUtils$$anon$1-540b0448==org.apache.spark.ui.JettyUtils$$anon$1@3021d7c7{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-540b0448
2022-01-12 15:09:49 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@37864b77{/storage,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4326ms o.s.j.s.ServletContextHandler@37864b77{/storage,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting GzipHandler@524a2ffb{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@524a2ffb{STARTING,min=32,inflate=-1} added {DeflaterPool@7173ae5b{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting GzipHandler@524a2ffb{STARTING,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@7173ae5b{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4326ms DeflaterPool@7173ae5b{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4326ms GzipHandler@524a2ffb{STARTED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@3b95d13c{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-72456279==org.apache.spark.ui.HttpSecurityFilter@72456279{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@3b95d13c{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-72456279,POJO}
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG GzipHandler:208 - GzipHandler@53a9fcfd{STOPPED,min=32,inflate=-1} mime types IncludeExclude@21f459fc{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@53a9fcfd{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@557eb543{/storage/json,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@35764bef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@7139bd31{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5d01ea21{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@778d82e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@700f518a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@3901f6af{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@681e144{/stages,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@3724b43e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@53a9fcfd{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@557eb543{/storage/json,null,STOPPED,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@524a2ffb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@37864b77{/storage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@6778aea6{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6da9dc6{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@790a251b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@134c370e{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@53a9fcfd{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@557eb543{/storage/json,null,STOPPED,@Spark}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@557eb543{/storage/json,null,STARTING,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ServletHandler@3b95d13c{STOPPED}
2022-01-12 15:09:49 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-3730ab42[EMBEDDED:null]
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-3730ab42==org.apache.spark.ui.JettyUtils$$anon$1@187154e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-72456279=org.apache.spark.ui.HttpSecurityFilter-72456279==org.apache.spark.ui.HttpSecurityFilter@72456279{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-72456279]
2022-01-12 15:09:49 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:49 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-3730ab42=org.apache.spark.ui.JettyUtils$$anon$1-3730ab42==org.apache.spark.ui.JettyUtils$$anon$1@187154e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting ServletHandler@3b95d13c{STARTING}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4332ms ServletHandler@3b95d13c{STARTED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-72456279==org.apache.spark.ui.HttpSecurityFilter@72456279{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4333ms org.apache.spark.ui.HttpSecurityFilter-72456279==org.apache.spark.ui.HttpSecurityFilter@72456279{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@4d192aef
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-3730ab42==org.apache.spark.ui.JettyUtils$$anon$1@187154e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4334ms org.apache.spark.ui.JettyUtils$$anon$1-3730ab42==org.apache.spark.ui.JettyUtils$$anon$1@187154e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-3730ab42
2022-01-12 15:09:49 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@557eb543{/storage/json,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4334ms o.s.j.s.ServletContextHandler@557eb543{/storage/json,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting GzipHandler@53a9fcfd{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@53a9fcfd{STARTING,min=32,inflate=-1} added {DeflaterPool@1416cf9f{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting GzipHandler@53a9fcfd{STARTING,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@1416cf9f{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4335ms DeflaterPool@1416cf9f{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4335ms GzipHandler@53a9fcfd{STARTED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@54d901aa{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-84487f4==org.apache.spark.ui.HttpSecurityFilter@84487f4{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@54d901aa{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-84487f4,POJO}
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG GzipHandler:208 - GzipHandler@bfc14b9{STOPPED,min=32,inflate=-1} mime types IncludeExclude@fb6097b{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@bfc14b9{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@6601cc93{/storage/rdd,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@7139bd31{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5d01ea21{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@bfc14b9{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6601cc93{/storage/rdd,null,STOPPED,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@778d82e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@700f518a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@3724b43e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@53a9fcfd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@557eb543{/storage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@524a2ffb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@37864b77{/storage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@35764bef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@3901f6af{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@681e144{/stages,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@6778aea6{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6da9dc6{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@790a251b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@134c370e{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@bfc14b9{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@6601cc93{/storage/rdd,null,STOPPED,@Spark}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@6601cc93{/storage/rdd,null,STARTING,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ServletHandler@54d901aa{STOPPED}
2022-01-12 15:09:49 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-63716833[EMBEDDED:null]
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-63716833==org.apache.spark.ui.JettyUtils$$anon$1@6c5eff27{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-84487f4=org.apache.spark.ui.HttpSecurityFilter-84487f4==org.apache.spark.ui.HttpSecurityFilter@84487f4{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-84487f4]
2022-01-12 15:09:49 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:49 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-63716833=org.apache.spark.ui.JettyUtils$$anon$1-63716833==org.apache.spark.ui.JettyUtils$$anon$1@6c5eff27{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting ServletHandler@54d901aa{STARTING}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4341ms ServletHandler@54d901aa{STARTED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-84487f4==org.apache.spark.ui.HttpSecurityFilter@84487f4{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4342ms org.apache.spark.ui.HttpSecurityFilter-84487f4==org.apache.spark.ui.HttpSecurityFilter@84487f4{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@2dfe5525
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-63716833==org.apache.spark.ui.JettyUtils$$anon$1@6c5eff27{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4342ms org.apache.spark.ui.JettyUtils$$anon$1-63716833==org.apache.spark.ui.JettyUtils$$anon$1@6c5eff27{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-63716833
2022-01-12 15:09:49 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@6601cc93{/storage/rdd,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4342ms o.s.j.s.ServletContextHandler@6601cc93{/storage/rdd,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting GzipHandler@bfc14b9{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@bfc14b9{STARTING,min=32,inflate=-1} added {DeflaterPool@1290c49{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting GzipHandler@bfc14b9{STARTING,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@1290c49{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4343ms DeflaterPool@1290c49{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4343ms GzipHandler@bfc14b9{STARTED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@23f72d88{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-6a9b9909==org.apache.spark.ui.HttpSecurityFilter@6a9b9909{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@23f72d88{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-6a9b9909,POJO}
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG GzipHandler:208 - GzipHandler@55d9b8f0{STOPPED,min=32,inflate=-1} mime types IncludeExclude@a518813{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@55d9b8f0{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@3fbfbf84{/storage/rdd/json,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@7139bd31{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5d01ea21{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@bfc14b9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6601cc93{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@778d82e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@700f518a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@3724b43e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@53a9fcfd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@557eb543{/storage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@524a2ffb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@37864b77{/storage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@55d9b8f0{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3fbfbf84{/storage/rdd/json,null,STOPPED,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@35764bef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@3901f6af{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@681e144{/stages,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@6778aea6{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6da9dc6{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@790a251b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@134c370e{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@55d9b8f0{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@3fbfbf84{/storage/rdd/json,null,STOPPED,@Spark}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@3fbfbf84{/storage/rdd/json,null,STARTING,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ServletHandler@23f72d88{STOPPED}
2022-01-12 15:09:49 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-4bafe935[EMBEDDED:null]
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-4bafe935==org.apache.spark.ui.JettyUtils$$anon$1@9d8d4f57{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-6a9b9909=org.apache.spark.ui.HttpSecurityFilter-6a9b9909==org.apache.spark.ui.HttpSecurityFilter@6a9b9909{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-6a9b9909]
2022-01-12 15:09:49 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:49 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-4bafe935=org.apache.spark.ui.JettyUtils$$anon$1-4bafe935==org.apache.spark.ui.JettyUtils$$anon$1@9d8d4f57{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting ServletHandler@23f72d88{STARTING}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4348ms ServletHandler@23f72d88{STARTED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-6a9b9909==org.apache.spark.ui.HttpSecurityFilter@6a9b9909{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4348ms org.apache.spark.ui.HttpSecurityFilter-6a9b9909==org.apache.spark.ui.HttpSecurityFilter@6a9b9909{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@43d38654
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-4bafe935==org.apache.spark.ui.JettyUtils$$anon$1@9d8d4f57{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4349ms org.apache.spark.ui.JettyUtils$$anon$1-4bafe935==org.apache.spark.ui.JettyUtils$$anon$1@9d8d4f57{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-4bafe935
2022-01-12 15:09:49 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@3fbfbf84{/storage/rdd/json,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4349ms o.s.j.s.ServletContextHandler@3fbfbf84{/storage/rdd/json,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting GzipHandler@55d9b8f0{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@55d9b8f0{STARTING,min=32,inflate=-1} added {DeflaterPool@75361cf6{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting GzipHandler@55d9b8f0{STARTING,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@75361cf6{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4350ms DeflaterPool@75361cf6{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4350ms GzipHandler@55d9b8f0{STARTED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@99407c2{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-6d303498==org.apache.spark.ui.HttpSecurityFilter@6d303498{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@99407c2{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-6d303498,POJO}
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG GzipHandler:208 - GzipHandler@6ba7383d{STOPPED,min=32,inflate=-1} mime types IncludeExclude@3419e23b{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@6ba7383d{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@23b3aa8c{/environment,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@7139bd31{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5d01ea21{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@bfc14b9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6601cc93{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@778d82e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@700f518a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@3724b43e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@53a9fcfd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@557eb543{/storage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@524a2ffb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@37864b77{/storage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@55d9b8f0{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3fbfbf84{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@35764bef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@6ba7383d{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@23b3aa8c{/environment,null,STOPPED,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@3901f6af{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@681e144{/stages,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@6778aea6{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6da9dc6{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@790a251b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@134c370e{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@6ba7383d{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@23b3aa8c{/environment,null,STOPPED,@Spark}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@23b3aa8c{/environment,null,STARTING,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ServletHandler@99407c2{STOPPED}
2022-01-12 15:09:49 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-6c796cc1[EMBEDDED:null]
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-6c796cc1==org.apache.spark.ui.JettyUtils$$anon$1@57fb7e98{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-6d303498=org.apache.spark.ui.HttpSecurityFilter-6d303498==org.apache.spark.ui.HttpSecurityFilter@6d303498{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-6d303498]
2022-01-12 15:09:49 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:49 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-6c796cc1=org.apache.spark.ui.JettyUtils$$anon$1-6c796cc1==org.apache.spark.ui.JettyUtils$$anon$1@57fb7e98{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting ServletHandler@99407c2{STARTING}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4354ms ServletHandler@99407c2{STARTED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-6d303498==org.apache.spark.ui.HttpSecurityFilter@6d303498{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4354ms org.apache.spark.ui.HttpSecurityFilter-6d303498==org.apache.spark.ui.HttpSecurityFilter@6d303498{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@710d89e2
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-6c796cc1==org.apache.spark.ui.JettyUtils$$anon$1@57fb7e98{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4354ms org.apache.spark.ui.JettyUtils$$anon$1-6c796cc1==org.apache.spark.ui.JettyUtils$$anon$1@57fb7e98{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-6c796cc1
2022-01-12 15:09:49 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@23b3aa8c{/environment,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4354ms o.s.j.s.ServletContextHandler@23b3aa8c{/environment,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting GzipHandler@6ba7383d{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@6ba7383d{STARTING,min=32,inflate=-1} added {DeflaterPool@1d75e7af{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting GzipHandler@6ba7383d{STARTING,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@1d75e7af{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4355ms DeflaterPool@1d75e7af{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4355ms GzipHandler@6ba7383d{STARTED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@35342d2f{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-4fc142ec==org.apache.spark.ui.HttpSecurityFilter@4fc142ec{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@35342d2f{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-4fc142ec,POJO}
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG GzipHandler:208 - GzipHandler@34b27915{STOPPED,min=32,inflate=-1} mime types IncludeExclude@29eda4f8{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@34b27915{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@1cb7936c{/environment/json,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@7139bd31{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5d01ea21{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@bfc14b9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6601cc93{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@34b27915{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1cb7936c{/environment/json,null,STOPPED,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@778d82e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@700f518a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@3724b43e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@53a9fcfd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@557eb543{/storage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@524a2ffb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@37864b77{/storage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@55d9b8f0{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3fbfbf84{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@6ba7383d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@23b3aa8c{/environment,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@35764bef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@3901f6af{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@681e144{/stages,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@6778aea6{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6da9dc6{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@790a251b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@134c370e{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@34b27915{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@1cb7936c{/environment/json,null,STOPPED,@Spark}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@1cb7936c{/environment/json,null,STARTING,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ServletHandler@35342d2f{STOPPED}
2022-01-12 15:09:49 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-128c502c[EMBEDDED:null]
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-128c502c==org.apache.spark.ui.JettyUtils$$anon$1@3487c106{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-4fc142ec=org.apache.spark.ui.HttpSecurityFilter-4fc142ec==org.apache.spark.ui.HttpSecurityFilter@4fc142ec{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-4fc142ec]
2022-01-12 15:09:49 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:49 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-128c502c=org.apache.spark.ui.JettyUtils$$anon$1-128c502c==org.apache.spark.ui.JettyUtils$$anon$1@3487c106{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting ServletHandler@35342d2f{STARTING}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4360ms ServletHandler@35342d2f{STARTED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-4fc142ec==org.apache.spark.ui.HttpSecurityFilter@4fc142ec{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4360ms org.apache.spark.ui.HttpSecurityFilter-4fc142ec==org.apache.spark.ui.HttpSecurityFilter@4fc142ec{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@1b9776f5
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-128c502c==org.apache.spark.ui.JettyUtils$$anon$1@3487c106{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4361ms org.apache.spark.ui.JettyUtils$$anon$1-128c502c==org.apache.spark.ui.JettyUtils$$anon$1@3487c106{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-128c502c
2022-01-12 15:09:49 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@1cb7936c{/environment/json,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4361ms o.s.j.s.ServletContextHandler@1cb7936c{/environment/json,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting GzipHandler@34b27915{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@34b27915{STARTING,min=32,inflate=-1} added {DeflaterPool@5e048149{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting GzipHandler@34b27915{STARTING,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@5e048149{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4362ms DeflaterPool@5e048149{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4362ms GzipHandler@34b27915{STARTED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@30c0d731{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-79d9214d==org.apache.spark.ui.HttpSecurityFilter@79d9214d{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@30c0d731{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-79d9214d,POJO}
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG GzipHandler:208 - GzipHandler@3d5790ea{STOPPED,min=32,inflate=-1} mime types IncludeExclude@1dd7796b{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@3d5790ea{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@100c567f{/executors,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@7139bd31{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5d01ea21{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@bfc14b9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6601cc93{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@34b27915{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1cb7936c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@778d82e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@700f518a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@3724b43e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@53a9fcfd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@557eb543{/storage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@524a2ffb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@37864b77{/storage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@55d9b8f0{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3fbfbf84{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@6ba7383d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@23b3aa8c{/environment,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@35764bef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@3901f6af{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@681e144{/stages,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@3d5790ea{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@100c567f{/executors,null,STOPPED,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@6778aea6{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6da9dc6{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@790a251b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@134c370e{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@3d5790ea{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@100c567f{/executors,null,STOPPED,@Spark}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@100c567f{/executors,null,STARTING,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ServletHandler@30c0d731{STOPPED}
2022-01-12 15:09:49 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-6d5037a9[EMBEDDED:null]
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-6d5037a9==org.apache.spark.ui.JettyUtils$$anon$1@88f73293{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-79d9214d=org.apache.spark.ui.HttpSecurityFilter-79d9214d==org.apache.spark.ui.HttpSecurityFilter@79d9214d{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-79d9214d]
2022-01-12 15:09:49 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:49 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-6d5037a9=org.apache.spark.ui.JettyUtils$$anon$1-6d5037a9==org.apache.spark.ui.JettyUtils$$anon$1@88f73293{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting ServletHandler@30c0d731{STARTING}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4371ms ServletHandler@30c0d731{STARTED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-79d9214d==org.apache.spark.ui.HttpSecurityFilter@79d9214d{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4371ms org.apache.spark.ui.HttpSecurityFilter-79d9214d==org.apache.spark.ui.HttpSecurityFilter@79d9214d{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@67a3bd51
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-6d5037a9==org.apache.spark.ui.JettyUtils$$anon$1@88f73293{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4371ms org.apache.spark.ui.JettyUtils$$anon$1-6d5037a9==org.apache.spark.ui.JettyUtils$$anon$1@88f73293{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-6d5037a9
2022-01-12 15:09:49 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@100c567f{/executors,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4371ms o.s.j.s.ServletContextHandler@100c567f{/executors,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting GzipHandler@3d5790ea{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@3d5790ea{STARTING,min=32,inflate=-1} added {DeflaterPool@57402ba1{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting GzipHandler@3d5790ea{STARTING,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@57402ba1{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4372ms DeflaterPool@57402ba1{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4372ms GzipHandler@3d5790ea{STARTED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@629adce{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-56913163==org.apache.spark.ui.HttpSecurityFilter@56913163{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@629adce{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-56913163,POJO}
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG GzipHandler:208 - GzipHandler@702b06fb{STOPPED,min=32,inflate=-1} mime types IncludeExclude@a18649a{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@702b06fb{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@30669dac{/executors/json,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@702b06fb{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@30669dac{/executors/json,null,STOPPED,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@7139bd31{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5d01ea21{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@bfc14b9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6601cc93{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@34b27915{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1cb7936c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@778d82e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@700f518a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@3724b43e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@53a9fcfd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@557eb543{/storage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@524a2ffb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@37864b77{/storage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@55d9b8f0{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3fbfbf84{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@6ba7383d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@23b3aa8c{/environment,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@35764bef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@3901f6af{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@681e144{/stages,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@3d5790ea{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@100c567f{/executors,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@6778aea6{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6da9dc6{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@790a251b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@134c370e{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@702b06fb{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@30669dac{/executors/json,null,STOPPED,@Spark}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@30669dac{/executors/json,null,STARTING,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ServletHandler@629adce{STOPPED}
2022-01-12 15:09:49 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-6a282fdd[EMBEDDED:null]
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-6a282fdd==org.apache.spark.ui.JettyUtils$$anon$1@e596ef93{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-56913163=org.apache.spark.ui.HttpSecurityFilter-56913163==org.apache.spark.ui.HttpSecurityFilter@56913163{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-56913163]
2022-01-12 15:09:49 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:49 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-6a282fdd=org.apache.spark.ui.JettyUtils$$anon$1-6a282fdd==org.apache.spark.ui.JettyUtils$$anon$1@e596ef93{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting ServletHandler@629adce{STARTING}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4377ms ServletHandler@629adce{STARTED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-56913163==org.apache.spark.ui.HttpSecurityFilter@56913163{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4377ms org.apache.spark.ui.HttpSecurityFilter-56913163==org.apache.spark.ui.HttpSecurityFilter@56913163{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@5c534b5b
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-6a282fdd==org.apache.spark.ui.JettyUtils$$anon$1@e596ef93{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4377ms org.apache.spark.ui.JettyUtils$$anon$1-6a282fdd==org.apache.spark.ui.JettyUtils$$anon$1@e596ef93{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-6a282fdd
2022-01-12 15:09:49 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@30669dac{/executors/json,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4378ms o.s.j.s.ServletContextHandler@30669dac{/executors/json,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting GzipHandler@702b06fb{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@702b06fb{STARTING,min=32,inflate=-1} added {DeflaterPool@396639b{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting GzipHandler@702b06fb{STARTING,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@396639b{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4379ms DeflaterPool@396639b{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4379ms GzipHandler@702b06fb{STARTED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@10c2064a{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-2b22a1cc==org.apache.spark.ui.HttpSecurityFilter@2b22a1cc{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@10c2064a{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-2b22a1cc,POJO}
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG GzipHandler:208 - GzipHandler@62573c86{STOPPED,min=32,inflate=-1} mime types IncludeExclude@2418ba04{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@62573c86{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@3bbf9027{/executors/threadDump,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@702b06fb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@30669dac{/executors/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@7139bd31{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5d01ea21{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@bfc14b9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6601cc93{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@34b27915{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1cb7936c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@778d82e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@700f518a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@3724b43e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@53a9fcfd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@557eb543{/storage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@524a2ffb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@37864b77{/storage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@55d9b8f0{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3fbfbf84{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@6ba7383d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@23b3aa8c{/environment,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@35764bef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@3901f6af{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@681e144{/stages,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@3d5790ea{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@100c567f{/executors,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@6778aea6{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6da9dc6{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@790a251b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@134c370e{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@62573c86{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3bbf9027{/executors/threadDump,null,STOPPED,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@62573c86{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@3bbf9027{/executors/threadDump,null,STOPPED,@Spark}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@3bbf9027{/executors/threadDump,null,STARTING,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ServletHandler@10c2064a{STOPPED}
2022-01-12 15:09:49 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-70e13fa[EMBEDDED:null]
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-70e13fa==org.apache.spark.ui.JettyUtils$$anon$1@675b379b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-2b22a1cc=org.apache.spark.ui.HttpSecurityFilter-2b22a1cc==org.apache.spark.ui.HttpSecurityFilter@2b22a1cc{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-2b22a1cc]
2022-01-12 15:09:49 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:49 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-70e13fa=org.apache.spark.ui.JettyUtils$$anon$1-70e13fa==org.apache.spark.ui.JettyUtils$$anon$1@675b379b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting ServletHandler@10c2064a{STARTING}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4386ms ServletHandler@10c2064a{STARTED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-2b22a1cc==org.apache.spark.ui.HttpSecurityFilter@2b22a1cc{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4386ms org.apache.spark.ui.HttpSecurityFilter-2b22a1cc==org.apache.spark.ui.HttpSecurityFilter@2b22a1cc{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@14229fa7
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-70e13fa==org.apache.spark.ui.JettyUtils$$anon$1@675b379b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4386ms org.apache.spark.ui.JettyUtils$$anon$1-70e13fa==org.apache.spark.ui.JettyUtils$$anon$1@675b379b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-70e13fa
2022-01-12 15:09:49 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@3bbf9027{/executors/threadDump,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4387ms o.s.j.s.ServletContextHandler@3bbf9027{/executors/threadDump,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting GzipHandler@62573c86{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@62573c86{STARTING,min=32,inflate=-1} added {DeflaterPool@2ab0702e{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting GzipHandler@62573c86{STARTING,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@2ab0702e{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4387ms DeflaterPool@2ab0702e{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4387ms GzipHandler@62573c86{STARTED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@28fd3dc1{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-7158daf2==org.apache.spark.ui.HttpSecurityFilter@7158daf2{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@28fd3dc1{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-7158daf2,POJO}
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG GzipHandler:208 - GzipHandler@10f19647{STOPPED,min=32,inflate=-1} mime types IncludeExclude@102efc59{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@10f19647{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@280d9edc{/executors/threadDump/json,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@702b06fb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@30669dac{/executors/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@7139bd31{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5d01ea21{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@bfc14b9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6601cc93{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@10f19647{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@280d9edc{/executors/threadDump/json,null,STOPPED,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@34b27915{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1cb7936c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@778d82e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@700f518a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@3724b43e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@53a9fcfd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@557eb543{/storage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@524a2ffb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@37864b77{/storage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@55d9b8f0{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3fbfbf84{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@6ba7383d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@23b3aa8c{/environment,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@35764bef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@3901f6af{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@681e144{/stages,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@3d5790ea{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@100c567f{/executors,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@6778aea6{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6da9dc6{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@790a251b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@134c370e{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@62573c86{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3bbf9027{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@10f19647{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@280d9edc{/executors/threadDump/json,null,STOPPED,@Spark}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@280d9edc{/executors/threadDump/json,null,STARTING,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ServletHandler@28fd3dc1{STOPPED}
2022-01-12 15:09:49 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-5f9b6ae7[EMBEDDED:null]
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-5f9b6ae7==org.apache.spark.ui.JettyUtils$$anon$1@94787125{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-7158daf2=org.apache.spark.ui.HttpSecurityFilter-7158daf2==org.apache.spark.ui.HttpSecurityFilter@7158daf2{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-7158daf2]
2022-01-12 15:09:49 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:49 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-5f9b6ae7=org.apache.spark.ui.JettyUtils$$anon$1-5f9b6ae7==org.apache.spark.ui.JettyUtils$$anon$1@94787125{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting ServletHandler@28fd3dc1{STARTING}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4394ms ServletHandler@28fd3dc1{STARTED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-7158daf2==org.apache.spark.ui.HttpSecurityFilter@7158daf2{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4394ms org.apache.spark.ui.HttpSecurityFilter-7158daf2==org.apache.spark.ui.HttpSecurityFilter@7158daf2{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@3936df72
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-5f9b6ae7==org.apache.spark.ui.JettyUtils$$anon$1@94787125{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4395ms org.apache.spark.ui.JettyUtils$$anon$1-5f9b6ae7==org.apache.spark.ui.JettyUtils$$anon$1@94787125{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-5f9b6ae7
2022-01-12 15:09:49 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@280d9edc{/executors/threadDump/json,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4395ms o.s.j.s.ServletContextHandler@280d9edc{/executors/threadDump/json,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting GzipHandler@10f19647{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@10f19647{STARTING,min=32,inflate=-1} added {DeflaterPool@e8e0dec{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting GzipHandler@10f19647{STARTING,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@e8e0dec{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4396ms DeflaterPool@e8e0dec{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4396ms GzipHandler@10f19647{STARTED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@1128620c{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-12d1f1d4==org.apache.spark.ui.HttpSecurityFilter@12d1f1d4{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@1128620c{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-12d1f1d4,POJO}
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG GzipHandler:208 - GzipHandler@75fa1be3{STOPPED,min=32,inflate=-1} mime types IncludeExclude@7a389761{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@75fa1be3{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@15e0fe05{/static,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@75fa1be3{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@15e0fe05{/static,null,STOPPED,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@702b06fb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@30669dac{/executors/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@7139bd31{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5d01ea21{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@bfc14b9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6601cc93{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@10f19647{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@280d9edc{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@34b27915{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1cb7936c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@778d82e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@700f518a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@3724b43e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@53a9fcfd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@557eb543{/storage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@524a2ffb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@37864b77{/storage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@55d9b8f0{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3fbfbf84{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@6ba7383d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@23b3aa8c{/environment,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@35764bef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@3901f6af{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@681e144{/stages,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@3d5790ea{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@100c567f{/executors,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@6778aea6{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6da9dc6{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@790a251b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@134c370e{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@62573c86{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3bbf9027{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@75fa1be3{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@15e0fe05{/static,null,STOPPED,@Spark}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@15e0fe05{/static,null,STARTING,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ServletHandler@1128620c{STOPPED}
2022-01-12 15:09:49 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.sparkproject.jetty.servlet.DefaultServlet-68f32020[EMBEDDED:null]
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.sparkproject.jetty.servlet.DefaultServlet-68f32020==org.sparkproject.jetty.servlet.DefaultServlet@10113d3{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-12d1f1d4=org.apache.spark.ui.HttpSecurityFilter-12d1f1d4==org.apache.spark.ui.HttpSecurityFilter@12d1f1d4{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-12d1f1d4]
2022-01-12 15:09:49 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:49 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1443 - servletNameMap={org.sparkproject.jetty.servlet.DefaultServlet-68f32020=org.sparkproject.jetty.servlet.DefaultServlet-68f32020==org.sparkproject.jetty.servlet.DefaultServlet@10113d3{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting ServletHandler@1128620c{STARTING}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4404ms ServletHandler@1128620c{STARTED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-12d1f1d4==org.apache.spark.ui.HttpSecurityFilter@12d1f1d4{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4404ms org.apache.spark.ui.HttpSecurityFilter-12d1f1d4==org.apache.spark.ui.HttpSecurityFilter@12d1f1d4{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@42714a7
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.sparkproject.jetty.servlet.DefaultServlet-68f32020==org.sparkproject.jetty.servlet.DefaultServlet@10113d3{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4404ms org.sparkproject.jetty.servlet.DefaultServlet-68f32020==org.sparkproject.jetty.servlet.DefaultServlet@10113d3{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG ServletHolder:621 - Servlet.init null for org.sparkproject.jetty.servlet.DefaultServlet-68f32020
2022-01-12 15:09:49 DEBUG DefaultServlet:308 - resource base = jar:file:/C:/Users/Rahul%20Kabothula/.m2/repository/org/apache/spark/spark-core_2.12/3.1.2/spark-core_2.12-3.1.2.jar!/org/apache/spark/ui/static
2022-01-12 15:09:49 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@15e0fe05{/static,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4419ms o.s.j.s.ServletContextHandler@15e0fe05{/static,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting GzipHandler@75fa1be3{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@75fa1be3{STARTING,min=32,inflate=-1} added {DeflaterPool@34acbc60{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting GzipHandler@75fa1be3{STARTING,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@34acbc60{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4420ms DeflaterPool@34acbc60{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4420ms GzipHandler@75fa1be3{STARTED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@5f780a86{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-42b28ff1==org.apache.spark.ui.HttpSecurityFilter@42b28ff1{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@5f780a86{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-42b28ff1,POJO}
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG GzipHandler:208 - GzipHandler@36061cf3{STOPPED,min=32,inflate=-1} mime types IncludeExclude@718dbd79{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@36061cf3{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@53dad875{/,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@36061cf3{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@53dad875{/,null,STOPPED,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@75fa1be3{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@15e0fe05{/static,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@702b06fb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@30669dac{/executors/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@7139bd31{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5d01ea21{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@bfc14b9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6601cc93{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@10f19647{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@280d9edc{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@34b27915{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1cb7936c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@778d82e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@700f518a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@3724b43e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@53a9fcfd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@557eb543{/storage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@524a2ffb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@37864b77{/storage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@55d9b8f0{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3fbfbf84{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@6ba7383d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@23b3aa8c{/environment,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@35764bef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@3901f6af{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@681e144{/stages,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@3d5790ea{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@100c567f{/executors,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@6778aea6{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6da9dc6{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@790a251b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@134c370e{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@62573c86{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3bbf9027{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@36061cf3{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@53dad875{/,null,STOPPED,@Spark}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@53dad875{/,null,STARTING,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ServletHandler@5f780a86{STOPPED}
2022-01-12 15:09:49 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-446c3920[EMBEDDED:null]
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$2-446c3920==org.apache.spark.ui.JettyUtils$$anon$2@c6d6b6de{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-42b28ff1=org.apache.spark.ui.HttpSecurityFilter-42b28ff1==org.apache.spark.ui.HttpSecurityFilter@42b28ff1{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-42b28ff1]
2022-01-12 15:09:49 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:49 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-446c3920=org.apache.spark.ui.JettyUtils$$anon$2-446c3920==org.apache.spark.ui.JettyUtils$$anon$2@c6d6b6de{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting ServletHandler@5f780a86{STARTING}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4427ms ServletHandler@5f780a86{STARTED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-42b28ff1==org.apache.spark.ui.HttpSecurityFilter@42b28ff1{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4427ms org.apache.spark.ui.HttpSecurityFilter-42b28ff1==org.apache.spark.ui.HttpSecurityFilter@42b28ff1{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@20134094
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$2-446c3920==org.apache.spark.ui.JettyUtils$$anon$2@c6d6b6de{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4428ms org.apache.spark.ui.JettyUtils$$anon$2-446c3920==org.apache.spark.ui.JettyUtils$$anon$2@c6d6b6de{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$2-446c3920
2022-01-12 15:09:49 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@53dad875{/,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4428ms o.s.j.s.ServletContextHandler@53dad875{/,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting GzipHandler@36061cf3{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@36061cf3{STARTING,min=32,inflate=-1} added {DeflaterPool@76889e60{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting GzipHandler@36061cf3{STARTING,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@76889e60{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4429ms DeflaterPool@76889e60{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4429ms GzipHandler@36061cf3{STARTED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@771d1ffb{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-706fe5c6==org.apache.spark.ui.HttpSecurityFilter@706fe5c6{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@771d1ffb{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-706fe5c6,POJO}
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG GzipHandler:208 - GzipHandler@6c15e8c7{STOPPED,min=32,inflate=-1} mime types IncludeExclude@56380231{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@6c15e8c7{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@48cd9a2c{/api,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@36061cf3{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@53dad875{/,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@75fa1be3{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@15e0fe05{/static,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@702b06fb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@30669dac{/executors/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@7139bd31{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5d01ea21{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@bfc14b9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6601cc93{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@10f19647{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@280d9edc{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@34b27915{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1cb7936c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@778d82e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@700f518a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@3724b43e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@53a9fcfd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@557eb543{/storage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@524a2ffb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@37864b77{/storage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@55d9b8f0{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3fbfbf84{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@6ba7383d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@23b3aa8c{/environment,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@35764bef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@3901f6af{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@681e144{/stages,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@3d5790ea{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@100c567f{/executors,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@6c15e8c7{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@48cd9a2c{/api,null,STOPPED,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@6778aea6{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6da9dc6{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@790a251b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@134c370e{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@62573c86{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3bbf9027{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@6c15e8c7{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@48cd9a2c{/api,null,STOPPED,@Spark}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@48cd9a2c{/api,null,STARTING,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ServletHandler@771d1ffb{STOPPED}
2022-01-12 15:09:49 DEBUG ServletHandler:1418 - Path=/*[EMBEDDED:null] mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-41fed14f[EMBEDDED:null]
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@5fa{/*},resource=org.glassfish.jersey.servlet.ServletContainer-41fed14f==org.glassfish.jersey.servlet.ServletContainer@c694ca49{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-706fe5c6=org.apache.spark.ui.HttpSecurityFilter-706fe5c6==org.apache.spark.ui.HttpSecurityFilter@706fe5c6{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-706fe5c6]
2022-01-12 15:09:49 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:49 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1443 - servletNameMap={org.glassfish.jersey.servlet.ServletContainer-41fed14f=org.glassfish.jersey.servlet.ServletContainer-41fed14f==org.glassfish.jersey.servlet.ServletContainer@c694ca49{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG ServletHandler:169 - Adding Default404Servlet to ServletHandler@771d1ffb{STARTING}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@771d1ffb{STARTING} added {org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-282ffbf5==org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet@d060642{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@771d1ffb{STARTING} added {[/]=>org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-282ffbf5,POJO}
2022-01-12 15:09:49 DEBUG ServletHandler:1418 - Path=/*[EMBEDDED:null] mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-41fed14f[EMBEDDED:null]
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@5fa{/*},resource=org.glassfish.jersey.servlet.ServletContainer-41fed14f==org.glassfish.jersey.servlet.ServletContainer@c694ca49{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-282ffbf5[EMBEDDED:null]
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-282ffbf5==org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet@d060642{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=2]
2022-01-12 15:09:49 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-706fe5c6=org.apache.spark.ui.HttpSecurityFilter-706fe5c6==org.apache.spark.ui.HttpSecurityFilter@706fe5c6{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-706fe5c6]
2022-01-12 15:09:49 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:49 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=2]
2022-01-12 15:09:49 DEBUG ServletHandler:1443 - servletNameMap={org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-282ffbf5=org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-282ffbf5==org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet@d060642{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}, org.glassfish.jersey.servlet.ServletContainer-41fed14f=org.glassfish.jersey.servlet.ServletContainer-41fed14f==org.glassfish.jersey.servlet.ServletContainer@c694ca49{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG ServletHandler:1418 - Path=/*[EMBEDDED:null] mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-41fed14f[EMBEDDED:null]
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@5fa{/*},resource=org.glassfish.jersey.servlet.ServletContainer-41fed14f==org.glassfish.jersey.servlet.ServletContainer@c694ca49{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-282ffbf5[EMBEDDED:null]
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-282ffbf5==org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet@d060642{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=2]
2022-01-12 15:09:49 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-706fe5c6=org.apache.spark.ui.HttpSecurityFilter-706fe5c6==org.apache.spark.ui.HttpSecurityFilter@706fe5c6{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-706fe5c6]
2022-01-12 15:09:49 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:49 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=2]
2022-01-12 15:09:49 DEBUG ServletHandler:1443 - servletNameMap={org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-282ffbf5=org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-282ffbf5==org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet@d060642{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}, org.glassfish.jersey.servlet.ServletContainer-41fed14f=org.glassfish.jersey.servlet.ServletContainer-41fed14f==org.glassfish.jersey.servlet.ServletContainer@c694ca49{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting ServletHandler@771d1ffb{STARTING}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4441ms ServletHandler@771d1ffb{STARTED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-706fe5c6==org.apache.spark.ui.HttpSecurityFilter@706fe5c6{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4441ms org.apache.spark.ui.HttpSecurityFilter-706fe5c6==org.apache.spark.ui.HttpSecurityFilter@706fe5c6{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@3e104d4b
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.glassfish.jersey.servlet.ServletContainer-41fed14f==org.glassfish.jersey.servlet.ServletContainer@c694ca49{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4442ms org.glassfish.jersey.servlet.ServletContainer-41fed14f==org.glassfish.jersey.servlet.ServletContainer@c694ca49{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-282ffbf5==org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet@d060642{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4442ms org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-282ffbf5==org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet@d060642{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@48cd9a2c{/api,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4443ms o.s.j.s.ServletContextHandler@48cd9a2c{/api,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting GzipHandler@6c15e8c7{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@6c15e8c7{STARTING,min=32,inflate=-1} added {DeflaterPool@55e2fe3c{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting GzipHandler@6c15e8c7{STARTING,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@55e2fe3c{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4444ms DeflaterPool@55e2fe3c{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4444ms GzipHandler@6c15e8c7{STARTED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@76c387f9{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-45e1aa48==org.apache.spark.ui.HttpSecurityFilter@45e1aa48{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@76c387f9{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-45e1aa48,POJO}
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG GzipHandler:208 - GzipHandler@12c60152{STOPPED,min=32,inflate=-1} mime types IncludeExclude@2e807c54{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@12c60152{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@36b310aa{/jobs/job/kill,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@36061cf3{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@53dad875{/,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@75fa1be3{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@15e0fe05{/static,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@702b06fb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@30669dac{/executors/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@7139bd31{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5d01ea21{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@bfc14b9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6601cc93{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@10f19647{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@280d9edc{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@34b27915{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1cb7936c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@778d82e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@700f518a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@3724b43e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@53a9fcfd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@557eb543{/storage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@524a2ffb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@37864b77{/storage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@55d9b8f0{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3fbfbf84{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@6ba7383d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@23b3aa8c{/environment,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@35764bef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@3901f6af{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@681e144{/stages,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@3d5790ea{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@100c567f{/executors,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@6c15e8c7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@48cd9a2c{/api,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@12c60152{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@36b310aa{/jobs/job/kill,null,STOPPED,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@6778aea6{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6da9dc6{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@790a251b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@134c370e{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@62573c86{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3bbf9027{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@12c60152{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@36b310aa{/jobs/job/kill,null,STOPPED,@Spark}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@36b310aa{/jobs/job/kill,null,STARTING,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ServletHandler@76c387f9{STOPPED}
2022-01-12 15:09:49 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-3874b815[EMBEDDED:null]
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$2-3874b815==org.apache.spark.ui.JettyUtils$$anon$2@31c25889{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-45e1aa48=org.apache.spark.ui.HttpSecurityFilter-45e1aa48==org.apache.spark.ui.HttpSecurityFilter@45e1aa48{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-45e1aa48]
2022-01-12 15:09:49 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:49 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-3874b815=org.apache.spark.ui.JettyUtils$$anon$2-3874b815==org.apache.spark.ui.JettyUtils$$anon$2@31c25889{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting ServletHandler@76c387f9{STARTING}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4452ms ServletHandler@76c387f9{STARTED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-45e1aa48==org.apache.spark.ui.HttpSecurityFilter@45e1aa48{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4453ms org.apache.spark.ui.HttpSecurityFilter-45e1aa48==org.apache.spark.ui.HttpSecurityFilter@45e1aa48{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@6cd164a6
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$2-3874b815==org.apache.spark.ui.JettyUtils$$anon$2@31c25889{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4453ms org.apache.spark.ui.JettyUtils$$anon$2-3874b815==org.apache.spark.ui.JettyUtils$$anon$2@31c25889{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$2-3874b815
2022-01-12 15:09:49 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@36b310aa{/jobs/job/kill,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4454ms o.s.j.s.ServletContextHandler@36b310aa{/jobs/job/kill,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting GzipHandler@12c60152{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@12c60152{STARTING,min=32,inflate=-1} added {DeflaterPool@242a209e{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting GzipHandler@12c60152{STARTING,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@242a209e{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4454ms DeflaterPool@242a209e{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4454ms GzipHandler@12c60152{STARTED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@45f421c{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-64469d8==org.apache.spark.ui.HttpSecurityFilter@64469d8{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ServletHandler@45f421c{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-64469d8,POJO}
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG GzipHandler:208 - GzipHandler@2b8bd798{STOPPED,min=32,inflate=-1} mime types IncludeExclude@4c18621b{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@2b8bd798{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@1976f537{/stages/stage/kill,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@36061cf3{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@53dad875{/,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@bfc14b9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6601cc93{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@524a2ffb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@37864b77{/storage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@55d9b8f0{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3fbfbf84{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@6c15e8c7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@48cd9a2c{/api,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@6778aea6{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6da9dc6{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@790a251b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@134c370e{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@75fa1be3{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@15e0fe05{/static,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@702b06fb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@30669dac{/executors/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@7139bd31{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5d01ea21{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@10f19647{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@280d9edc{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@34b27915{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1cb7936c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@778d82e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@700f518a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@3724b43e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@53a9fcfd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@557eb543{/storage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages/stage/kill->[{GzipHandler@2b8bd798{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1976f537{/stages/stage/kill,null,STOPPED,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@35764bef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@6ba7383d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@23b3aa8c{/environment,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@3901f6af{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@681e144{/stages,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@3d5790ea{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@100c567f{/executors,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@12c60152{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@36b310aa{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@62573c86{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3bbf9027{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@2b8bd798{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@1976f537{/stages/stage/kill,null,STOPPED,@Spark}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@1976f537{/stages/stage/kill,null,STARTING,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting ServletHandler@45f421c{STOPPED}
2022-01-12 15:09:49 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-1816e24a[EMBEDDED:null]
2022-01-12 15:09:49 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$2-1816e24a==org.apache.spark.ui.JettyUtils$$anon$2@57e06133{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-64469d8=org.apache.spark.ui.HttpSecurityFilter-64469d8==org.apache.spark.ui.HttpSecurityFilter@64469d8{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-64469d8]
2022-01-12 15:09:49 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:49 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:49 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-1816e24a=org.apache.spark.ui.JettyUtils$$anon$2-1816e24a==org.apache.spark.ui.JettyUtils$$anon$2@57e06133{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting ServletHandler@45f421c{STARTING}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4462ms ServletHandler@45f421c{STARTED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-64469d8==org.apache.spark.ui.HttpSecurityFilter@64469d8{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4463ms org.apache.spark.ui.HttpSecurityFilter-64469d8==org.apache.spark.ui.HttpSecurityFilter@64469d8{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@39c385d6
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$2-1816e24a==org.apache.spark.ui.JettyUtils$$anon$2@57e06133{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4463ms org.apache.spark.ui.JettyUtils$$anon$2-1816e24a==org.apache.spark.ui.JettyUtils$$anon$2@57e06133{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:49 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$2-1816e24a
2022-01-12 15:09:49 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@1976f537{/stages/stage/kill,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4464ms o.s.j.s.ServletContextHandler@1976f537{/stages/stage/kill,null,AVAILABLE,@Spark}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting GzipHandler@2b8bd798{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG ContainerLifeCycle:412 - GzipHandler@2b8bd798{STARTING,min=32,inflate=-1} added {DeflaterPool@1cec219f{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:49 DEBUG AbstractHandler:94 - starting GzipHandler@2b8bd798{STARTING,min=32,inflate=-1}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@1cec219f{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4464ms DeflaterPool@1cec219f{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:49 DEBUG AbstractLifeCycle:191 - STARTED @4464ms GzipHandler@2b8bd798{STARTED,min=32,inflate=-1}
2022-01-12 15:09:49 INFO  SparkUI:57 - Bound SparkUI to 0.0.0.0, and started at http://host.docker.internal:4040
2022-01-12 15:09:50 INFO  Executor:57 - Starting executor ID driver on host host.docker.internal
2022-01-12 15:09:50 DEBUG TransportServer:153 - Shuffle server started on port: 64148
2022-01-12 15:09:50 INFO  Utils:57 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64148.
2022-01-12 15:09:50 INFO  NettyBlockTransferService:81 - Server created on host.docker.internal:64148
2022-01-12 15:09:50 INFO  BlockManager:57 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022-01-12 15:09:50 INFO  BlockManagerMaster:57 - Registering BlockManager BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:50 DEBUG DefaultTopologyMapper:61 - Got a request for host.docker.internal
2022-01-12 15:09:50 INFO  BlockManagerMasterEndpoint:57 - Registering block manager host.docker.internal:64148 with 2.2 GiB RAM, BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:50 INFO  BlockManagerMaster:57 - Registered BlockManager BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:50 INFO  BlockManager:57 - Initialized BlockManager: BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:50 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@c386958
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@157ec23b{/,null,STOPPED} added {ServletHandler@44d64d4e{STOPPED},MANAGED}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ServletHandler@44d64d4e{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-1dd74143==org.apache.spark.ui.JettyUtils$$anon$1@d2281450{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ServletHandler@44d64d4e{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-1dd74143,POJO}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ServletHandler@44d64d4e{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-df921b1==org.apache.spark.ui.HttpSecurityFilter@df921b1{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ServletHandler@44d64d4e{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-df921b1,POJO}
2022-01-12 15:09:50 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:50 DEBUG GzipHandler:208 - GzipHandler@4db60246{STOPPED,min=32,inflate=-1} mime types IncludeExclude@2152ab30{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - GzipHandler@4db60246{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@157ec23b{/metrics/json,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@36061cf3{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@53dad875{/,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@bfc14b9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6601cc93{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@524a2ffb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@37864b77{/storage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@55d9b8f0{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3fbfbf84{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@6c15e8c7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@48cd9a2c{/api,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@6778aea6{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6da9dc6{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@790a251b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@134c370e{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@75fa1be3{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@15e0fe05{/static,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@702b06fb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@30669dac{/executors/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@7139bd31{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5d01ea21{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@10f19647{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@280d9edc{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@34b27915{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1cb7936c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@778d82e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@700f518a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@3724b43e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@53a9fcfd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@557eb543{/storage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/stage/kill->[{GzipHandler@2b8bd798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1976f537{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@35764bef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@6ba7383d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@23b3aa8c{/environment,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@3901f6af{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@681e144{/stages,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@3d5790ea{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@100c567f{/executors,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@12c60152{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@36b310aa{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - metrics/json->[{GzipHandler@4db60246{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@157ec23b{/metrics/json,null,STOPPED,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@62573c86{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3bbf9027{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@4db60246{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@157ec23b{/metrics/json,null,STOPPED,@Spark}
2022-01-12 15:09:50 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@157ec23b{/metrics/json,null,STARTING,@Spark}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting ServletHandler@44d64d4e{STOPPED}
2022-01-12 15:09:50 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-1dd74143[EMBEDDED:null]
2022-01-12 15:09:50 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-1dd74143==org.apache.spark.ui.JettyUtils$$anon$1@d2281450{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:50 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-df921b1=org.apache.spark.ui.HttpSecurityFilter-df921b1==org.apache.spark.ui.HttpSecurityFilter@df921b1{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:50 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-df921b1]
2022-01-12 15:09:50 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:50 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:50 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-1dd74143=org.apache.spark.ui.JettyUtils$$anon$1-1dd74143==org.apache.spark.ui.JettyUtils$$anon$1@d2281450{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:50 DEBUG AbstractHandler:94 - starting ServletHandler@44d64d4e{STARTING}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5009ms ServletHandler@44d64d4e{STARTED}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-df921b1==org.apache.spark.ui.HttpSecurityFilter@df921b1{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5009ms org.apache.spark.ui.HttpSecurityFilter-df921b1==org.apache.spark.ui.HttpSecurityFilter@df921b1{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:50 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@3902bd2c
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-1dd74143==org.apache.spark.ui.JettyUtils$$anon$1@d2281450{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5010ms org.apache.spark.ui.JettyUtils$$anon$1-1dd74143==org.apache.spark.ui.JettyUtils$$anon$1@d2281450{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:50 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-1dd74143
2022-01-12 15:09:50 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@157ec23b{/metrics/json,null,AVAILABLE,@Spark}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5010ms o.s.j.s.ServletContextHandler@157ec23b{/metrics/json,null,AVAILABLE,@Spark}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting GzipHandler@4db60246{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - GzipHandler@4db60246{STARTING,min=32,inflate=-1} added {DeflaterPool@7d32e714{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:50 DEBUG AbstractHandler:94 - starting GzipHandler@4db60246{STARTING,min=32,inflate=-1}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@7d32e714{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5011ms DeflaterPool@7d32e714{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5011ms GzipHandler@4db60246{STARTED,min=32,inflate=-1}
2022-01-12 15:09:50 DEBUG SparkContext:61 - Adding shutdown hook
2022-01-12 15:09:50 DEBUG FileSystem:3209 - Loading filesystems
2022-01-12 15:09:50 DEBUG FileSystem:3221 - file:// = class org.apache.hadoop.fs.LocalFileSystem from /C:/Users/Rahul Kabothula/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0.jar
2022-01-12 15:09:50 DEBUG FileSystem:3221 - viewfs:// = class org.apache.hadoop.fs.viewfs.ViewFileSystem from /C:/Users/Rahul Kabothula/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0.jar
2022-01-12 15:09:50 DEBUG FileSystem:3221 - har:// = class org.apache.hadoop.fs.HarFileSystem from /C:/Users/Rahul Kabothula/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0.jar
2022-01-12 15:09:50 DEBUG FileSystem:3221 - http:// = class org.apache.hadoop.fs.http.HttpFileSystem from /C:/Users/Rahul Kabothula/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0.jar
2022-01-12 15:09:50 DEBUG FileSystem:3221 - https:// = class org.apache.hadoop.fs.http.HttpsFileSystem from /C:/Users/Rahul Kabothula/.m2/repository/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0.jar
2022-01-12 15:09:50 DEBUG FileSystem:3221 - hdfs:// = class org.apache.hadoop.hdfs.DistributedFileSystem from /C:/Users/Rahul Kabothula/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.2.0/hadoop-hdfs-client-3.2.0.jar
2022-01-12 15:09:50 DEBUG FileSystem:3221 - webhdfs:// = class org.apache.hadoop.hdfs.web.WebHdfsFileSystem from /C:/Users/Rahul Kabothula/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.2.0/hadoop-hdfs-client-3.2.0.jar
2022-01-12 15:09:50 DEBUG FileSystem:3221 - swebhdfs:// = class org.apache.hadoop.hdfs.web.SWebHdfsFileSystem from /C:/Users/Rahul Kabothula/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.2.0/hadoop-hdfs-client-3.2.0.jar
2022-01-12 15:09:50 DEBUG FileSystem:3264 - Looking for FS supporting file
2022-01-12 15:09:50 DEBUG FileSystem:3268 - looking for configuration option fs.file.impl
2022-01-12 15:09:50 DEBUG FileSystem:3275 - Looking in service filesystems for implementation class
2022-01-12 15:09:50 DEBUG FileSystem:3284 - FS for file is class org.apache.hadoop.fs.LocalFileSystem
2022-01-12 15:09:50 INFO  SharedState:57 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Rahul%20Kabothula/Intellij%20Maven%20Projects/retail_db/spark-warehouse').
2022-01-12 15:09:50 INFO  SharedState:57 - Warehouse path is 'file:/C:/Users/Rahul%20Kabothula/Intellij%20Maven%20Projects/retail_db/spark-warehouse'.
2022-01-12 15:09:50 DEBUG SharedState:61 - Applying other initial session options to HadoopConf: spark.master -> local[*]
2022-01-12 15:09:50 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@68f6e55d
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@6fff46bf{/,null,STOPPED} added {ServletHandler@1835dc92{STOPPED},MANAGED}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ServletHandler@1835dc92{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-3aaa3c39==org.apache.spark.ui.JettyUtils$$anon$1@6954d2{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ServletHandler@1835dc92{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-3aaa3c39,POJO}
2022-01-12 15:09:50 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@65a9ea3c
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@70f68288{/,null,STOPPED} added {ServletHandler@46911148{STOPPED},MANAGED}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ServletHandler@46911148{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-2db1b657==org.apache.spark.ui.JettyUtils$$anon$1@365ffee5{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ServletHandler@46911148{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-2db1b657,POJO}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ServletHandler@1835dc92{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-7e351d7==org.apache.spark.ui.HttpSecurityFilter@7e351d7{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ServletHandler@1835dc92{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-7e351d7,POJO}
2022-01-12 15:09:50 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:50 DEBUG GzipHandler:208 - GzipHandler@43c57161{STOPPED,min=32,inflate=-1} mime types IncludeExclude@d902300{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - GzipHandler@43c57161{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@6fff46bf{/SQL,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@36061cf3{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@53dad875{/,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@bfc14b9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6601cc93{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@524a2ffb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@37864b77{/storage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@55d9b8f0{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3fbfbf84{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@6c15e8c7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@48cd9a2c{/api,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@6778aea6{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6da9dc6{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@790a251b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@134c370e{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@75fa1be3{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@15e0fe05{/static,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@702b06fb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@30669dac{/executors/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@7139bd31{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5d01ea21{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@10f19647{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@280d9edc{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@34b27915{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1cb7936c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@778d82e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@700f518a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@3724b43e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@53a9fcfd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@557eb543{/storage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - SQL->[{GzipHandler@43c57161{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff46bf{/SQL,null,STOPPED,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/stage/kill->[{GzipHandler@2b8bd798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1976f537{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@35764bef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@6ba7383d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@23b3aa8c{/environment,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@3901f6af{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@681e144{/stages,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@3d5790ea{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@100c567f{/executors,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@12c60152{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@36b310aa{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - metrics/json->[{GzipHandler@4db60246{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@157ec23b{/metrics/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@62573c86{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3bbf9027{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@43c57161{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@6fff46bf{/SQL,null,STOPPED,@Spark}
2022-01-12 15:09:50 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@6fff46bf{/SQL,null,STARTING,@Spark}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting ServletHandler@1835dc92{STOPPED}
2022-01-12 15:09:50 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-3aaa3c39[EMBEDDED:null]
2022-01-12 15:09:50 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-3aaa3c39==org.apache.spark.ui.JettyUtils$$anon$1@6954d2{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:50 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-7e351d7=org.apache.spark.ui.HttpSecurityFilter-7e351d7==org.apache.spark.ui.HttpSecurityFilter@7e351d7{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:50 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-7e351d7]
2022-01-12 15:09:50 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:50 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:50 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-3aaa3c39=org.apache.spark.ui.JettyUtils$$anon$1-3aaa3c39==org.apache.spark.ui.JettyUtils$$anon$1@6954d2{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:50 DEBUG AbstractHandler:94 - starting ServletHandler@1835dc92{STARTING}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5304ms ServletHandler@1835dc92{STARTED}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-7e351d7==org.apache.spark.ui.HttpSecurityFilter@7e351d7{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5304ms org.apache.spark.ui.HttpSecurityFilter-7e351d7==org.apache.spark.ui.HttpSecurityFilter@7e351d7{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:50 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@2db33feb
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-3aaa3c39==org.apache.spark.ui.JettyUtils$$anon$1@6954d2{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5305ms org.apache.spark.ui.JettyUtils$$anon$1-3aaa3c39==org.apache.spark.ui.JettyUtils$$anon$1@6954d2{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:50 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-3aaa3c39
2022-01-12 15:09:50 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@6fff46bf{/SQL,null,AVAILABLE,@Spark}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5305ms o.s.j.s.ServletContextHandler@6fff46bf{/SQL,null,AVAILABLE,@Spark}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting GzipHandler@43c57161{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - GzipHandler@43c57161{STARTING,min=32,inflate=-1} added {DeflaterPool@30c3ae63{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:50 DEBUG AbstractHandler:94 - starting GzipHandler@43c57161{STARTING,min=32,inflate=-1}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@30c3ae63{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5306ms DeflaterPool@30c3ae63{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5306ms GzipHandler@43c57161{STARTED,min=32,inflate=-1}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ServletHandler@46911148{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-58658f63==org.apache.spark.ui.HttpSecurityFilter@58658f63{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ServletHandler@46911148{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-58658f63,POJO}
2022-01-12 15:09:50 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:50 DEBUG GzipHandler:208 - GzipHandler@54e12f4c{STOPPED,min=32,inflate=-1} mime types IncludeExclude@60990e5c{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - GzipHandler@54e12f4c{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@70f68288{/SQL/json,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@36061cf3{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@53dad875{/,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@bfc14b9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6601cc93{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@524a2ffb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@37864b77{/storage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@55d9b8f0{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3fbfbf84{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@6c15e8c7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@48cd9a2c{/api,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@6778aea6{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6da9dc6{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@790a251b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@134c370e{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@75fa1be3{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@15e0fe05{/static,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@702b06fb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@30669dac{/executors/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@7139bd31{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5d01ea21{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@10f19647{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@280d9edc{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@34b27915{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1cb7936c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@778d82e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@700f518a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@3724b43e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@53a9fcfd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@557eb543{/storage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - SQL->[{GzipHandler@43c57161{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff46bf{/SQL,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/stage/kill->[{GzipHandler@2b8bd798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1976f537{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@35764bef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@6ba7383d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@23b3aa8c{/environment,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@3901f6af{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@681e144{/stages,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@3d5790ea{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@100c567f{/executors,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - SQL/json->[{GzipHandler@54e12f4c{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@70f68288{/SQL/json,null,STOPPED,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@12c60152{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@36b310aa{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - metrics/json->[{GzipHandler@4db60246{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@157ec23b{/metrics/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@62573c86{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3bbf9027{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@54e12f4c{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@70f68288{/SQL/json,null,STOPPED,@Spark}
2022-01-12 15:09:50 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@70f68288{/SQL/json,null,STARTING,@Spark}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting ServletHandler@46911148{STOPPED}
2022-01-12 15:09:50 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-2db1b657[EMBEDDED:null]
2022-01-12 15:09:50 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-2db1b657==org.apache.spark.ui.JettyUtils$$anon$1@365ffee5{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:50 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-58658f63=org.apache.spark.ui.HttpSecurityFilter-58658f63==org.apache.spark.ui.HttpSecurityFilter@58658f63{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:50 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-58658f63]
2022-01-12 15:09:50 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:50 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:50 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-2db1b657=org.apache.spark.ui.JettyUtils$$anon$1-2db1b657==org.apache.spark.ui.JettyUtils$$anon$1@365ffee5{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:50 DEBUG AbstractHandler:94 - starting ServletHandler@46911148{STARTING}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5314ms ServletHandler@46911148{STARTED}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-58658f63==org.apache.spark.ui.HttpSecurityFilter@58658f63{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5314ms org.apache.spark.ui.HttpSecurityFilter-58658f63==org.apache.spark.ui.HttpSecurityFilter@58658f63{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:50 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@4d84049a
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-2db1b657==org.apache.spark.ui.JettyUtils$$anon$1@365ffee5{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5315ms org.apache.spark.ui.JettyUtils$$anon$1-2db1b657==org.apache.spark.ui.JettyUtils$$anon$1@365ffee5{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:50 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-2db1b657
2022-01-12 15:09:50 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@70f68288{/SQL/json,null,AVAILABLE,@Spark}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5316ms o.s.j.s.ServletContextHandler@70f68288{/SQL/json,null,AVAILABLE,@Spark}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting GzipHandler@54e12f4c{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - GzipHandler@54e12f4c{STARTING,min=32,inflate=-1} added {DeflaterPool@39ee94de{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:50 DEBUG AbstractHandler:94 - starting GzipHandler@54e12f4c{STARTING,min=32,inflate=-1}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@39ee94de{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5317ms DeflaterPool@39ee94de{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5317ms GzipHandler@54e12f4c{STARTED,min=32,inflate=-1}
2022-01-12 15:09:50 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@4c6b4ed7
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@21263314{/,null,STOPPED} added {ServletHandler@6ca30b8a{STOPPED},MANAGED}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ServletHandler@6ca30b8a{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-4a92c6a9==org.apache.spark.ui.JettyUtils$$anon$1@2187869f{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ServletHandler@6ca30b8a{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-4a92c6a9,POJO}
2022-01-12 15:09:50 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@5c9934da
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@4cb702ce{/,null,STOPPED} added {ServletHandler@383caf89{STOPPED},MANAGED}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ServletHandler@383caf89{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$1-64c781a9==org.apache.spark.ui.JettyUtils$$anon$1@ecafd6d1{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ServletHandler@383caf89{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$1-64c781a9,POJO}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ServletHandler@6ca30b8a{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-71ed560f==org.apache.spark.ui.HttpSecurityFilter@71ed560f{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ServletHandler@6ca30b8a{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-71ed560f,POJO}
2022-01-12 15:09:50 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:50 DEBUG GzipHandler:208 - GzipHandler@5b88b8e{STOPPED,min=32,inflate=-1} mime types IncludeExclude@58253c57{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - GzipHandler@5b88b8e{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@21263314{/SQL/execution,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@36061cf3{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@53dad875{/,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@bfc14b9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6601cc93{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@524a2ffb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@37864b77{/storage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@55d9b8f0{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3fbfbf84{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@6c15e8c7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@48cd9a2c{/api,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@6778aea6{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6da9dc6{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@790a251b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@134c370e{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@75fa1be3{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@15e0fe05{/static,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@702b06fb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@30669dac{/executors/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@7139bd31{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5d01ea21{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@10f19647{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@280d9edc{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@34b27915{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1cb7936c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@778d82e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@700f518a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@3724b43e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@53a9fcfd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@557eb543{/storage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - SQL->[{GzipHandler@43c57161{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff46bf{/SQL,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/stage/kill->[{GzipHandler@2b8bd798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1976f537{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@35764bef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@6ba7383d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@23b3aa8c{/environment,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@3901f6af{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@681e144{/stages,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@3d5790ea{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@100c567f{/executors,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - SQL/json->[{GzipHandler@54e12f4c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@70f68288{/SQL/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@12c60152{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@36b310aa{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - metrics/json->[{GzipHandler@4db60246{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@157ec23b{/metrics/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - SQL/execution->[{GzipHandler@5b88b8e{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@21263314{/SQL/execution,null,STOPPED,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@62573c86{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3bbf9027{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@5b88b8e{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@21263314{/SQL/execution,null,STOPPED,@Spark}
2022-01-12 15:09:50 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@21263314{/SQL/execution,null,STARTING,@Spark}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting ServletHandler@6ca30b8a{STOPPED}
2022-01-12 15:09:50 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-4a92c6a9[EMBEDDED:null]
2022-01-12 15:09:50 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-4a92c6a9==org.apache.spark.ui.JettyUtils$$anon$1@2187869f{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:50 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-71ed560f=org.apache.spark.ui.HttpSecurityFilter-71ed560f==org.apache.spark.ui.HttpSecurityFilter@71ed560f{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:50 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-71ed560f]
2022-01-12 15:09:50 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:50 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:50 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-4a92c6a9=org.apache.spark.ui.JettyUtils$$anon$1-4a92c6a9==org.apache.spark.ui.JettyUtils$$anon$1@2187869f{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:50 DEBUG AbstractHandler:94 - starting ServletHandler@6ca30b8a{STARTING}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5325ms ServletHandler@6ca30b8a{STARTED}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-71ed560f==org.apache.spark.ui.HttpSecurityFilter@71ed560f{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5325ms org.apache.spark.ui.HttpSecurityFilter-71ed560f==org.apache.spark.ui.HttpSecurityFilter@71ed560f{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:50 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@b73433
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-4a92c6a9==org.apache.spark.ui.JettyUtils$$anon$1@2187869f{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5326ms org.apache.spark.ui.JettyUtils$$anon$1-4a92c6a9==org.apache.spark.ui.JettyUtils$$anon$1@2187869f{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:50 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-4a92c6a9
2022-01-12 15:09:50 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@21263314{/SQL/execution,null,AVAILABLE,@Spark}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5326ms o.s.j.s.ServletContextHandler@21263314{/SQL/execution,null,AVAILABLE,@Spark}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting GzipHandler@5b88b8e{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - GzipHandler@5b88b8e{STARTING,min=32,inflate=-1} added {DeflaterPool@1bf14704{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:50 DEBUG AbstractHandler:94 - starting GzipHandler@5b88b8e{STARTING,min=32,inflate=-1}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@1bf14704{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5327ms DeflaterPool@1bf14704{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5327ms GzipHandler@5b88b8e{STARTED,min=32,inflate=-1}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ServletHandler@383caf89{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-5a545b0f==org.apache.spark.ui.HttpSecurityFilter@5a545b0f{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ServletHandler@383caf89{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-5a545b0f,POJO}
2022-01-12 15:09:50 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:50 DEBUG GzipHandler:208 - GzipHandler@2be21396{STOPPED,min=32,inflate=-1} mime types IncludeExclude@124dac75{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - GzipHandler@2be21396{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@4cb702ce{/SQL/execution/json,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@36061cf3{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@53dad875{/,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@bfc14b9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6601cc93{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@524a2ffb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@37864b77{/storage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@55d9b8f0{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3fbfbf84{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - SQL/execution/json->[{GzipHandler@2be21396{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4cb702ce{/SQL/execution/json,null,STOPPED,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@6c15e8c7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@48cd9a2c{/api,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@6778aea6{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6da9dc6{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@790a251b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@134c370e{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@75fa1be3{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@15e0fe05{/static,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@702b06fb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@30669dac{/executors/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@7139bd31{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5d01ea21{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@10f19647{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@280d9edc{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@34b27915{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1cb7936c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@778d82e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@700f518a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@3724b43e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@53a9fcfd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@557eb543{/storage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - SQL->[{GzipHandler@43c57161{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff46bf{/SQL,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/stage/kill->[{GzipHandler@2b8bd798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1976f537{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@35764bef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@6ba7383d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@23b3aa8c{/environment,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@3901f6af{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@681e144{/stages,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@3d5790ea{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@100c567f{/executors,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - SQL/json->[{GzipHandler@54e12f4c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@70f68288{/SQL/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@12c60152{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@36b310aa{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - metrics/json->[{GzipHandler@4db60246{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@157ec23b{/metrics/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - SQL/execution->[{GzipHandler@5b88b8e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@21263314{/SQL/execution,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@62573c86{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3bbf9027{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@2be21396{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@4cb702ce{/SQL/execution/json,null,STOPPED,@Spark}
2022-01-12 15:09:50 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@4cb702ce{/SQL/execution/json,null,STARTING,@Spark}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting ServletHandler@383caf89{STOPPED}
2022-01-12 15:09:50 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-64c781a9[EMBEDDED:null]
2022-01-12 15:09:50 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$1-64c781a9==org.apache.spark.ui.JettyUtils$$anon$1@ecafd6d1{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:50 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-5a545b0f=org.apache.spark.ui.HttpSecurityFilter-5a545b0f==org.apache.spark.ui.HttpSecurityFilter@5a545b0f{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:50 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-5a545b0f]
2022-01-12 15:09:50 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:50 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:50 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-64c781a9=org.apache.spark.ui.JettyUtils$$anon$1-64c781a9==org.apache.spark.ui.JettyUtils$$anon$1@ecafd6d1{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:50 DEBUG AbstractHandler:94 - starting ServletHandler@383caf89{STARTING}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5337ms ServletHandler@383caf89{STARTED}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-5a545b0f==org.apache.spark.ui.HttpSecurityFilter@5a545b0f{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5337ms org.apache.spark.ui.HttpSecurityFilter-5a545b0f==org.apache.spark.ui.HttpSecurityFilter@5a545b0f{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:50 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@315105f
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$1-64c781a9==org.apache.spark.ui.JettyUtils$$anon$1@ecafd6d1{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5337ms org.apache.spark.ui.JettyUtils$$anon$1-64c781a9==org.apache.spark.ui.JettyUtils$$anon$1@ecafd6d1{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:50 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$1-64c781a9
2022-01-12 15:09:50 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@4cb702ce{/SQL/execution/json,null,AVAILABLE,@Spark}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5338ms o.s.j.s.ServletContextHandler@4cb702ce{/SQL/execution/json,null,AVAILABLE,@Spark}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting GzipHandler@2be21396{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - GzipHandler@2be21396{STARTING,min=32,inflate=-1} added {DeflaterPool@7b61bf11{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:50 DEBUG AbstractHandler:94 - starting GzipHandler@2be21396{STARTING,min=32,inflate=-1}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@7b61bf11{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5338ms DeflaterPool@7b61bf11{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5338ms GzipHandler@2be21396{STARTED,min=32,inflate=-1}
2022-01-12 15:09:50 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@18b74ea
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@14924f41{/,null,STOPPED} added {ServletHandler@493da830{STOPPED},MANAGED}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ServletHandler@493da830{STOPPED} added {org.sparkproject.jetty.servlet.DefaultServlet-1f939a0f==org.sparkproject.jetty.servlet.DefaultServlet@2e33abb5{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ServletHandler@493da830{STOPPED} added {[/]=>org.sparkproject.jetty.servlet.DefaultServlet-1f939a0f,POJO}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ServletHandler@493da830{STOPPED} added {org.apache.spark.ui.HttpSecurityFilter-45658133==org.apache.spark.ui.HttpSecurityFilter@45658133{inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ServletHandler@493da830{STOPPED} added {[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-45658133,POJO}
2022-01-12 15:09:50 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-01-12 15:09:50 DEBUG GzipHandler:208 - GzipHandler@430b2699{STOPPED,min=32,inflate=-1} mime types IncludeExclude@67536ae0{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - GzipHandler@430b2699{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@14924f41{/static/sql,null,STOPPED,@Spark},MANAGED}
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@36061cf3{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@53dad875{/,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@bfc14b9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6601cc93{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@524a2ffb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@37864b77{/storage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@55d9b8f0{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3fbfbf84{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - SQL/execution/json->[{GzipHandler@2be21396{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4cb702ce{/SQL/execution/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@6c15e8c7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@48cd9a2c{/api,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@6778aea6{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6da9dc6{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@790a251b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@134c370e{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@63411512{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@ce9b9a9{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@75fa1be3{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@15e0fe05{/static,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@702b06fb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@30669dac{/executors/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@7139bd31{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@5d01ea21{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@10f19647{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@280d9edc{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@34b27915{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1cb7936c{/environment/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@778d82e9{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@66ad7bf0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@34f392be{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1ffcf674{/jobs,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@700f518a{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6145b81e{/stages/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@3724b43e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@31e04b13{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@53a9fcfd{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@557eb543{/storage/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - SQL->[{GzipHandler@43c57161{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff46bf{/SQL,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - static/sql->[{GzipHandler@430b2699{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@14924f41{/static/sql,null,STOPPED,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages/stage/kill->[{GzipHandler@2b8bd798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1976f537{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@35764bef{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7e94d093{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@6ba7383d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@23b3aa8c{/environment,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@3901f6af{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@681e144{/stages,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@3d5790ea{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@100c567f{/executors,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - SQL/json->[{GzipHandler@54e12f4c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@70f68288{/SQL/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@12c60152{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@36b310aa{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - metrics/json->[{GzipHandler@4db60246{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@157ec23b{/metrics/json,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - SQL/execution->[{GzipHandler@5b88b8e{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@21263314{/SQL/execution,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@62573c86{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3bbf9027{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@39c1fe0b{STARTED} added {GzipHandler@430b2699{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@14924f41{/static/sql,null,STOPPED,@Spark}
2022-01-12 15:09:50 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@14924f41{/static/sql,null,STARTING,@Spark}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting ServletHandler@493da830{STOPPED}
2022-01-12 15:09:50 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.sparkproject.jetty.servlet.DefaultServlet-1f939a0f[EMBEDDED:null]
2022-01-12 15:09:50 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.sparkproject.jetty.servlet.DefaultServlet-1f939a0f==org.sparkproject.jetty.servlet.DefaultServlet@2e33abb5{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-01-12 15:09:50 DEBUG ServletHandler:1439 - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-45658133=org.apache.spark.ui.HttpSecurityFilter-45658133==org.apache.spark.ui.HttpSecurityFilter@45658133{inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:50 DEBUG ServletHandler:1440 - pathFilters=[[/*]/[]/[INCLUDE, ERROR, FORWARD, REQUEST, ASYNC]=>org.apache.spark.ui.HttpSecurityFilter-45658133]
2022-01-12 15:09:50 DEBUG ServletHandler:1441 - servletFilterMap={}
2022-01-12 15:09:50 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-01-12 15:09:50 DEBUG ServletHandler:1443 - servletNameMap={org.sparkproject.jetty.servlet.DefaultServlet-1f939a0f=org.sparkproject.jetty.servlet.DefaultServlet-1f939a0f==org.sparkproject.jetty.servlet.DefaultServlet@2e33abb5{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-01-12 15:09:50 DEBUG AbstractHandler:94 - starting ServletHandler@493da830{STARTING}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5347ms ServletHandler@493da830{STARTED}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.HttpSecurityFilter-45658133==org.apache.spark.ui.HttpSecurityFilter@45658133{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5348ms org.apache.spark.ui.HttpSecurityFilter-45658133==org.apache.spark.ui.HttpSecurityFilter@45658133{inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:50 DEBUG FilterHolder:139 - Filter.init org.apache.spark.ui.HttpSecurityFilter@6413d7e7
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting org.sparkproject.jetty.servlet.DefaultServlet-1f939a0f==org.sparkproject.jetty.servlet.DefaultServlet@2e33abb5{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5348ms org.sparkproject.jetty.servlet.DefaultServlet-1f939a0f==org.sparkproject.jetty.servlet.DefaultServlet@2e33abb5{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-01-12 15:09:50 DEBUG ServletHolder:621 - Servlet.init null for org.sparkproject.jetty.servlet.DefaultServlet-1f939a0f
2022-01-12 15:09:50 DEBUG FsUrlStreamHandlerFactory:89 - Creating handler for protocol jar
2022-01-12 15:09:50 DEBUG FileSystem:3264 - Looking for FS supporting jar
2022-01-12 15:09:50 DEBUG FileSystem:3268 - looking for configuration option fs.jar.impl
2022-01-12 15:09:50 DEBUG FileSystem:3275 - Looking in service filesystems for implementation class
2022-01-12 15:09:50 DEBUG FsUrlStreamHandlerFactory:107 - Unknown protocol jar, delegating to default implementation
2022-01-12 15:09:50 DEBUG DefaultServlet:308 - resource base = jar:file:/C:/Users/Rahul%20Kabothula/.m2/repository/org/apache/spark/spark-sql_2.12/3.1.2/spark-sql_2.12-3.1.2.jar!/org/apache/spark/sql/execution/ui/static
2022-01-12 15:09:50 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@14924f41{/static/sql,null,AVAILABLE,@Spark}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5366ms o.s.j.s.ServletContextHandler@14924f41{/static/sql,null,AVAILABLE,@Spark}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting GzipHandler@430b2699{STOPPED,min=32,inflate=-1}
2022-01-12 15:09:50 DEBUG ContainerLifeCycle:412 - GzipHandler@430b2699{STARTING,min=32,inflate=-1} added {DeflaterPool@2262d6d5{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-01-12 15:09:50 DEBUG AbstractHandler:94 - starting GzipHandler@430b2699{STARTING,min=32,inflate=-1}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@2262d6d5{STOPPED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5366ms DeflaterPool@2262d6d5{STARTED,size=0,capacity=UNLIMITED}
2022-01-12 15:09:50 DEBUG AbstractLifeCycle:191 - STARTED @5367ms GzipHandler@430b2699{STARTED,min=32,inflate=-1}
2022-01-12 15:09:51 DEBUG Tracer:106 - sampler.classes = ; loaded no samplers
2022-01-12 15:09:52 DEBUG Tracer:128 - span.receiver.classes = ; loaded no span receivers
2022-01-12 15:09:52 DEBUG FileSystem:3264 - Looking for FS supporting file
2022-01-12 15:09:52 DEBUG FileSystem:3268 - looking for configuration option fs.file.impl
2022-01-12 15:09:52 DEBUG FileSystem:3275 - Looking in service filesystems for implementation class
2022-01-12 15:09:52 DEBUG FileSystem:3284 - FS for file is class org.apache.hadoop.fs.LocalFileSystem
2022-01-12 15:09:52 DEBUG DataSource:61 - Some paths were ignored:
  
2022-01-12 15:09:52 INFO  InMemoryFileIndex:57 - It took 47 ms to list leaf files for 1 paths.
2022-01-12 15:09:52 INFO  InMemoryFileIndex:57 - It took 4 ms to list leaf files for 1 paths.
2022-01-12 15:09:53 DEBUG Analyzer$ResolveReferences:61 - Resolving 'value to value#0
2022-01-12 15:09:53 DEBUG Analyzer$ResolveReferences:61 - Resolving 'value to value#6
2022-01-12 15:09:54 INFO  FileSourceStrategy:57 - Pushed Filters: 
2022-01-12 15:09:54 INFO  FileSourceStrategy:57 - Post-Scan Filters: (length(trim(value#0, None)) > 0)
2022-01-12 15:09:54 INFO  FileSourceStrategy:57 - Output Data Schema: struct<value: string>
2022-01-12 15:09:54 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator inputadapter_input_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     inputadapter_input_0 = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while ( inputadapter_input_0.hasNext()) {
/* 026 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 027 */
/* 028 */       do {
/* 029 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 030 */         UTF8String inputadapter_value_0 = inputadapter_isNull_0 ?
/* 031 */         null : (inputadapter_row_0.getUTF8String(0));
/* 032 */
/* 033 */         boolean filter_isNull_0 = true;
/* 034 */         boolean filter_value_0 = false;
/* 035 */         boolean filter_isNull_2 = false;
/* 036 */         UTF8String filter_value_2 = null;
/* 037 */         if (inputadapter_isNull_0) {
/* 038 */           filter_isNull_2 = true;
/* 039 */         } else {
/* 040 */           filter_value_2 = inputadapter_value_0.trim();
/* 041 */         }
/* 042 */         boolean filter_isNull_1 = filter_isNull_2;
/* 043 */         int filter_value_1 = -1;
/* 044 */
/* 045 */         if (!filter_isNull_2) {
/* 046 */           filter_value_1 = (filter_value_2).numChars();
/* 047 */         }
/* 048 */         if (!filter_isNull_1) {
/* 049 */           filter_isNull_0 = false; // resultCode could change nullability.
/* 050 */           filter_value_0 = filter_value_1 > 0;
/* 051 */
/* 052 */         }
/* 053 */         if (filter_isNull_0 || !filter_value_0) continue;
/* 054 */
/* 055 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 056 */
/* 057 */         filter_mutableStateArray_0[0].reset();
/* 058 */
/* 059 */         filter_mutableStateArray_0[0].zeroOutNullBytes();
/* 060 */
/* 061 */         if (inputadapter_isNull_0) {
/* 062 */           filter_mutableStateArray_0[0].setNullAt(0);
/* 063 */         } else {
/* 064 */           filter_mutableStateArray_0[0].write(0, inputadapter_value_0);
/* 065 */         }
/* 066 */         append((filter_mutableStateArray_0[0].getRow()));
/* 067 */
/* 068 */       } while(false);
/* 069 */       if (shouldStop()) return;
/* 070 */     }
/* 071 */   }
/* 072 */
/* 073 */ }

2022-01-12 15:09:54 DEBUG CodeGenerator:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator inputadapter_input_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     inputadapter_input_0 = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while ( inputadapter_input_0.hasNext()) {
/* 026 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 027 */
/* 028 */       do {
/* 029 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 030 */         UTF8String inputadapter_value_0 = inputadapter_isNull_0 ?
/* 031 */         null : (inputadapter_row_0.getUTF8String(0));
/* 032 */
/* 033 */         boolean filter_isNull_0 = true;
/* 034 */         boolean filter_value_0 = false;
/* 035 */         boolean filter_isNull_2 = false;
/* 036 */         UTF8String filter_value_2 = null;
/* 037 */         if (inputadapter_isNull_0) {
/* 038 */           filter_isNull_2 = true;
/* 039 */         } else {
/* 040 */           filter_value_2 = inputadapter_value_0.trim();
/* 041 */         }
/* 042 */         boolean filter_isNull_1 = filter_isNull_2;
/* 043 */         int filter_value_1 = -1;
/* 044 */
/* 045 */         if (!filter_isNull_2) {
/* 046 */           filter_value_1 = (filter_value_2).numChars();
/* 047 */         }
/* 048 */         if (!filter_isNull_1) {
/* 049 */           filter_isNull_0 = false; // resultCode could change nullability.
/* 050 */           filter_value_0 = filter_value_1 > 0;
/* 051 */
/* 052 */         }
/* 053 */         if (filter_isNull_0 || !filter_value_0) continue;
/* 054 */
/* 055 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 056 */
/* 057 */         filter_mutableStateArray_0[0].reset();
/* 058 */
/* 059 */         filter_mutableStateArray_0[0].zeroOutNullBytes();
/* 060 */
/* 061 */         if (inputadapter_isNull_0) {
/* 062 */           filter_mutableStateArray_0[0].setNullAt(0);
/* 063 */         } else {
/* 064 */           filter_mutableStateArray_0[0].write(0, inputadapter_value_0);
/* 065 */         }
/* 066 */         append((filter_mutableStateArray_0[0].getRow()));
/* 067 */
/* 068 */       } while(false);
/* 069 */       if (shouldStop()) return;
/* 070 */     }
/* 071 */   }
/* 072 */
/* 073 */ }

2022-01-12 15:09:54 INFO  CodeGenerator:57 - Code generated in 246.486 ms
2022-01-12 15:09:55 INFO  MemoryStore:57 - Block broadcast_0 stored as values in memory (estimated size 174.3 KiB, free 2.2 GiB)
2022-01-12 15:09:55 DEBUG BlockManager:61 - Put block broadcast_0 locally took 56 ms
2022-01-12 15:09:55 DEBUG BlockManager:61 - Putting block broadcast_0 without replication took 57 ms
2022-01-12 15:09:55 INFO  MemoryStore:57 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 2.2 GiB)
2022-01-12 15:09:55 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_0_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:55 INFO  BlockManagerInfo:57 - Added broadcast_0_piece0 in memory on host.docker.internal:64148 (size: 27.6 KiB, free: 2.2 GiB)
2022-01-12 15:09:55 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_0_piece0
2022-01-12 15:09:55 DEBUG BlockManager:61 - Told master about block broadcast_0_piece0
2022-01-12 15:09:55 DEBUG BlockManager:61 - Put block broadcast_0_piece0 locally took 10 ms
2022-01-12 15:09:55 DEBUG BlockManager:61 - Putting block broadcast_0_piece0 without replication took 10 ms
2022-01-12 15:09:55 INFO  SparkContext:57 - Created broadcast 0 from load at Extract.java:13
2022-01-12 15:09:55 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2022-01-12 15:09:55 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-01-12 15:09:55 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-01-12 15:09:55 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$executeTake$2
2022-01-12 15:09:55 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$executeTake$2) is now cleaned +++
2022-01-12 15:09:55 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$5
2022-01-12 15:09:55 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
2022-01-12 15:09:55 INFO  SparkContext:57 - Starting job: load at Extract.java:13
2022-01-12 15:09:55 DEBUG DAGScheduler:61 - Merging stage rdd profiles: Set()
2022-01-12 15:09:55 INFO  DAGScheduler:57 - Got job 0 (load at Extract.java:13) with 1 output partitions
2022-01-12 15:09:55 INFO  DAGScheduler:57 - Final stage: ResultStage 0 (load at Extract.java:13)
2022-01-12 15:09:55 INFO  DAGScheduler:57 - Parents of final stage: List()
2022-01-12 15:09:55 INFO  DAGScheduler:57 - Missing parents: List()
2022-01-12 15:09:55 DEBUG DAGScheduler:61 - submitStage(ResultStage 0 (name=load at Extract.java:13;jobs=0))
2022-01-12 15:09:55 DEBUG DAGScheduler:61 - missing: List()
2022-01-12 15:09:55 INFO  DAGScheduler:57 - Submitting ResultStage 0 (MapPartitionsRDD[3] at load at Extract.java:13), which has no missing parents
2022-01-12 15:09:55 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 0)
2022-01-12 15:09:55 INFO  MemoryStore:57 - Block broadcast_1 stored as values in memory (estimated size 10.8 KiB, free 2.2 GiB)
2022-01-12 15:09:55 DEBUG BlockManager:61 - Put block broadcast_1 locally took 3 ms
2022-01-12 15:09:55 DEBUG BlockManager:61 - Putting block broadcast_1 without replication took 4 ms
2022-01-12 15:09:55 INFO  MemoryStore:57 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 2.2 GiB)
2022-01-12 15:09:55 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_1_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:55 INFO  BlockManagerInfo:57 - Added broadcast_1_piece0 in memory on host.docker.internal:64148 (size: 5.4 KiB, free: 2.2 GiB)
2022-01-12 15:09:55 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_1_piece0
2022-01-12 15:09:55 DEBUG BlockManager:61 - Told master about block broadcast_1_piece0
2022-01-12 15:09:55 DEBUG BlockManager:61 - Put block broadcast_1_piece0 locally took 3 ms
2022-01-12 15:09:55 DEBUG BlockManager:61 - Putting block broadcast_1_piece0 without replication took 3 ms
2022-01-12 15:09:55 INFO  SparkContext:57 - Created broadcast 1 from broadcast at DAGScheduler.scala:1388
2022-01-12 15:09:55 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at load at Extract.java:13) (first 15 tasks are for partitions Vector(0))
2022-01-12 15:09:55 INFO  TaskSchedulerImpl:57 - Adding task set 0.0 with 1 tasks resource profile 0
2022-01-12 15:09:55 DEBUG TaskSetManager:61 - Epoch for TaskSet 0.0: 0
2022-01-12 15:09:55 DEBUG TaskSetManager:61 - Adding pending tasks took 2 ms
2022-01-12 15:09:55 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 0.0: NO_PREF, ANY
2022-01-12 15:09:55 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_0.0, runningTasks: 0
2022-01-12 15:09:55 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 0.0: NO_PREF, ANY
2022-01-12 15:09:55 INFO  TaskSetManager:57 - Starting task 0.0 in stage 0.0 (TID 0) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4974 bytes) taskResourceAssignments Map()
2022-01-12 15:09:55 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-01-12 15:09:55 INFO  Executor:57 - Running task 0.0 in stage 0.0 (TID 0)
2022-01-12 15:09:55 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (0, 0) -> 1
2022-01-12 15:09:55 DEBUG BlockManager:61 - Getting local block broadcast_1
2022-01-12 15:09:55 DEBUG BlockManager:61 - Level for block broadcast_1 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:55 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Rahul%20Kabothula/Intellij%20Maven%20Projects/retail_db/result/task4_result/part-00000-68b49292-7121-4eec-b8f7-71802d6a3258-c000.csv, range: 0-1226, partition values: [empty row]
2022-01-12 15:09:55 DEBUG GenerateUnsafeProjection:61 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-12 15:09:55 DEBUG CodeGenerator:61 - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-12 15:09:55 INFO  CodeGenerator:57 - Code generated in 20.9429 ms
2022-01-12 15:09:55 DEBUG BlockManager:61 - Getting local block broadcast_0
2022-01-12 15:09:55 DEBUG BlockManager:61 - Level for block broadcast_0 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:55 INFO  Executor:57 - Finished task 0.0 in stage 0.0 (TID 0). 1566 bytes result sent to driver
2022-01-12 15:09:55 DEBUG ExecutorMetricsPoller:61 - removing (0, 0) from stageTCMP
2022-01-12 15:09:55 INFO  TaskSetManager:57 - Finished task 0.0 in stage 0.0 (TID 0) in 270 ms on host.docker.internal (executor driver) (1/1)
2022-01-12 15:09:55 INFO  TaskSchedulerImpl:57 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-01-12 15:09:55 INFO  DAGScheduler:57 - ResultStage 0 (load at Extract.java:13) finished in 0.457 s
2022-01-12 15:09:55 DEBUG DAGScheduler:61 - After removal of stage 0, remaining stages = 0
2022-01-12 15:09:55 INFO  DAGScheduler:57 - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2022-01-12 15:09:55 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 0: Stage finished
2022-01-12 15:09:55 INFO  DAGScheduler:57 - Job 0 finished: load at Extract.java:13, took 0.527943 s
2022-01-12 15:09:55 DEBUG GenerateSafeProjection:61 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-01-12 15:09:55 DEBUG CodeGenerator:61 - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-01-12 15:09:55 INFO  CodeGenerator:57 - Code generated in 17.8396 ms
2022-01-12 15:09:55 INFO  FileSourceStrategy:57 - Pushed Filters: 
2022-01-12 15:09:55 INFO  FileSourceStrategy:57 - Post-Scan Filters: 
2022-01-12 15:09:55 INFO  FileSourceStrategy:57 - Output Data Schema: struct<value: string>
2022-01-12 15:09:55 INFO  MemoryStore:57 - Block broadcast_2 stored as values in memory (estimated size 174.3 KiB, free 2.2 GiB)
2022-01-12 15:09:55 DEBUG BlockManager:61 - Put block broadcast_2 locally took 6 ms
2022-01-12 15:09:55 DEBUG BlockManager:61 - Putting block broadcast_2 without replication took 7 ms
2022-01-12 15:09:55 INFO  MemoryStore:57 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 2.2 GiB)
2022-01-12 15:09:56 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_2_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:56 INFO  BlockManagerInfo:57 - Added broadcast_2_piece0 in memory on host.docker.internal:64148 (size: 27.6 KiB, free: 2.2 GiB)
2022-01-12 15:09:56 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_2_piece0
2022-01-12 15:09:56 DEBUG BlockManager:61 - Told master about block broadcast_2_piece0
2022-01-12 15:09:56 DEBUG BlockManager:61 - Put block broadcast_2_piece0 locally took 6 ms
2022-01-12 15:09:56 DEBUG BlockManager:61 - Putting block broadcast_2_piece0 without replication took 6 ms
2022-01-12 15:09:56 INFO  SparkContext:57 - Created broadcast 2 from load at Extract.java:13
2022-01-12 15:09:56 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2022-01-12 15:09:56 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$rdd$1
2022-01-12 15:09:56 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$rdd$1) is now cleaned +++
2022-01-12 15:09:56 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$inferFromDataset$2
2022-01-12 15:09:56 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$inferFromDataset$2) is now cleaned +++
2022-01-12 15:09:56 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$infer$2
2022-01-12 15:09:56 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$infer$2) is now cleaned +++
2022-01-12 15:09:56 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$infer$3
2022-01-12 15:09:56 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$infer$3) is now cleaned +++
2022-01-12 15:09:56 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$6
2022-01-12 15:09:56 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$6) is now cleaned +++
2022-01-12 15:09:56 INFO  SparkContext:57 - Starting job: load at Extract.java:13
2022-01-12 15:09:56 DEBUG DAGScheduler:61 - Merging stage rdd profiles: Set()
2022-01-12 15:09:56 INFO  DAGScheduler:57 - Got job 1 (load at Extract.java:13) with 1 output partitions
2022-01-12 15:09:56 INFO  DAGScheduler:57 - Final stage: ResultStage 1 (load at Extract.java:13)
2022-01-12 15:09:56 INFO  DAGScheduler:57 - Parents of final stage: List()
2022-01-12 15:09:56 INFO  DAGScheduler:57 - Missing parents: List()
2022-01-12 15:09:56 DEBUG DAGScheduler:61 - submitStage(ResultStage 1 (name=load at Extract.java:13;jobs=1))
2022-01-12 15:09:56 DEBUG DAGScheduler:61 - missing: List()
2022-01-12 15:09:56 INFO  DAGScheduler:57 - Submitting ResultStage 1 (MapPartitionsRDD[9] at load at Extract.java:13), which has no missing parents
2022-01-12 15:09:56 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 1)
2022-01-12 15:09:56 INFO  MemoryStore:57 - Block broadcast_3 stored as values in memory (estimated size 15.4 KiB, free 2.2 GiB)
2022-01-12 15:09:56 DEBUG BlockManager:61 - Put block broadcast_3 locally took 38 ms
2022-01-12 15:09:56 DEBUG BlockManager:61 - Putting block broadcast_3 without replication took 39 ms
2022-01-12 15:09:56 INFO  MemoryStore:57 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 2.2 GiB)
2022-01-12 15:09:56 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_3_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:56 INFO  BlockManagerInfo:57 - Added broadcast_3_piece0 in memory on host.docker.internal:64148 (size: 7.8 KiB, free: 2.2 GiB)
2022-01-12 15:09:56 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_3_piece0
2022-01-12 15:09:56 DEBUG BlockManager:61 - Told master about block broadcast_3_piece0
2022-01-12 15:09:56 DEBUG BlockManager:61 - Put block broadcast_3_piece0 locally took 2 ms
2022-01-12 15:09:56 DEBUG BlockManager:61 - Putting block broadcast_3_piece0 without replication took 2 ms
2022-01-12 15:09:56 INFO  SparkContext:57 - Created broadcast 3 from broadcast at DAGScheduler.scala:1388
2022-01-12 15:09:56 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at load at Extract.java:13) (first 15 tasks are for partitions Vector(0))
2022-01-12 15:09:56 INFO  TaskSchedulerImpl:57 - Adding task set 1.0 with 1 tasks resource profile 0
2022-01-12 15:09:56 DEBUG TaskSetManager:61 - Epoch for TaskSet 1.0: 0
2022-01-12 15:09:56 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-01-12 15:09:56 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 1.0: NO_PREF, ANY
2022-01-12 15:09:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_1.0, runningTasks: 0
2022-01-12 15:09:56 INFO  TaskSetManager:57 - Starting task 0.0 in stage 1.0 (TID 1) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4974 bytes) taskResourceAssignments Map()
2022-01-12 15:09:56 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-01-12 15:09:56 INFO  Executor:57 - Running task 0.0 in stage 1.0 (TID 1)
2022-01-12 15:09:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (1, 0) -> 1
2022-01-12 15:09:56 DEBUG BlockManager:61 - Getting local block broadcast_3
2022-01-12 15:09:56 DEBUG BlockManager:61 - Level for block broadcast_3 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:56 DEBUG GenerateSafeProjection:61 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-01-12 15:09:56 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Rahul%20Kabothula/Intellij%20Maven%20Projects/retail_db/result/task4_result/part-00000-68b49292-7121-4eec-b8f7-71802d6a3258-c000.csv, range: 0-1226, partition values: [empty row]
2022-01-12 15:09:56 DEBUG GenerateUnsafeProjection:61 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-12 15:09:56 DEBUG BlockManager:61 - Getting local block broadcast_2
2022-01-12 15:09:56 DEBUG BlockManager:61 - Level for block broadcast_2 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:56 INFO  Executor:57 - Finished task 0.0 in stage 1.0 (TID 1). 1659 bytes result sent to driver
2022-01-12 15:09:56 DEBUG ExecutorMetricsPoller:61 - removing (1, 0) from stageTCMP
2022-01-12 15:09:56 INFO  TaskSetManager:57 - Finished task 0.0 in stage 1.0 (TID 1) in 115 ms on host.docker.internal (executor driver) (1/1)
2022-01-12 15:09:56 INFO  TaskSchedulerImpl:57 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022-01-12 15:09:56 INFO  DAGScheduler:57 - ResultStage 1 (load at Extract.java:13) finished in 0.187 s
2022-01-12 15:09:56 DEBUG DAGScheduler:61 - After removal of stage 1, remaining stages = 0
2022-01-12 15:09:56 INFO  DAGScheduler:57 - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2022-01-12 15:09:56 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 1: Stage finished
2022-01-12 15:09:56 INFO  DAGScheduler:57 - Job 1 finished: load at Extract.java:13, took 0.199340 s
2022-01-12 15:09:56 INFO  FileSourceStrategy:57 - Pushed Filters: 
2022-01-12 15:09:56 INFO  FileSourceStrategy:57 - Post-Scan Filters: 
2022-01-12 15:09:56 INFO  FileSourceStrategy:57 - Output Data Schema: struct<>
2022-01-12 15:09:56 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage2(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=2
/* 006 */ final class GeneratedIteratorForCodegenStage2 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private boolean agg_bufIsNull_0;
/* 011 */   private long agg_bufValue_0;
/* 012 */   private scala.collection.Iterator inputadapter_input_0;
/* 013 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] agg_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 014 */
/* 015 */   public GeneratedIteratorForCodegenStage2(Object[] references) {
/* 016 */     this.references = references;
/* 017 */   }
/* 018 */
/* 019 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 020 */     partitionIndex = index;
/* 021 */     this.inputs = inputs;
/* 022 */
/* 023 */     inputadapter_input_0 = inputs[0];
/* 024 */     agg_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 025 */
/* 026 */   }
/* 027 */
/* 028 */   private void agg_doAggregateWithoutKey_0() throws java.io.IOException {
/* 029 */     // initialize aggregation buffer
/* 030 */     agg_bufIsNull_0 = false;
/* 031 */     agg_bufValue_0 = 0L;
/* 032 */
/* 033 */     while ( inputadapter_input_0.hasNext()) {
/* 034 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 035 */
/* 036 */       long inputadapter_value_0 = inputadapter_row_0.getLong(0);
/* 037 */
/* 038 */       agg_doConsume_0(inputadapter_row_0, inputadapter_value_0);
/* 039 */       // shouldStop check is eliminated
/* 040 */     }
/* 041 */
/* 042 */   }
/* 043 */
/* 044 */   private void agg_doConsume_0(InternalRow inputadapter_row_0, long agg_expr_0_0) throws java.io.IOException {
/* 045 */     // do aggregate
/* 046 */     // common sub-expressions
/* 047 */
/* 048 */     // evaluate aggregate functions and update aggregation buffers
/* 049 */
/* 050 */     long agg_value_3 = -1L;
/* 051 */
/* 052 */     agg_value_3 = agg_bufValue_0 + agg_expr_0_0;
/* 053 */
/* 054 */     agg_bufIsNull_0 = false;
/* 055 */     agg_bufValue_0 = agg_value_3;
/* 056 */
/* 057 */   }
/* 058 */
/* 059 */   protected void processNext() throws java.io.IOException {
/* 060 */     while (!agg_initAgg_0) {
/* 061 */       agg_initAgg_0 = true;
/* 062 */       long agg_beforeAgg_0 = System.nanoTime();
/* 063 */       agg_doAggregateWithoutKey_0();
/* 064 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* aggTime */).add((System.nanoTime() - agg_beforeAgg_0) / 1000000);
/* 065 */
/* 066 */       // output the result
/* 067 */
/* 068 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 069 */       agg_mutableStateArray_0[0].reset();
/* 070 */
/* 071 */       agg_mutableStateArray_0[0].zeroOutNullBytes();
/* 072 */
/* 073 */       agg_mutableStateArray_0[0].write(0, agg_bufValue_0);
/* 074 */       append((agg_mutableStateArray_0[0].getRow()));
/* 075 */     }
/* 076 */   }
/* 077 */
/* 078 */ }

2022-01-12 15:09:56 DEBUG CodeGenerator:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage2(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=2
/* 006 */ final class GeneratedIteratorForCodegenStage2 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private boolean agg_bufIsNull_0;
/* 011 */   private long agg_bufValue_0;
/* 012 */   private scala.collection.Iterator inputadapter_input_0;
/* 013 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] agg_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 014 */
/* 015 */   public GeneratedIteratorForCodegenStage2(Object[] references) {
/* 016 */     this.references = references;
/* 017 */   }
/* 018 */
/* 019 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 020 */     partitionIndex = index;
/* 021 */     this.inputs = inputs;
/* 022 */
/* 023 */     inputadapter_input_0 = inputs[0];
/* 024 */     agg_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 025 */
/* 026 */   }
/* 027 */
/* 028 */   private void agg_doAggregateWithoutKey_0() throws java.io.IOException {
/* 029 */     // initialize aggregation buffer
/* 030 */     agg_bufIsNull_0 = false;
/* 031 */     agg_bufValue_0 = 0L;
/* 032 */
/* 033 */     while ( inputadapter_input_0.hasNext()) {
/* 034 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 035 */
/* 036 */       long inputadapter_value_0 = inputadapter_row_0.getLong(0);
/* 037 */
/* 038 */       agg_doConsume_0(inputadapter_row_0, inputadapter_value_0);
/* 039 */       // shouldStop check is eliminated
/* 040 */     }
/* 041 */
/* 042 */   }
/* 043 */
/* 044 */   private void agg_doConsume_0(InternalRow inputadapter_row_0, long agg_expr_0_0) throws java.io.IOException {
/* 045 */     // do aggregate
/* 046 */     // common sub-expressions
/* 047 */
/* 048 */     // evaluate aggregate functions and update aggregation buffers
/* 049 */
/* 050 */     long agg_value_3 = -1L;
/* 051 */
/* 052 */     agg_value_3 = agg_bufValue_0 + agg_expr_0_0;
/* 053 */
/* 054 */     agg_bufIsNull_0 = false;
/* 055 */     agg_bufValue_0 = agg_value_3;
/* 056 */
/* 057 */   }
/* 058 */
/* 059 */   protected void processNext() throws java.io.IOException {
/* 060 */     while (!agg_initAgg_0) {
/* 061 */       agg_initAgg_0 = true;
/* 062 */       long agg_beforeAgg_0 = System.nanoTime();
/* 063 */       agg_doAggregateWithoutKey_0();
/* 064 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* aggTime */).add((System.nanoTime() - agg_beforeAgg_0) / 1000000);
/* 065 */
/* 066 */       // output the result
/* 067 */
/* 068 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 069 */       agg_mutableStateArray_0[0].reset();
/* 070 */
/* 071 */       agg_mutableStateArray_0[0].zeroOutNullBytes();
/* 072 */
/* 073 */       agg_mutableStateArray_0[0].write(0, agg_bufValue_0);
/* 074 */       append((agg_mutableStateArray_0[0].getRow()));
/* 075 */     }
/* 076 */   }
/* 077 */
/* 078 */ }

2022-01-12 15:09:56 INFO  CodeGenerator:57 - Code generated in 21.5715 ms
2022-01-12 15:09:56 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private boolean agg_bufIsNull_0;
/* 011 */   private long agg_bufValue_0;
/* 012 */   private scala.collection.Iterator inputadapter_input_0;
/* 013 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] agg_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 014 */
/* 015 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 016 */     this.references = references;
/* 017 */   }
/* 018 */
/* 019 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 020 */     partitionIndex = index;
/* 021 */     this.inputs = inputs;
/* 022 */
/* 023 */     inputadapter_input_0 = inputs[0];
/* 024 */     agg_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 025 */
/* 026 */   }
/* 027 */
/* 028 */   private void agg_doAggregateWithoutKey_0() throws java.io.IOException {
/* 029 */     // initialize aggregation buffer
/* 030 */     agg_bufIsNull_0 = false;
/* 031 */     agg_bufValue_0 = 0L;
/* 032 */
/* 033 */     while ( inputadapter_input_0.hasNext()) {
/* 034 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 035 */
/* 036 */       agg_doConsume_0(inputadapter_row_0);
/* 037 */       // shouldStop check is eliminated
/* 038 */     }
/* 039 */
/* 040 */   }
/* 041 */
/* 042 */   private void agg_doConsume_0(InternalRow inputadapter_row_0) throws java.io.IOException {
/* 043 */     // do aggregate
/* 044 */     // common sub-expressions
/* 045 */
/* 046 */     // evaluate aggregate functions and update aggregation buffers
/* 047 */
/* 048 */     long agg_value_1 = -1L;
/* 049 */
/* 050 */     agg_value_1 = agg_bufValue_0 + 1L;
/* 051 */
/* 052 */     agg_bufIsNull_0 = false;
/* 053 */     agg_bufValue_0 = agg_value_1;
/* 054 */
/* 055 */   }
/* 056 */
/* 057 */   protected void processNext() throws java.io.IOException {
/* 058 */     while (!agg_initAgg_0) {
/* 059 */       agg_initAgg_0 = true;
/* 060 */       long agg_beforeAgg_0 = System.nanoTime();
/* 061 */       agg_doAggregateWithoutKey_0();
/* 062 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* aggTime */).add((System.nanoTime() - agg_beforeAgg_0) / 1000000);
/* 063 */
/* 064 */       // output the result
/* 065 */
/* 066 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 067 */       agg_mutableStateArray_0[0].reset();
/* 068 */
/* 069 */       agg_mutableStateArray_0[0].zeroOutNullBytes();
/* 070 */
/* 071 */       agg_mutableStateArray_0[0].write(0, agg_bufValue_0);
/* 072 */       append((agg_mutableStateArray_0[0].getRow()));
/* 073 */     }
/* 074 */   }
/* 075 */
/* 076 */ }

2022-01-12 15:09:56 DEBUG CodeGenerator:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private boolean agg_bufIsNull_0;
/* 011 */   private long agg_bufValue_0;
/* 012 */   private scala.collection.Iterator inputadapter_input_0;
/* 013 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] agg_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 014 */
/* 015 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 016 */     this.references = references;
/* 017 */   }
/* 018 */
/* 019 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 020 */     partitionIndex = index;
/* 021 */     this.inputs = inputs;
/* 022 */
/* 023 */     inputadapter_input_0 = inputs[0];
/* 024 */     agg_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 025 */
/* 026 */   }
/* 027 */
/* 028 */   private void agg_doAggregateWithoutKey_0() throws java.io.IOException {
/* 029 */     // initialize aggregation buffer
/* 030 */     agg_bufIsNull_0 = false;
/* 031 */     agg_bufValue_0 = 0L;
/* 032 */
/* 033 */     while ( inputadapter_input_0.hasNext()) {
/* 034 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 035 */
/* 036 */       agg_doConsume_0(inputadapter_row_0);
/* 037 */       // shouldStop check is eliminated
/* 038 */     }
/* 039 */
/* 040 */   }
/* 041 */
/* 042 */   private void agg_doConsume_0(InternalRow inputadapter_row_0) throws java.io.IOException {
/* 043 */     // do aggregate
/* 044 */     // common sub-expressions
/* 045 */
/* 046 */     // evaluate aggregate functions and update aggregation buffers
/* 047 */
/* 048 */     long agg_value_1 = -1L;
/* 049 */
/* 050 */     agg_value_1 = agg_bufValue_0 + 1L;
/* 051 */
/* 052 */     agg_bufIsNull_0 = false;
/* 053 */     agg_bufValue_0 = agg_value_1;
/* 054 */
/* 055 */   }
/* 056 */
/* 057 */   protected void processNext() throws java.io.IOException {
/* 058 */     while (!agg_initAgg_0) {
/* 059 */       agg_initAgg_0 = true;
/* 060 */       long agg_beforeAgg_0 = System.nanoTime();
/* 061 */       agg_doAggregateWithoutKey_0();
/* 062 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* aggTime */).add((System.nanoTime() - agg_beforeAgg_0) / 1000000);
/* 063 */
/* 064 */       // output the result
/* 065 */
/* 066 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 067 */       agg_mutableStateArray_0[0].reset();
/* 068 */
/* 069 */       agg_mutableStateArray_0[0].zeroOutNullBytes();
/* 070 */
/* 071 */       agg_mutableStateArray_0[0].write(0, agg_bufValue_0);
/* 072 */       append((agg_mutableStateArray_0[0].getRow()));
/* 073 */     }
/* 074 */   }
/* 075 */
/* 076 */ }

2022-01-12 15:09:56 INFO  CodeGenerator:57 - Code generated in 19.6146 ms
2022-01-12 15:09:56 INFO  MemoryStore:57 - Block broadcast_4 stored as values in memory (estimated size 174.2 KiB, free 2.2 GiB)
2022-01-12 15:09:56 DEBUG BlockManager:61 - Put block broadcast_4 locally took 6 ms
2022-01-12 15:09:56 DEBUG BlockManager:61 - Putting block broadcast_4 without replication took 6 ms
2022-01-12 15:09:56 INFO  MemoryStore:57 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 2.2 GiB)
2022-01-12 15:09:56 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_4_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:56 INFO  BlockManagerInfo:57 - Added broadcast_4_piece0 in memory on host.docker.internal:64148 (size: 27.6 KiB, free: 2.2 GiB)
2022-01-12 15:09:56 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_4_piece0
2022-01-12 15:09:56 DEBUG BlockManager:61 - Told master about block broadcast_4_piece0
2022-01-12 15:09:56 DEBUG BlockManager:61 - Put block broadcast_4_piece0 locally took 7 ms
2022-01-12 15:09:56 DEBUG BlockManager:61 - Putting block broadcast_4_piece0 without replication took 7 ms
2022-01-12 15:09:56 INFO  SparkContext:57 - Created broadcast 4 from count at LoadTesting.java:45
2022-01-12 15:09:56 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2022-01-12 15:09:56 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-01-12 15:09:56 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-01-12 15:09:56 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-01-12 15:09:56 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-01-12 15:09:56 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$collect$2
2022-01-12 15:09:56 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$collect$2) is now cleaned +++
2022-01-12 15:09:56 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$5
2022-01-12 15:09:56 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
2022-01-12 15:09:56 INFO  SparkContext:57 - Starting job: count at LoadTesting.java:45
2022-01-12 15:09:56 DEBUG DAGScheduler:61 - Merging stage rdd profiles: Set()
2022-01-12 15:09:56 DEBUG DAGScheduler:61 - Merging stage rdd profiles: Set()
2022-01-12 15:09:56 INFO  DAGScheduler:57 - Registering RDD 13 (count at LoadTesting.java:45) as input to shuffle 0
2022-01-12 15:09:56 INFO  DAGScheduler:57 - Got job 2 (count at LoadTesting.java:45) with 1 output partitions
2022-01-12 15:09:56 INFO  DAGScheduler:57 - Final stage: ResultStage 3 (count at LoadTesting.java:45)
2022-01-12 15:09:56 INFO  DAGScheduler:57 - Parents of final stage: List(ShuffleMapStage 2)
2022-01-12 15:09:56 INFO  DAGScheduler:57 - Missing parents: List(ShuffleMapStage 2)
2022-01-12 15:09:56 DEBUG DAGScheduler:61 - submitStage(ResultStage 3 (name=count at LoadTesting.java:45;jobs=2))
2022-01-12 15:09:56 DEBUG DAGScheduler:61 - missing: List(ShuffleMapStage 2)
2022-01-12 15:09:56 DEBUG DAGScheduler:61 - submitStage(ShuffleMapStage 2 (name=count at LoadTesting.java:45;jobs=2))
2022-01-12 15:09:56 DEBUG DAGScheduler:61 - missing: List()
2022-01-12 15:09:56 INFO  DAGScheduler:57 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[13] at count at LoadTesting.java:45), which has no missing parents
2022-01-12 15:09:56 DEBUG DAGScheduler:61 - submitMissingTasks(ShuffleMapStage 2)
2022-01-12 15:09:56 INFO  MemoryStore:57 - Block broadcast_5 stored as values in memory (estimated size 15.4 KiB, free 2.2 GiB)
2022-01-12 15:09:56 DEBUG BlockManager:61 - Put block broadcast_5 locally took 3 ms
2022-01-12 15:09:56 DEBUG BlockManager:61 - Putting block broadcast_5 without replication took 4 ms
2022-01-12 15:09:56 INFO  MemoryStore:57 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 2.2 GiB)
2022-01-12 15:09:56 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_5_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:56 INFO  BlockManagerInfo:57 - Added broadcast_5_piece0 in memory on host.docker.internal:64148 (size: 7.9 KiB, free: 2.2 GiB)
2022-01-12 15:09:56 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_5_piece0
2022-01-12 15:09:56 DEBUG BlockManager:61 - Told master about block broadcast_5_piece0
2022-01-12 15:09:56 DEBUG BlockManager:61 - Put block broadcast_5_piece0 locally took 5 ms
2022-01-12 15:09:56 DEBUG BlockManager:61 - Putting block broadcast_5_piece0 without replication took 5 ms
2022-01-12 15:09:56 INFO  SparkContext:57 - Created broadcast 5 from broadcast at DAGScheduler.scala:1388
2022-01-12 15:09:56 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[13] at count at LoadTesting.java:45) (first 15 tasks are for partitions Vector(0))
2022-01-12 15:09:56 INFO  TaskSchedulerImpl:57 - Adding task set 2.0 with 1 tasks resource profile 0
2022-01-12 15:09:56 DEBUG TaskSetManager:61 - Epoch for TaskSet 2.0: 0
2022-01-12 15:09:56 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-01-12 15:09:56 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 2.0: NO_PREF, ANY
2022-01-12 15:09:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_2.0, runningTasks: 0
2022-01-12 15:09:56 INFO  TaskSetManager:57 - Starting task 0.0 in stage 2.0 (TID 2) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4963 bytes) taskResourceAssignments Map()
2022-01-12 15:09:56 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-01-12 15:09:56 INFO  Executor:57 - Running task 0.0 in stage 2.0 (TID 2)
2022-01-12 15:09:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (2, 0) -> 1
2022-01-12 15:09:56 DEBUG BlockManager:61 - Getting local block broadcast_5
2022-01-12 15:09:56 DEBUG BlockManager:61 - Level for block broadcast_5 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:56 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Rahul%20Kabothula/Intellij%20Maven%20Projects/retail_db/result/task4_result/part-00000-68b49292-7121-4eec-b8f7-71802d6a3258-c000.csv, range: 0-1226, partition values: [empty row]
2022-01-12 15:09:56 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-01-12 15:09:56 DEBUG CodeGenerator:61 - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-01-12 15:09:56 INFO  CodeGenerator:57 - Code generated in 10.3802 ms
2022-01-12 15:09:56 DEBUG BlockManager:61 - Getting local block broadcast_4
2022-01-12 15:09:56 DEBUG BlockManager:61 - Level for block broadcast_4 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:56 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 2 with length 1
2022-01-12 15:09:56 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 2: [59]
2022-01-12 15:09:56 INFO  Executor:57 - Finished task 0.0 in stage 2.0 (TID 2). 1973 bytes result sent to driver
2022-01-12 15:09:56 DEBUG ExecutorMetricsPoller:61 - removing (2, 0) from stageTCMP
2022-01-12 15:09:56 INFO  TaskSetManager:57 - Finished task 0.0 in stage 2.0 (TID 2) in 172 ms on host.docker.internal (executor driver) (1/1)
2022-01-12 15:09:56 INFO  TaskSchedulerImpl:57 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022-01-12 15:09:56 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-12 15:09:56 INFO  DAGScheduler:57 - ShuffleMapStage 2 (count at LoadTesting.java:45) finished in 0.188 s
2022-01-12 15:09:56 INFO  DAGScheduler:57 - looking for newly runnable stages
2022-01-12 15:09:56 INFO  DAGScheduler:57 - running: Set()
2022-01-12 15:09:56 INFO  DAGScheduler:57 - waiting: Set(ResultStage 3)
2022-01-12 15:09:56 INFO  DAGScheduler:57 - failed: Set()
2022-01-12 15:09:56 DEBUG MapOutputTrackerMaster:61 - Increasing epoch to 1
2022-01-12 15:09:56 DEBUG DAGScheduler:61 - submitStage(ResultStage 3 (name=count at LoadTesting.java:45;jobs=2))
2022-01-12 15:09:56 DEBUG DAGScheduler:61 - missing: List()
2022-01-12 15:09:56 INFO  DAGScheduler:57 - Submitting ResultStage 3 (MapPartitionsRDD[16] at count at LoadTesting.java:45), which has no missing parents
2022-01-12 15:09:56 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 3)
2022-01-12 15:09:56 INFO  MemoryStore:57 - Block broadcast_6 stored as values in memory (estimated size 10.1 KiB, free 2.2 GiB)
2022-01-12 15:09:56 DEBUG BlockManager:61 - Put block broadcast_6 locally took 3 ms
2022-01-12 15:09:56 DEBUG BlockManager:61 - Putting block broadcast_6 without replication took 3 ms
2022-01-12 15:09:56 INFO  MemoryStore:57 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 2.2 GiB)
2022-01-12 15:09:56 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_6_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:56 INFO  BlockManagerInfo:57 - Added broadcast_6_piece0 in memory on host.docker.internal:64148 (size: 5.0 KiB, free: 2.2 GiB)
2022-01-12 15:09:56 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_6_piece0
2022-01-12 15:09:56 DEBUG BlockManager:61 - Told master about block broadcast_6_piece0
2022-01-12 15:09:56 DEBUG BlockManager:61 - Put block broadcast_6_piece0 locally took 4 ms
2022-01-12 15:09:56 DEBUG BlockManager:61 - Putting block broadcast_6_piece0 without replication took 4 ms
2022-01-12 15:09:56 INFO  SparkContext:57 - Created broadcast 6 from broadcast at DAGScheduler.scala:1388
2022-01-12 15:09:56 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at count at LoadTesting.java:45) (first 15 tasks are for partitions Vector(0))
2022-01-12 15:09:56 INFO  TaskSchedulerImpl:57 - Adding task set 3.0 with 1 tasks resource profile 0
2022-01-12 15:09:56 DEBUG TaskSetManager:61 - Epoch for TaskSet 3.0: 1
2022-01-12 15:09:56 DEBUG TaskSetManager:61 - Adding pending tasks took 2 ms
2022-01-12 15:09:56 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 3.0: NODE_LOCAL, ANY
2022-01-12 15:09:56 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_3.0, runningTasks: 0
2022-01-12 15:09:56 INFO  TaskSetManager:57 - Starting task 0.0 in stage 3.0 (TID 3) (host.docker.internal, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-12 15:09:56 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
2022-01-12 15:09:56 INFO  Executor:57 - Running task 0.0 in stage 3.0 (TID 3)
2022-01-12 15:09:56 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (3, 0) -> 1
2022-01-12 15:09:56 DEBUG BlockManager:61 - Getting local block broadcast_6
2022-01-12 15:09:56 DEBUG BlockManager:61 - Level for block broadcast_6 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:56 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 0
2022-01-12 15:09:56 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 0, mappers 0-1, partitions 0-1
2022-01-12 15:09:56 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-12 15:09:56 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-12 15:09:56 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 9 ms
2022-01-12 15:09:56 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_0_2_0,0)
2022-01-12 15:09:56 DEBUG BlockManager:61 - Getting local shuffle block shuffle_0_2_0
2022-01-12 15:09:56 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 14 ms
2022-01-12 15:09:56 INFO  Executor:57 - Finished task 0.0 in stage 3.0 (TID 3). 2605 bytes result sent to driver
2022-01-12 15:09:56 DEBUG ExecutorMetricsPoller:61 - removing (3, 0) from stageTCMP
2022-01-12 15:09:56 INFO  TaskSetManager:57 - Finished task 0.0 in stage 3.0 (TID 3) in 63 ms on host.docker.internal (executor driver) (1/1)
2022-01-12 15:09:56 INFO  TaskSchedulerImpl:57 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2022-01-12 15:09:56 INFO  DAGScheduler:57 - ResultStage 3 (count at LoadTesting.java:45) finished in 0.095 s
2022-01-12 15:09:56 DEBUG DAGScheduler:61 - After removal of stage 2, remaining stages = 1
2022-01-12 15:09:56 DEBUG DAGScheduler:61 - After removal of stage 3, remaining stages = 0
2022-01-12 15:09:56 INFO  DAGScheduler:57 - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2022-01-12 15:09:56 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 3: Stage finished
2022-01-12 15:09:56 INFO  DAGScheduler:57 - Job 2 finished: count at LoadTesting.java:45, took 0.302669 s
2022-01-12 15:09:56 WARN  SparkSession$Builder:69 - Using an existing SparkSession; some spark core configurations may not take effect.
2022-01-12 15:09:56 DEBUG DataSource:61 - Some paths were ignored:
  
2022-01-12 15:09:56 INFO  InMemoryFileIndex:57 - It took 5 ms to list leaf files for 1 paths.
2022-01-12 15:09:56 INFO  InMemoryFileIndex:57 - It took 2 ms to list leaf files for 1 paths.
2022-01-12 15:09:56 DEBUG Analyzer$ResolveReferences:61 - Resolving 'value to value#33
2022-01-12 15:09:57 DEBUG Analyzer$ResolveReferences:61 - Resolving 'value to value#39
2022-01-12 15:09:57 INFO  FileSourceStrategy:57 - Pushed Filters: 
2022-01-12 15:09:57 INFO  FileSourceStrategy:57 - Post-Scan Filters: (length(trim(value#33, None)) > 0)
2022-01-12 15:09:57 INFO  FileSourceStrategy:57 - Output Data Schema: struct<value: string>
2022-01-12 15:09:57 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator inputadapter_input_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     inputadapter_input_0 = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while ( inputadapter_input_0.hasNext()) {
/* 026 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 027 */
/* 028 */       do {
/* 029 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 030 */         UTF8String inputadapter_value_0 = inputadapter_isNull_0 ?
/* 031 */         null : (inputadapter_row_0.getUTF8String(0));
/* 032 */
/* 033 */         boolean filter_isNull_0 = true;
/* 034 */         boolean filter_value_0 = false;
/* 035 */         boolean filter_isNull_2 = false;
/* 036 */         UTF8String filter_value_2 = null;
/* 037 */         if (inputadapter_isNull_0) {
/* 038 */           filter_isNull_2 = true;
/* 039 */         } else {
/* 040 */           filter_value_2 = inputadapter_value_0.trim();
/* 041 */         }
/* 042 */         boolean filter_isNull_1 = filter_isNull_2;
/* 043 */         int filter_value_1 = -1;
/* 044 */
/* 045 */         if (!filter_isNull_2) {
/* 046 */           filter_value_1 = (filter_value_2).numChars();
/* 047 */         }
/* 048 */         if (!filter_isNull_1) {
/* 049 */           filter_isNull_0 = false; // resultCode could change nullability.
/* 050 */           filter_value_0 = filter_value_1 > 0;
/* 051 */
/* 052 */         }
/* 053 */         if (filter_isNull_0 || !filter_value_0) continue;
/* 054 */
/* 055 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 056 */
/* 057 */         filter_mutableStateArray_0[0].reset();
/* 058 */
/* 059 */         filter_mutableStateArray_0[0].zeroOutNullBytes();
/* 060 */
/* 061 */         if (inputadapter_isNull_0) {
/* 062 */           filter_mutableStateArray_0[0].setNullAt(0);
/* 063 */         } else {
/* 064 */           filter_mutableStateArray_0[0].write(0, inputadapter_value_0);
/* 065 */         }
/* 066 */         append((filter_mutableStateArray_0[0].getRow()));
/* 067 */
/* 068 */       } while(false);
/* 069 */       if (shouldStop()) return;
/* 070 */     }
/* 071 */   }
/* 072 */
/* 073 */ }

2022-01-12 15:09:57 INFO  MemoryStore:57 - Block broadcast_7 stored as values in memory (estimated size 174.3 KiB, free 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManager:61 - Put block broadcast_7 locally took 4 ms
2022-01-12 15:09:57 DEBUG BlockManager:61 - Putting block broadcast_7 without replication took 4 ms
2022-01-12 15:09:57 INFO  MemoryStore:57 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_7_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:57 INFO  BlockManagerInfo:57 - Added broadcast_7_piece0 in memory on host.docker.internal:64148 (size: 27.6 KiB, free: 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_7_piece0
2022-01-12 15:09:57 DEBUG BlockManager:61 - Told master about block broadcast_7_piece0
2022-01-12 15:09:57 DEBUG BlockManager:61 - Put block broadcast_7_piece0 locally took 4 ms
2022-01-12 15:09:57 DEBUG BlockManager:61 - Putting block broadcast_7_piece0 without replication took 4 ms
2022-01-12 15:09:57 INFO  SparkContext:57 - Created broadcast 7 from load at Extract.java:13
2022-01-12 15:09:57 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$executeTake$2
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$executeTake$2) is now cleaned +++
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$5
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
2022-01-12 15:09:57 INFO  SparkContext:57 - Starting job: load at Extract.java:13
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - Merging stage rdd profiles: Set()
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Got job 3 (load at Extract.java:13) with 1 output partitions
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Final stage: ResultStage 4 (load at Extract.java:13)
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Parents of final stage: List()
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Missing parents: List()
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - submitStage(ResultStage 4 (name=load at Extract.java:13;jobs=3))
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - missing: List()
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Submitting ResultStage 4 (MapPartitionsRDD[20] at load at Extract.java:13), which has no missing parents
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 4)
2022-01-12 15:09:57 INFO  MemoryStore:57 - Block broadcast_8 stored as values in memory (estimated size 10.8 KiB, free 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManager:61 - Put block broadcast_8 locally took 2 ms
2022-01-12 15:09:57 DEBUG BlockManager:61 - Putting block broadcast_8 without replication took 2 ms
2022-01-12 15:09:57 INFO  MemoryStore:57 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_8_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:57 INFO  BlockManagerInfo:57 - Added broadcast_8_piece0 in memory on host.docker.internal:64148 (size: 5.4 KiB, free: 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_8_piece0
2022-01-12 15:09:57 DEBUG BlockManager:61 - Told master about block broadcast_8_piece0
2022-01-12 15:09:57 DEBUG BlockManager:61 - Put block broadcast_8_piece0 locally took 3 ms
2022-01-12 15:09:57 DEBUG BlockManager:61 - Putting block broadcast_8_piece0 without replication took 3 ms
2022-01-12 15:09:57 INFO  SparkContext:57 - Created broadcast 8 from broadcast at DAGScheduler.scala:1388
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at load at Extract.java:13) (first 15 tasks are for partitions Vector(0))
2022-01-12 15:09:57 INFO  TaskSchedulerImpl:57 - Adding task set 4.0 with 1 tasks resource profile 0
2022-01-12 15:09:57 DEBUG TaskSetManager:61 - Epoch for TaskSet 4.0: 1
2022-01-12 15:09:57 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-01-12 15:09:57 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 4.0: NO_PREF, ANY
2022-01-12 15:09:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_4.0, runningTasks: 0
2022-01-12 15:09:57 INFO  TaskSetManager:57 - Starting task 0.0 in stage 4.0 (TID 4) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4974 bytes) taskResourceAssignments Map()
2022-01-12 15:09:57 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-01-12 15:09:57 INFO  Executor:57 - Running task 0.0 in stage 4.0 (TID 4)
2022-01-12 15:09:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (4, 0) -> 1
2022-01-12 15:09:57 DEBUG BlockManager:61 - Getting local block broadcast_8
2022-01-12 15:09:57 DEBUG BlockManager:61 - Level for block broadcast_8 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:57 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Rahul%20Kabothula/Intellij%20Maven%20Projects/retail_db/result/task5_result/part-00000-94256c95-e544-4b5f-8dd5-dddad79d703e-c000.csv, range: 0-135, partition values: [empty row]
2022-01-12 15:09:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-12 15:09:57 DEBUG BlockManager:61 - Getting local block broadcast_7
2022-01-12 15:09:57 DEBUG BlockManager:61 - Level for block broadcast_7 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:57 INFO  Executor:57 - Finished task 0.0 in stage 4.0 (TID 4). 1514 bytes result sent to driver
2022-01-12 15:09:57 DEBUG ExecutorMetricsPoller:61 - removing (4, 0) from stageTCMP
2022-01-12 15:09:57 INFO  TaskSetManager:57 - Finished task 0.0 in stage 4.0 (TID 4) in 19 ms on host.docker.internal (executor driver) (1/1)
2022-01-12 15:09:57 INFO  TaskSchedulerImpl:57 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2022-01-12 15:09:57 INFO  DAGScheduler:57 - ResultStage 4 (load at Extract.java:13) finished in 0.050 s
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - After removal of stage 4, remaining stages = 0
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2022-01-12 15:09:57 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 4: Stage finished
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Job 3 finished: load at Extract.java:13, took 0.040005 s
2022-01-12 15:09:57 DEBUG GenerateSafeProjection:61 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-01-12 15:09:57 INFO  FileSourceStrategy:57 - Pushed Filters: 
2022-01-12 15:09:57 INFO  FileSourceStrategy:57 - Post-Scan Filters: 
2022-01-12 15:09:57 INFO  FileSourceStrategy:57 - Output Data Schema: struct<value: string>
2022-01-12 15:09:57 INFO  MemoryStore:57 - Block broadcast_9 stored as values in memory (estimated size 174.3 KiB, free 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManager:61 - Put block broadcast_9 locally took 5 ms
2022-01-12 15:09:57 DEBUG BlockManager:61 - Putting block broadcast_9 without replication took 6 ms
2022-01-12 15:09:57 INFO  MemoryStore:57 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_9_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:57 INFO  BlockManagerInfo:57 - Added broadcast_9_piece0 in memory on host.docker.internal:64148 (size: 27.6 KiB, free: 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_9_piece0
2022-01-12 15:09:57 DEBUG BlockManager:61 - Told master about block broadcast_9_piece0
2022-01-12 15:09:57 DEBUG BlockManager:61 - Put block broadcast_9_piece0 locally took 3 ms
2022-01-12 15:09:57 DEBUG BlockManager:61 - Putting block broadcast_9_piece0 without replication took 4 ms
2022-01-12 15:09:57 INFO  SparkContext:57 - Created broadcast 9 from load at Extract.java:13
2022-01-12 15:09:57 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$rdd$1
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$rdd$1) is now cleaned +++
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$inferFromDataset$2
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$inferFromDataset$2) is now cleaned +++
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$infer$2
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$infer$2) is now cleaned +++
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$infer$3
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$infer$3) is now cleaned +++
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$6
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$6) is now cleaned +++
2022-01-12 15:09:57 INFO  SparkContext:57 - Starting job: load at Extract.java:13
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - Merging stage rdd profiles: Set()
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Got job 4 (load at Extract.java:13) with 1 output partitions
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Final stage: ResultStage 5 (load at Extract.java:13)
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Parents of final stage: List()
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Missing parents: List()
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - submitStage(ResultStage 5 (name=load at Extract.java:13;jobs=4))
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - missing: List()
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Submitting ResultStage 5 (MapPartitionsRDD[26] at load at Extract.java:13), which has no missing parents
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 5)
2022-01-12 15:09:57 INFO  MemoryStore:57 - Block broadcast_10 stored as values in memory (estimated size 15.4 KiB, free 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManager:61 - Put block broadcast_10 locally took 3 ms
2022-01-12 15:09:57 DEBUG BlockManager:61 - Putting block broadcast_10 without replication took 4 ms
2022-01-12 15:09:57 INFO  MemoryStore:57 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_10_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:57 INFO  BlockManagerInfo:57 - Added broadcast_10_piece0 in memory on host.docker.internal:64148 (size: 7.8 KiB, free: 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_10_piece0
2022-01-12 15:09:57 DEBUG BlockManager:61 - Told master about block broadcast_10_piece0
2022-01-12 15:09:57 DEBUG BlockManager:61 - Put block broadcast_10_piece0 locally took 4 ms
2022-01-12 15:09:57 DEBUG BlockManager:61 - Putting block broadcast_10_piece0 without replication took 4 ms
2022-01-12 15:09:57 INFO  SparkContext:57 - Created broadcast 10 from broadcast at DAGScheduler.scala:1388
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[26] at load at Extract.java:13) (first 15 tasks are for partitions Vector(0))
2022-01-12 15:09:57 INFO  TaskSchedulerImpl:57 - Adding task set 5.0 with 1 tasks resource profile 0
2022-01-12 15:09:57 DEBUG TaskSetManager:61 - Epoch for TaskSet 5.0: 1
2022-01-12 15:09:57 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-01-12 15:09:57 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 5.0: NO_PREF, ANY
2022-01-12 15:09:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_5.0, runningTasks: 0
2022-01-12 15:09:57 INFO  TaskSetManager:57 - Starting task 0.0 in stage 5.0 (TID 5) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4974 bytes) taskResourceAssignments Map()
2022-01-12 15:09:57 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-01-12 15:09:57 INFO  Executor:57 - Running task 0.0 in stage 5.0 (TID 5)
2022-01-12 15:09:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (5, 0) -> 1
2022-01-12 15:09:57 DEBUG BlockManager:61 - Getting local block broadcast_10
2022-01-12 15:09:57 DEBUG BlockManager:61 - Level for block broadcast_10 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:57 DEBUG GenerateSafeProjection:61 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-01-12 15:09:57 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Rahul%20Kabothula/Intellij%20Maven%20Projects/retail_db/result/task5_result/part-00000-94256c95-e544-4b5f-8dd5-dddad79d703e-c000.csv, range: 0-135, partition values: [empty row]
2022-01-12 15:09:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-12 15:09:57 DEBUG BlockManager:61 - Getting local block broadcast_9
2022-01-12 15:09:57 DEBUG BlockManager:61 - Level for block broadcast_9 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:57 INFO  Executor:57 - Finished task 0.0 in stage 5.0 (TID 5). 1518 bytes result sent to driver
2022-01-12 15:09:57 DEBUG ExecutorMetricsPoller:61 - removing (5, 0) from stageTCMP
2022-01-12 15:09:57 INFO  TaskSetManager:57 - Finished task 0.0 in stage 5.0 (TID 5) in 22 ms on host.docker.internal (executor driver) (1/1)
2022-01-12 15:09:57 INFO  TaskSchedulerImpl:57 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2022-01-12 15:09:57 INFO  DAGScheduler:57 - ResultStage 5 (load at Extract.java:13) finished in 0.040 s
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - After removal of stage 5, remaining stages = 0
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2022-01-12 15:09:57 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 5: Stage finished
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Job 4 finished: load at Extract.java:13, took 0.051833 s
2022-01-12 15:09:57 INFO  FileSourceStrategy:57 - Pushed Filters: 
2022-01-12 15:09:57 INFO  FileSourceStrategy:57 - Post-Scan Filters: 
2022-01-12 15:09:57 INFO  FileSourceStrategy:57 - Output Data Schema: struct<>
2022-01-12 15:09:57 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage2(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=2
/* 006 */ final class GeneratedIteratorForCodegenStage2 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private boolean agg_bufIsNull_0;
/* 011 */   private long agg_bufValue_0;
/* 012 */   private scala.collection.Iterator inputadapter_input_0;
/* 013 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] agg_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 014 */
/* 015 */   public GeneratedIteratorForCodegenStage2(Object[] references) {
/* 016 */     this.references = references;
/* 017 */   }
/* 018 */
/* 019 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 020 */     partitionIndex = index;
/* 021 */     this.inputs = inputs;
/* 022 */
/* 023 */     inputadapter_input_0 = inputs[0];
/* 024 */     agg_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 025 */
/* 026 */   }
/* 027 */
/* 028 */   private void agg_doAggregateWithoutKey_0() throws java.io.IOException {
/* 029 */     // initialize aggregation buffer
/* 030 */     agg_bufIsNull_0 = false;
/* 031 */     agg_bufValue_0 = 0L;
/* 032 */
/* 033 */     while ( inputadapter_input_0.hasNext()) {
/* 034 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 035 */
/* 036 */       long inputadapter_value_0 = inputadapter_row_0.getLong(0);
/* 037 */
/* 038 */       agg_doConsume_0(inputadapter_row_0, inputadapter_value_0);
/* 039 */       // shouldStop check is eliminated
/* 040 */     }
/* 041 */
/* 042 */   }
/* 043 */
/* 044 */   private void agg_doConsume_0(InternalRow inputadapter_row_0, long agg_expr_0_0) throws java.io.IOException {
/* 045 */     // do aggregate
/* 046 */     // common sub-expressions
/* 047 */
/* 048 */     // evaluate aggregate functions and update aggregation buffers
/* 049 */
/* 050 */     long agg_value_3 = -1L;
/* 051 */
/* 052 */     agg_value_3 = agg_bufValue_0 + agg_expr_0_0;
/* 053 */
/* 054 */     agg_bufIsNull_0 = false;
/* 055 */     agg_bufValue_0 = agg_value_3;
/* 056 */
/* 057 */   }
/* 058 */
/* 059 */   protected void processNext() throws java.io.IOException {
/* 060 */     while (!agg_initAgg_0) {
/* 061 */       agg_initAgg_0 = true;
/* 062 */       long agg_beforeAgg_0 = System.nanoTime();
/* 063 */       agg_doAggregateWithoutKey_0();
/* 064 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* aggTime */).add((System.nanoTime() - agg_beforeAgg_0) / 1000000);
/* 065 */
/* 066 */       // output the result
/* 067 */
/* 068 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 069 */       agg_mutableStateArray_0[0].reset();
/* 070 */
/* 071 */       agg_mutableStateArray_0[0].zeroOutNullBytes();
/* 072 */
/* 073 */       agg_mutableStateArray_0[0].write(0, agg_bufValue_0);
/* 074 */       append((agg_mutableStateArray_0[0].getRow()));
/* 075 */     }
/* 076 */   }
/* 077 */
/* 078 */ }

2022-01-12 15:09:57 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private boolean agg_bufIsNull_0;
/* 011 */   private long agg_bufValue_0;
/* 012 */   private scala.collection.Iterator inputadapter_input_0;
/* 013 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] agg_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 014 */
/* 015 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 016 */     this.references = references;
/* 017 */   }
/* 018 */
/* 019 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 020 */     partitionIndex = index;
/* 021 */     this.inputs = inputs;
/* 022 */
/* 023 */     inputadapter_input_0 = inputs[0];
/* 024 */     agg_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 025 */
/* 026 */   }
/* 027 */
/* 028 */   private void agg_doAggregateWithoutKey_0() throws java.io.IOException {
/* 029 */     // initialize aggregation buffer
/* 030 */     agg_bufIsNull_0 = false;
/* 031 */     agg_bufValue_0 = 0L;
/* 032 */
/* 033 */     while ( inputadapter_input_0.hasNext()) {
/* 034 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 035 */
/* 036 */       agg_doConsume_0(inputadapter_row_0);
/* 037 */       // shouldStop check is eliminated
/* 038 */     }
/* 039 */
/* 040 */   }
/* 041 */
/* 042 */   private void agg_doConsume_0(InternalRow inputadapter_row_0) throws java.io.IOException {
/* 043 */     // do aggregate
/* 044 */     // common sub-expressions
/* 045 */
/* 046 */     // evaluate aggregate functions and update aggregation buffers
/* 047 */
/* 048 */     long agg_value_1 = -1L;
/* 049 */
/* 050 */     agg_value_1 = agg_bufValue_0 + 1L;
/* 051 */
/* 052 */     agg_bufIsNull_0 = false;
/* 053 */     agg_bufValue_0 = agg_value_1;
/* 054 */
/* 055 */   }
/* 056 */
/* 057 */   protected void processNext() throws java.io.IOException {
/* 058 */     while (!agg_initAgg_0) {
/* 059 */       agg_initAgg_0 = true;
/* 060 */       long agg_beforeAgg_0 = System.nanoTime();
/* 061 */       agg_doAggregateWithoutKey_0();
/* 062 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* aggTime */).add((System.nanoTime() - agg_beforeAgg_0) / 1000000);
/* 063 */
/* 064 */       // output the result
/* 065 */
/* 066 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 067 */       agg_mutableStateArray_0[0].reset();
/* 068 */
/* 069 */       agg_mutableStateArray_0[0].zeroOutNullBytes();
/* 070 */
/* 071 */       agg_mutableStateArray_0[0].write(0, agg_bufValue_0);
/* 072 */       append((agg_mutableStateArray_0[0].getRow()));
/* 073 */     }
/* 074 */   }
/* 075 */
/* 076 */ }

2022-01-12 15:09:57 INFO  MemoryStore:57 - Block broadcast_11 stored as values in memory (estimated size 174.2 KiB, free 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManager:61 - Put block broadcast_11 locally took 4 ms
2022-01-12 15:09:57 DEBUG BlockManager:61 - Putting block broadcast_11 without replication took 4 ms
2022-01-12 15:09:57 INFO  MemoryStore:57 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_11_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:57 INFO  BlockManagerInfo:57 - Added broadcast_11_piece0 in memory on host.docker.internal:64148 (size: 27.6 KiB, free: 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_11_piece0
2022-01-12 15:09:57 DEBUG BlockManager:61 - Told master about block broadcast_11_piece0
2022-01-12 15:09:57 DEBUG BlockManager:61 - Put block broadcast_11_piece0 locally took 4 ms
2022-01-12 15:09:57 DEBUG BlockManager:61 - Putting block broadcast_11_piece0 without replication took 4 ms
2022-01-12 15:09:57 INFO  SparkContext:57 - Created broadcast 11 from count at LoadTesting.java:53
2022-01-12 15:09:57 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$collect$2
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$collect$2) is now cleaned +++
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$5
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
2022-01-12 15:09:57 INFO  SparkContext:57 - Starting job: count at LoadTesting.java:53
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - Merging stage rdd profiles: Set()
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - Merging stage rdd profiles: Set()
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Registering RDD 30 (count at LoadTesting.java:53) as input to shuffle 1
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Got job 5 (count at LoadTesting.java:53) with 1 output partitions
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Final stage: ResultStage 7 (count at LoadTesting.java:53)
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Parents of final stage: List(ShuffleMapStage 6)
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Missing parents: List(ShuffleMapStage 6)
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - submitStage(ResultStage 7 (name=count at LoadTesting.java:53;jobs=5))
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - missing: List(ShuffleMapStage 6)
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - submitStage(ShuffleMapStage 6 (name=count at LoadTesting.java:53;jobs=5))
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - missing: List()
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Submitting ShuffleMapStage 6 (MapPartitionsRDD[30] at count at LoadTesting.java:53), which has no missing parents
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - submitMissingTasks(ShuffleMapStage 6)
2022-01-12 15:09:57 INFO  MemoryStore:57 - Block broadcast_12 stored as values in memory (estimated size 15.1 KiB, free 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManager:61 - Put block broadcast_12 locally took 2 ms
2022-01-12 15:09:57 DEBUG BlockManager:61 - Putting block broadcast_12 without replication took 2 ms
2022-01-12 15:09:57 INFO  MemoryStore:57 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_12_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:57 INFO  BlockManagerInfo:57 - Added broadcast_12_piece0 in memory on host.docker.internal:64148 (size: 7.8 KiB, free: 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_12_piece0
2022-01-12 15:09:57 DEBUG BlockManager:61 - Told master about block broadcast_12_piece0
2022-01-12 15:09:57 DEBUG BlockManager:61 - Put block broadcast_12_piece0 locally took 3 ms
2022-01-12 15:09:57 DEBUG BlockManager:61 - Putting block broadcast_12_piece0 without replication took 3 ms
2022-01-12 15:09:57 INFO  SparkContext:57 - Created broadcast 12 from broadcast at DAGScheduler.scala:1388
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[30] at count at LoadTesting.java:53) (first 15 tasks are for partitions Vector(0))
2022-01-12 15:09:57 INFO  TaskSchedulerImpl:57 - Adding task set 6.0 with 1 tasks resource profile 0
2022-01-12 15:09:57 DEBUG TaskSetManager:61 - Epoch for TaskSet 6.0: 1
2022-01-12 15:09:57 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-01-12 15:09:57 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 6.0: NO_PREF, ANY
2022-01-12 15:09:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_6.0, runningTasks: 0
2022-01-12 15:09:57 INFO  TaskSetManager:57 - Starting task 0.0 in stage 6.0 (TID 6) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4963 bytes) taskResourceAssignments Map()
2022-01-12 15:09:57 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-01-12 15:09:57 INFO  Executor:57 - Running task 0.0 in stage 6.0 (TID 6)
2022-01-12 15:09:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (6, 0) -> 1
2022-01-12 15:09:57 DEBUG BlockManager:61 - Getting local block broadcast_12
2022-01-12 15:09:57 DEBUG BlockManager:61 - Level for block broadcast_12 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:57 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Rahul%20Kabothula/Intellij%20Maven%20Projects/retail_db/result/task5_result/part-00000-94256c95-e544-4b5f-8dd5-dddad79d703e-c000.csv, range: 0-135, partition values: [empty row]
2022-01-12 15:09:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-01-12 15:09:57 DEBUG BlockManager:61 - Getting local block broadcast_11
2022-01-12 15:09:57 DEBUG BlockManager:61 - Level for block broadcast_11 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:57 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 6 with length 1
2022-01-12 15:09:57 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 6: [59]
2022-01-12 15:09:57 INFO  Executor:57 - Finished task 0.0 in stage 6.0 (TID 6). 1887 bytes result sent to driver
2022-01-12 15:09:57 DEBUG ExecutorMetricsPoller:61 - removing (6, 0) from stageTCMP
2022-01-12 15:09:57 INFO  TaskSetManager:57 - Finished task 0.0 in stage 6.0 (TID 6) in 47 ms on host.docker.internal (executor driver) (1/1)
2022-01-12 15:09:57 INFO  TaskSchedulerImpl:57 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-12 15:09:57 INFO  DAGScheduler:57 - ShuffleMapStage 6 (count at LoadTesting.java:53) finished in 0.063 s
2022-01-12 15:09:57 INFO  DAGScheduler:57 - looking for newly runnable stages
2022-01-12 15:09:57 INFO  DAGScheduler:57 - running: Set()
2022-01-12 15:09:57 INFO  DAGScheduler:57 - waiting: Set(ResultStage 7)
2022-01-12 15:09:57 INFO  DAGScheduler:57 - failed: Set()
2022-01-12 15:09:57 DEBUG MapOutputTrackerMaster:61 - Increasing epoch to 2
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - submitStage(ResultStage 7 (name=count at LoadTesting.java:53;jobs=5))
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - missing: List()
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Submitting ResultStage 7 (MapPartitionsRDD[33] at count at LoadTesting.java:53), which has no missing parents
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 7)
2022-01-12 15:09:57 INFO  MemoryStore:57 - Block broadcast_13 stored as values in memory (estimated size 10.1 KiB, free 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManager:61 - Put block broadcast_13 locally took 2 ms
2022-01-12 15:09:57 DEBUG BlockManager:61 - Putting block broadcast_13 without replication took 2 ms
2022-01-12 15:09:57 INFO  MemoryStore:57 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_13_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:57 INFO  BlockManagerInfo:57 - Added broadcast_13_piece0 in memory on host.docker.internal:64148 (size: 5.0 KiB, free: 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_13_piece0
2022-01-12 15:09:57 DEBUG BlockManager:61 - Told master about block broadcast_13_piece0
2022-01-12 15:09:57 DEBUG BlockManager:61 - Put block broadcast_13_piece0 locally took 2 ms
2022-01-12 15:09:57 DEBUG BlockManager:61 - Putting block broadcast_13_piece0 without replication took 2 ms
2022-01-12 15:09:57 INFO  SparkContext:57 - Created broadcast 13 from broadcast at DAGScheduler.scala:1388
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[33] at count at LoadTesting.java:53) (first 15 tasks are for partitions Vector(0))
2022-01-12 15:09:57 INFO  TaskSchedulerImpl:57 - Adding task set 7.0 with 1 tasks resource profile 0
2022-01-12 15:09:57 DEBUG TaskSetManager:61 - Epoch for TaskSet 7.0: 2
2022-01-12 15:09:57 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-01-12 15:09:57 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 7.0: NODE_LOCAL, ANY
2022-01-12 15:09:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_7.0, runningTasks: 0
2022-01-12 15:09:57 INFO  TaskSetManager:57 - Starting task 0.0 in stage 7.0 (TID 7) (host.docker.internal, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-12 15:09:57 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
2022-01-12 15:09:57 INFO  Executor:57 - Running task 0.0 in stage 7.0 (TID 7)
2022-01-12 15:09:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (7, 0) -> 1
2022-01-12 15:09:57 DEBUG BlockManager:61 - Getting local block broadcast_13
2022-01-12 15:09:57 DEBUG BlockManager:61 - Level for block broadcast_13 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:57 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 1
2022-01-12 15:09:57 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 1, mappers 0-1, partitions 0-1
2022-01-12 15:09:57 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-12 15:09:57 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-12 15:09:57 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-12 15:09:57 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_1_6_0,0)
2022-01-12 15:09:57 DEBUG BlockManager:61 - Getting local shuffle block shuffle_1_6_0
2022-01-12 15:09:57 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-12 15:09:57 INFO  Executor:57 - Finished task 0.0 in stage 7.0 (TID 7). 2562 bytes result sent to driver
2022-01-12 15:09:57 DEBUG ExecutorMetricsPoller:61 - removing (7, 0) from stageTCMP
2022-01-12 15:09:57 INFO  TaskSetManager:57 - Finished task 0.0 in stage 7.0 (TID 7) in 0 ms on host.docker.internal (executor driver) (1/1)
2022-01-12 15:09:57 INFO  TaskSchedulerImpl:57 - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2022-01-12 15:09:57 INFO  DAGScheduler:57 - ResultStage 7 (count at LoadTesting.java:53) finished in 0.016 s
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - After removal of stage 7, remaining stages = 1
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - After removal of stage 6, remaining stages = 0
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2022-01-12 15:09:57 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 7: Stage finished
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Job 5 finished: count at LoadTesting.java:53, took 0.087357 s
2022-01-12 15:09:57 WARN  SparkSession$Builder:69 - Using an existing SparkSession; some spark core configurations may not take effect.
2022-01-12 15:09:57 DEBUG DataSource:61 - Some paths were ignored:
  
2022-01-12 15:09:57 INFO  InMemoryFileIndex:57 - It took 3 ms to list leaf files for 1 paths.
2022-01-12 15:09:57 INFO  InMemoryFileIndex:57 - It took 2 ms to list leaf files for 1 paths.
2022-01-12 15:09:57 DEBUG Analyzer$ResolveReferences:61 - Resolving 'value to value#63
2022-01-12 15:09:57 DEBUG Analyzer$ResolveReferences:61 - Resolving 'value to value#69
2022-01-12 15:09:57 INFO  FileSourceStrategy:57 - Pushed Filters: 
2022-01-12 15:09:57 INFO  FileSourceStrategy:57 - Post-Scan Filters: (length(trim(value#63, None)) > 0)
2022-01-12 15:09:57 INFO  FileSourceStrategy:57 - Output Data Schema: struct<value: string>
2022-01-12 15:09:57 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator inputadapter_input_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     inputadapter_input_0 = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while ( inputadapter_input_0.hasNext()) {
/* 026 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 027 */
/* 028 */       do {
/* 029 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 030 */         UTF8String inputadapter_value_0 = inputadapter_isNull_0 ?
/* 031 */         null : (inputadapter_row_0.getUTF8String(0));
/* 032 */
/* 033 */         boolean filter_isNull_0 = true;
/* 034 */         boolean filter_value_0 = false;
/* 035 */         boolean filter_isNull_2 = false;
/* 036 */         UTF8String filter_value_2 = null;
/* 037 */         if (inputadapter_isNull_0) {
/* 038 */           filter_isNull_2 = true;
/* 039 */         } else {
/* 040 */           filter_value_2 = inputadapter_value_0.trim();
/* 041 */         }
/* 042 */         boolean filter_isNull_1 = filter_isNull_2;
/* 043 */         int filter_value_1 = -1;
/* 044 */
/* 045 */         if (!filter_isNull_2) {
/* 046 */           filter_value_1 = (filter_value_2).numChars();
/* 047 */         }
/* 048 */         if (!filter_isNull_1) {
/* 049 */           filter_isNull_0 = false; // resultCode could change nullability.
/* 050 */           filter_value_0 = filter_value_1 > 0;
/* 051 */
/* 052 */         }
/* 053 */         if (filter_isNull_0 || !filter_value_0) continue;
/* 054 */
/* 055 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 056 */
/* 057 */         filter_mutableStateArray_0[0].reset();
/* 058 */
/* 059 */         filter_mutableStateArray_0[0].zeroOutNullBytes();
/* 060 */
/* 061 */         if (inputadapter_isNull_0) {
/* 062 */           filter_mutableStateArray_0[0].setNullAt(0);
/* 063 */         } else {
/* 064 */           filter_mutableStateArray_0[0].write(0, inputadapter_value_0);
/* 065 */         }
/* 066 */         append((filter_mutableStateArray_0[0].getRow()));
/* 067 */
/* 068 */       } while(false);
/* 069 */       if (shouldStop()) return;
/* 070 */     }
/* 071 */   }
/* 072 */
/* 073 */ }

2022-01-12 15:09:57 INFO  MemoryStore:57 - Block broadcast_14 stored as values in memory (estimated size 174.3 KiB, free 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManager:61 - Put block broadcast_14 locally took 6 ms
2022-01-12 15:09:57 DEBUG BlockManager:61 - Putting block broadcast_14 without replication took 7 ms
2022-01-12 15:09:57 INFO  MemoryStore:57 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_14_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:57 INFO  BlockManagerInfo:57 - Added broadcast_14_piece0 in memory on host.docker.internal:64148 (size: 27.6 KiB, free: 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_14_piece0
2022-01-12 15:09:57 DEBUG BlockManager:61 - Told master about block broadcast_14_piece0
2022-01-12 15:09:57 DEBUG BlockManager:61 - Put block broadcast_14_piece0 locally took 2 ms
2022-01-12 15:09:57 DEBUG BlockManager:61 - Putting block broadcast_14_piece0 without replication took 2 ms
2022-01-12 15:09:57 INFO  SparkContext:57 - Created broadcast 14 from load at Extract.java:13
2022-01-12 15:09:57 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$executeTake$2
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$executeTake$2) is now cleaned +++
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$5
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
2022-01-12 15:09:57 INFO  SparkContext:57 - Starting job: load at Extract.java:13
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - Merging stage rdd profiles: Set()
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Got job 6 (load at Extract.java:13) with 1 output partitions
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Final stage: ResultStage 8 (load at Extract.java:13)
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Parents of final stage: List()
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Missing parents: List()
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - submitStage(ResultStage 8 (name=load at Extract.java:13;jobs=6))
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - missing: List()
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Submitting ResultStage 8 (MapPartitionsRDD[37] at load at Extract.java:13), which has no missing parents
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 8)
2022-01-12 15:09:57 INFO  MemoryStore:57 - Block broadcast_15 stored as values in memory (estimated size 10.8 KiB, free 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManager:61 - Put block broadcast_15 locally took 1 ms
2022-01-12 15:09:57 DEBUG BlockManager:61 - Putting block broadcast_15 without replication took 1 ms
2022-01-12 15:09:57 INFO  MemoryStore:57 - Block broadcast_15_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_15_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:57 INFO  BlockManagerInfo:57 - Added broadcast_15_piece0 in memory on host.docker.internal:64148 (size: 5.4 KiB, free: 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_15_piece0
2022-01-12 15:09:57 DEBUG BlockManager:61 - Told master about block broadcast_15_piece0
2022-01-12 15:09:57 DEBUG BlockManager:61 - Put block broadcast_15_piece0 locally took 1 ms
2022-01-12 15:09:57 DEBUG BlockManager:61 - Putting block broadcast_15_piece0 without replication took 1 ms
2022-01-12 15:09:57 INFO  SparkContext:57 - Created broadcast 15 from broadcast at DAGScheduler.scala:1388
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[37] at load at Extract.java:13) (first 15 tasks are for partitions Vector(0))
2022-01-12 15:09:57 INFO  TaskSchedulerImpl:57 - Adding task set 8.0 with 1 tasks resource profile 0
2022-01-12 15:09:57 DEBUG TaskSetManager:61 - Epoch for TaskSet 8.0: 2
2022-01-12 15:09:57 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-01-12 15:09:57 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 8.0: NO_PREF, ANY
2022-01-12 15:09:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_8.0, runningTasks: 0
2022-01-12 15:09:57 INFO  TaskSetManager:57 - Starting task 0.0 in stage 8.0 (TID 8) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4974 bytes) taskResourceAssignments Map()
2022-01-12 15:09:57 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-01-12 15:09:57 INFO  Executor:57 - Running task 0.0 in stage 8.0 (TID 8)
2022-01-12 15:09:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (8, 0) -> 1
2022-01-12 15:09:57 DEBUG BlockManager:61 - Getting local block broadcast_15
2022-01-12 15:09:57 DEBUG BlockManager:61 - Level for block broadcast_15 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:57 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Rahul%20Kabothula/Intellij%20Maven%20Projects/retail_db/result/task1_result/part-00000-9da1dfbd-eb54-41e7-ad55-d28ab595e9f6-c000.csv, range: 0-98741, partition values: [empty row]
2022-01-12 15:09:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-12 15:09:57 DEBUG BlockManager:61 - Getting local block broadcast_14
2022-01-12 15:09:57 DEBUG BlockManager:61 - Level for block broadcast_14 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:57 INFO  Executor:57 - Finished task 0.0 in stage 8.0 (TID 8). 1514 bytes result sent to driver
2022-01-12 15:09:57 DEBUG ExecutorMetricsPoller:61 - removing (8, 0) from stageTCMP
2022-01-12 15:09:57 INFO  TaskSetManager:57 - Finished task 0.0 in stage 8.0 (TID 8) in 15 ms on host.docker.internal (executor driver) (1/1)
2022-01-12 15:09:57 INFO  TaskSchedulerImpl:57 - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2022-01-12 15:09:57 INFO  DAGScheduler:57 - ResultStage 8 (load at Extract.java:13) finished in 0.031 s
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - After removal of stage 8, remaining stages = 0
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
2022-01-12 15:09:57 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 8: Stage finished
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Job 6 finished: load at Extract.java:13, took 0.033362 s
2022-01-12 15:09:57 DEBUG GenerateSafeProjection:61 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-01-12 15:09:57 INFO  FileSourceStrategy:57 - Pushed Filters: 
2022-01-12 15:09:57 INFO  FileSourceStrategy:57 - Post-Scan Filters: 
2022-01-12 15:09:57 INFO  FileSourceStrategy:57 - Output Data Schema: struct<value: string>
2022-01-12 15:09:57 INFO  MemoryStore:57 - Block broadcast_16 stored as values in memory (estimated size 174.3 KiB, free 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManager:61 - Put block broadcast_16 locally took 5 ms
2022-01-12 15:09:57 DEBUG BlockManager:61 - Putting block broadcast_16 without replication took 5 ms
2022-01-12 15:09:57 INFO  MemoryStore:57 - Block broadcast_16_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_16_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:57 INFO  BlockManagerInfo:57 - Added broadcast_16_piece0 in memory on host.docker.internal:64148 (size: 27.6 KiB, free: 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_16_piece0
2022-01-12 15:09:57 DEBUG BlockManager:61 - Told master about block broadcast_16_piece0
2022-01-12 15:09:57 DEBUG BlockManager:61 - Put block broadcast_16_piece0 locally took 2 ms
2022-01-12 15:09:57 DEBUG BlockManager:61 - Putting block broadcast_16_piece0 without replication took 3 ms
2022-01-12 15:09:57 INFO  SparkContext:57 - Created broadcast 16 from load at Extract.java:13
2022-01-12 15:09:57 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$rdd$1
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$rdd$1) is now cleaned +++
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$inferFromDataset$2
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$inferFromDataset$2) is now cleaned +++
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$infer$2
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$infer$2) is now cleaned +++
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$infer$3
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$infer$3) is now cleaned +++
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$6
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$6) is now cleaned +++
2022-01-12 15:09:57 INFO  SparkContext:57 - Starting job: load at Extract.java:13
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - Merging stage rdd profiles: Set()
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Got job 7 (load at Extract.java:13) with 1 output partitions
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Final stage: ResultStage 9 (load at Extract.java:13)
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Parents of final stage: List()
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Missing parents: List()
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - submitStage(ResultStage 9 (name=load at Extract.java:13;jobs=7))
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - missing: List()
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Submitting ResultStage 9 (MapPartitionsRDD[43] at load at Extract.java:13), which has no missing parents
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 9)
2022-01-12 15:09:57 INFO  MemoryStore:57 - Block broadcast_17 stored as values in memory (estimated size 15.4 KiB, free 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManager:61 - Put block broadcast_17 locally took 1 ms
2022-01-12 15:09:57 DEBUG BlockManager:61 - Putting block broadcast_17 without replication took 1 ms
2022-01-12 15:09:57 INFO  MemoryStore:57 - Block broadcast_17_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_17_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:57 INFO  BlockManagerInfo:57 - Added broadcast_17_piece0 in memory on host.docker.internal:64148 (size: 7.8 KiB, free: 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_17_piece0
2022-01-12 15:09:57 DEBUG BlockManager:61 - Told master about block broadcast_17_piece0
2022-01-12 15:09:57 DEBUG BlockManager:61 - Put block broadcast_17_piece0 locally took 1 ms
2022-01-12 15:09:57 DEBUG BlockManager:61 - Putting block broadcast_17_piece0 without replication took 1 ms
2022-01-12 15:09:57 INFO  SparkContext:57 - Created broadcast 17 from broadcast at DAGScheduler.scala:1388
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[43] at load at Extract.java:13) (first 15 tasks are for partitions Vector(0))
2022-01-12 15:09:57 INFO  TaskSchedulerImpl:57 - Adding task set 9.0 with 1 tasks resource profile 0
2022-01-12 15:09:57 DEBUG TaskSetManager:61 - Epoch for TaskSet 9.0: 2
2022-01-12 15:09:57 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-01-12 15:09:57 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 9.0: NO_PREF, ANY
2022-01-12 15:09:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-01-12 15:09:57 INFO  TaskSetManager:57 - Starting task 0.0 in stage 9.0 (TID 9) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4974 bytes) taskResourceAssignments Map()
2022-01-12 15:09:57 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-01-12 15:09:57 INFO  Executor:57 - Running task 0.0 in stage 9.0 (TID 9)
2022-01-12 15:09:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (9, 0) -> 1
2022-01-12 15:09:57 DEBUG BlockManager:61 - Getting local block broadcast_17
2022-01-12 15:09:57 DEBUG BlockManager:61 - Level for block broadcast_17 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:57 DEBUG GenerateSafeProjection:61 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-01-12 15:09:57 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Rahul%20Kabothula/Intellij%20Maven%20Projects/retail_db/result/task1_result/part-00000-9da1dfbd-eb54-41e7-ad55-d28ab595e9f6-c000.csv, range: 0-98741, partition values: [empty row]
2022-01-12 15:09:57 DEBUG GenerateUnsafeProjection:61 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-12 15:09:57 DEBUG BlockManager:61 - Getting local block broadcast_16
2022-01-12 15:09:57 DEBUG BlockManager:61 - Level for block broadcast_16 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:57 INFO  Executor:57 - Finished task 0.0 in stage 9.0 (TID 9). 1523 bytes result sent to driver
2022-01-12 15:09:57 DEBUG ExecutorMetricsPoller:61 - removing (9, 0) from stageTCMP
2022-01-12 15:09:57 INFO  TaskSetManager:57 - Finished task 0.0 in stage 9.0 (TID 9) in 97 ms on host.docker.internal (executor driver) (1/1)
2022-01-12 15:09:57 INFO  TaskSchedulerImpl:57 - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2022-01-12 15:09:57 INFO  DAGScheduler:57 - ResultStage 9 (load at Extract.java:13) finished in 0.113 s
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - After removal of stage 9, remaining stages = 0
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
2022-01-12 15:09:57 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 9: Stage finished
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Job 7 finished: load at Extract.java:13, took 0.114966 s
2022-01-12 15:09:57 INFO  FileSourceStrategy:57 - Pushed Filters: 
2022-01-12 15:09:57 INFO  FileSourceStrategy:57 - Post-Scan Filters: 
2022-01-12 15:09:57 INFO  FileSourceStrategy:57 - Output Data Schema: struct<>
2022-01-12 15:09:57 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage2(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=2
/* 006 */ final class GeneratedIteratorForCodegenStage2 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private boolean agg_bufIsNull_0;
/* 011 */   private long agg_bufValue_0;
/* 012 */   private scala.collection.Iterator inputadapter_input_0;
/* 013 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] agg_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 014 */
/* 015 */   public GeneratedIteratorForCodegenStage2(Object[] references) {
/* 016 */     this.references = references;
/* 017 */   }
/* 018 */
/* 019 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 020 */     partitionIndex = index;
/* 021 */     this.inputs = inputs;
/* 022 */
/* 023 */     inputadapter_input_0 = inputs[0];
/* 024 */     agg_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 025 */
/* 026 */   }
/* 027 */
/* 028 */   private void agg_doAggregateWithoutKey_0() throws java.io.IOException {
/* 029 */     // initialize aggregation buffer
/* 030 */     agg_bufIsNull_0 = false;
/* 031 */     agg_bufValue_0 = 0L;
/* 032 */
/* 033 */     while ( inputadapter_input_0.hasNext()) {
/* 034 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 035 */
/* 036 */       long inputadapter_value_0 = inputadapter_row_0.getLong(0);
/* 037 */
/* 038 */       agg_doConsume_0(inputadapter_row_0, inputadapter_value_0);
/* 039 */       // shouldStop check is eliminated
/* 040 */     }
/* 041 */
/* 042 */   }
/* 043 */
/* 044 */   private void agg_doConsume_0(InternalRow inputadapter_row_0, long agg_expr_0_0) throws java.io.IOException {
/* 045 */     // do aggregate
/* 046 */     // common sub-expressions
/* 047 */
/* 048 */     // evaluate aggregate functions and update aggregation buffers
/* 049 */
/* 050 */     long agg_value_3 = -1L;
/* 051 */
/* 052 */     agg_value_3 = agg_bufValue_0 + agg_expr_0_0;
/* 053 */
/* 054 */     agg_bufIsNull_0 = false;
/* 055 */     agg_bufValue_0 = agg_value_3;
/* 056 */
/* 057 */   }
/* 058 */
/* 059 */   protected void processNext() throws java.io.IOException {
/* 060 */     while (!agg_initAgg_0) {
/* 061 */       agg_initAgg_0 = true;
/* 062 */       long agg_beforeAgg_0 = System.nanoTime();
/* 063 */       agg_doAggregateWithoutKey_0();
/* 064 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* aggTime */).add((System.nanoTime() - agg_beforeAgg_0) / 1000000);
/* 065 */
/* 066 */       // output the result
/* 067 */
/* 068 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 069 */       agg_mutableStateArray_0[0].reset();
/* 070 */
/* 071 */       agg_mutableStateArray_0[0].zeroOutNullBytes();
/* 072 */
/* 073 */       agg_mutableStateArray_0[0].write(0, agg_bufValue_0);
/* 074 */       append((agg_mutableStateArray_0[0].getRow()));
/* 075 */     }
/* 076 */   }
/* 077 */
/* 078 */ }

2022-01-12 15:09:57 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private boolean agg_bufIsNull_0;
/* 011 */   private long agg_bufValue_0;
/* 012 */   private scala.collection.Iterator inputadapter_input_0;
/* 013 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] agg_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 014 */
/* 015 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 016 */     this.references = references;
/* 017 */   }
/* 018 */
/* 019 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 020 */     partitionIndex = index;
/* 021 */     this.inputs = inputs;
/* 022 */
/* 023 */     inputadapter_input_0 = inputs[0];
/* 024 */     agg_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 025 */
/* 026 */   }
/* 027 */
/* 028 */   private void agg_doAggregateWithoutKey_0() throws java.io.IOException {
/* 029 */     // initialize aggregation buffer
/* 030 */     agg_bufIsNull_0 = false;
/* 031 */     agg_bufValue_0 = 0L;
/* 032 */
/* 033 */     while ( inputadapter_input_0.hasNext()) {
/* 034 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 035 */
/* 036 */       agg_doConsume_0(inputadapter_row_0);
/* 037 */       // shouldStop check is eliminated
/* 038 */     }
/* 039 */
/* 040 */   }
/* 041 */
/* 042 */   private void agg_doConsume_0(InternalRow inputadapter_row_0) throws java.io.IOException {
/* 043 */     // do aggregate
/* 044 */     // common sub-expressions
/* 045 */
/* 046 */     // evaluate aggregate functions and update aggregation buffers
/* 047 */
/* 048 */     long agg_value_1 = -1L;
/* 049 */
/* 050 */     agg_value_1 = agg_bufValue_0 + 1L;
/* 051 */
/* 052 */     agg_bufIsNull_0 = false;
/* 053 */     agg_bufValue_0 = agg_value_1;
/* 054 */
/* 055 */   }
/* 056 */
/* 057 */   protected void processNext() throws java.io.IOException {
/* 058 */     while (!agg_initAgg_0) {
/* 059 */       agg_initAgg_0 = true;
/* 060 */       long agg_beforeAgg_0 = System.nanoTime();
/* 061 */       agg_doAggregateWithoutKey_0();
/* 062 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* aggTime */).add((System.nanoTime() - agg_beforeAgg_0) / 1000000);
/* 063 */
/* 064 */       // output the result
/* 065 */
/* 066 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 067 */       agg_mutableStateArray_0[0].reset();
/* 068 */
/* 069 */       agg_mutableStateArray_0[0].zeroOutNullBytes();
/* 070 */
/* 071 */       agg_mutableStateArray_0[0].write(0, agg_bufValue_0);
/* 072 */       append((agg_mutableStateArray_0[0].getRow()));
/* 073 */     }
/* 074 */   }
/* 075 */
/* 076 */ }

2022-01-12 15:09:57 INFO  MemoryStore:57 - Block broadcast_18 stored as values in memory (estimated size 174.2 KiB, free 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManager:61 - Put block broadcast_18 locally took 3 ms
2022-01-12 15:09:57 DEBUG BlockManager:61 - Putting block broadcast_18 without replication took 4 ms
2022-01-12 15:09:57 INFO  MemoryStore:57 - Block broadcast_18_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_18_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:57 INFO  BlockManagerInfo:57 - Added broadcast_18_piece0 in memory on host.docker.internal:64148 (size: 27.6 KiB, free: 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_18_piece0
2022-01-12 15:09:57 DEBUG BlockManager:61 - Told master about block broadcast_18_piece0
2022-01-12 15:09:57 DEBUG BlockManager:61 - Put block broadcast_18_piece0 locally took 2 ms
2022-01-12 15:09:57 DEBUG BlockManager:61 - Putting block broadcast_18_piece0 without replication took 3 ms
2022-01-12 15:09:57 INFO  SparkContext:57 - Created broadcast 18 from count at LoadTesting.java:21
2022-01-12 15:09:57 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$collect$2
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$collect$2) is now cleaned +++
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$5
2022-01-12 15:09:57 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
2022-01-12 15:09:57 INFO  SparkContext:57 - Starting job: count at LoadTesting.java:21
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - Merging stage rdd profiles: Set()
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - Merging stage rdd profiles: Set()
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Registering RDD 47 (count at LoadTesting.java:21) as input to shuffle 2
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Got job 8 (count at LoadTesting.java:21) with 1 output partitions
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Final stage: ResultStage 11 (count at LoadTesting.java:21)
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Parents of final stage: List(ShuffleMapStage 10)
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Missing parents: List(ShuffleMapStage 10)
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - submitStage(ResultStage 11 (name=count at LoadTesting.java:21;jobs=8))
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - missing: List(ShuffleMapStage 10)
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - submitStage(ShuffleMapStage 10 (name=count at LoadTesting.java:21;jobs=8))
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - missing: List()
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Submitting ShuffleMapStage 10 (MapPartitionsRDD[47] at count at LoadTesting.java:21), which has no missing parents
2022-01-12 15:09:57 DEBUG DAGScheduler:61 - submitMissingTasks(ShuffleMapStage 10)
2022-01-12 15:09:57 INFO  MemoryStore:57 - Block broadcast_19 stored as values in memory (estimated size 15.3 KiB, free 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManager:61 - Put block broadcast_19 locally took 2 ms
2022-01-12 15:09:57 DEBUG BlockManager:61 - Putting block broadcast_19 without replication took 2 ms
2022-01-12 15:09:57 INFO  MemoryStore:57 - Block broadcast_19_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 2.2 GiB)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanShuffle(0)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning shuffle 0
2022-01-12 15:09:57 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_19_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:57 INFO  BlockManagerInfo:57 - Added broadcast_19_piece0 in memory on host.docker.internal:64148 (size: 7.9 KiB, free: 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_19_piece0
2022-01-12 15:09:57 DEBUG BlockManager:61 - Told master about block broadcast_19_piece0
2022-01-12 15:09:57 DEBUG BlockManager:61 - Put block broadcast_19_piece0 locally took 5 ms
2022-01-12 15:09:57 DEBUG BlockManager:61 - Putting block broadcast_19_piece0 without replication took 5 ms
2022-01-12 15:09:57 INFO  SparkContext:57 - Created broadcast 19 from broadcast at DAGScheduler.scala:1388
2022-01-12 15:09:57 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[47] at count at LoadTesting.java:21) (first 15 tasks are for partitions Vector(0))
2022-01-12 15:09:57 INFO  TaskSchedulerImpl:57 - Adding task set 10.0 with 1 tasks resource profile 0
2022-01-12 15:09:57 DEBUG TaskSetManager:61 - Epoch for TaskSet 10.0: 2
2022-01-12 15:09:57 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-01-12 15:09:57 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 10.0: NO_PREF, ANY
2022-01-12 15:09:57 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_10.0, runningTasks: 0
2022-01-12 15:09:57 INFO  TaskSetManager:57 - Starting task 0.0 in stage 10.0 (TID 10) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4963 bytes) taskResourceAssignments Map()
2022-01-12 15:09:57 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-01-12 15:09:57 INFO  Executor:57 - Running task 0.0 in stage 10.0 (TID 10)
2022-01-12 15:09:57 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (10, 0) -> 1
2022-01-12 15:09:57 DEBUG BlockManager:61 - Getting local block broadcast_19
2022-01-12 15:09:57 DEBUG BlockManager:61 - Level for block broadcast_19 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:57 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Rahul%20Kabothula/Intellij%20Maven%20Projects/retail_db/result/task1_result/part-00000-9da1dfbd-eb54-41e7-ad55-d28ab595e9f6-c000.csv, range: 0-98741, partition values: [empty row]
2022-01-12 15:09:57 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-01-12 15:09:57 DEBUG BlockManager:61 - Getting local block broadcast_18
2022-01-12 15:09:57 DEBUG BlockManager:61 - Level for block broadcast_18 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned shuffle 0
2022-01-12 15:09:57 DEBUG BlockManagerStorageEndpoint:61 - removing shuffle 0
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(159)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 159
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 159
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(185)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 185
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 185
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(304)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 304
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 304
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(368)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 368
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 368
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(381)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 381
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 381
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(0)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 0
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 0
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(282)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 282
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 282
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(136)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 136
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 136
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(325)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 325
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 325
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(303)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 303
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 303
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(142)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 142
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 142
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(71)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 71
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 71
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(67)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 67
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 67
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(250)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 250
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 250
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(191)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 191
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 191
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(100)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 100
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 100
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(93)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 93
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 93
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(353)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 353
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 353
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(247)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 247
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 247
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(170)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 170
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 170
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(200)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 200
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 200
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(192)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 192
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 192
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(266)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 266
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 266
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(16)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 16
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 16
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(49)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 49
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 49
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(25)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 25
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 25
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(28)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 28
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 28
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(3)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning broadcast 3
2022-01-12 15:09:57 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 3
2022-01-12 15:09:57 DEBUG BlockManagerStorageEndpoint:61 - removing broadcast 3
2022-01-12 15:09:57 DEBUG BlockManager:61 - Removing broadcast 3
2022-01-12 15:09:57 DEBUG BlockManagerStorageEndpoint:61 - Done removing shuffle 0, response is true
2022-01-12 15:09:57 DEBUG BlockManagerStorageEndpoint:61 - Sent response: true to host.docker.internal:64105
2022-01-12 15:09:57 DEBUG BlockManager:61 - Removing block broadcast_3_piece0
2022-01-12 15:09:57 DEBUG MemoryStore:61 - Block broadcast_3_piece0 of size 7975 dropped from memory (free 2345895517)
2022-01-12 15:09:57 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_3_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:57 INFO  BlockManagerInfo:57 - Removed broadcast_3_piece0 on host.docker.internal:64148 in memory (size: 7.8 KiB, free: 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_3_piece0
2022-01-12 15:09:57 DEBUG BlockManager:61 - Told master about block broadcast_3_piece0
2022-01-12 15:09:57 DEBUG BlockManager:61 - Removing block broadcast_3
2022-01-12 15:09:57 DEBUG MemoryStore:61 - Block broadcast_3 of size 15816 dropped from memory (free 2345911333)
2022-01-12 15:09:57 DEBUG BlockManagerStorageEndpoint:61 - Done removing broadcast 3, response is 0
2022-01-12 15:09:57 DEBUG BlockManagerStorageEndpoint:61 - Sent response: 0 to host.docker.internal:64105
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned broadcast 3
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(2)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning broadcast 2
2022-01-12 15:09:57 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 2
2022-01-12 15:09:57 DEBUG BlockManagerStorageEndpoint:61 - removing broadcast 2
2022-01-12 15:09:57 DEBUG BlockManager:61 - Removing broadcast 2
2022-01-12 15:09:57 DEBUG BlockManager:61 - Removing block broadcast_2
2022-01-12 15:09:57 DEBUG MemoryStore:61 - Block broadcast_2 of size 178496 dropped from memory (free 2346089829)
2022-01-12 15:09:57 DEBUG BlockManager:61 - Removing block broadcast_2_piece0
2022-01-12 15:09:57 DEBUG MemoryStore:61 - Block broadcast_2_piece0 of size 28276 dropped from memory (free 2346118105)
2022-01-12 15:09:57 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_2_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:57 INFO  BlockManagerInfo:57 - Removed broadcast_2_piece0 on host.docker.internal:64148 in memory (size: 27.6 KiB, free: 2.2 GiB)
2022-01-12 15:09:57 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_2_piece0
2022-01-12 15:09:57 DEBUG BlockManager:61 - Told master about block broadcast_2_piece0
2022-01-12 15:09:57 DEBUG BlockManagerStorageEndpoint:61 - Done removing broadcast 2, response is 0
2022-01-12 15:09:57 DEBUG BlockManagerStorageEndpoint:61 - Sent response: 0 to host.docker.internal:64105
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned broadcast 2
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(231)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 231
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 231
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(277)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 277
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 277
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(34)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 34
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 34
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(75)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 75
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 75
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(251)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 251
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 251
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(37)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 37
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 37
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(77)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 77
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 77
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(339)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 339
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 339
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(152)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 152
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 152
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(263)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 263
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 263
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(308)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 308
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 308
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(332)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 332
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 332
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(245)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 245
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 245
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(350)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 350
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 350
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(40)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 40
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 40
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(103)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 103
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 103
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(221)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 221
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 221
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(253)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 253
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 253
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(220)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 220
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 220
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(171)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 171
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 171
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(235)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning accumulator 235
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaned accumulator 235
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(12)
2022-01-12 15:09:57 DEBUG ContextCleaner:61 - Cleaning broadcast 12
2022-01-12 15:09:57 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 12
2022-01-12 15:09:58 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 10 with length 1
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - removing broadcast 12
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing broadcast 12
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_12_piece0
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_12_piece0 of size 7963 dropped from memory (free 2346126068)
2022-01-12 15:09:58 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_12_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:58 INFO  BlockManagerInfo:57 - Removed broadcast_12_piece0 on host.docker.internal:64148 in memory (size: 7.8 KiB, free: 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_12_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Told master about block broadcast_12_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_12
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_12 of size 15472 dropped from memory (free 2346141540)
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Done removing broadcast 12, response is 0
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Sent response: 0 to host.docker.internal:64105
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned broadcast 12
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(323)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 323
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 323
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(295)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 295
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 295
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(254)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 254
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 254
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(87)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 87
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 87
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(156)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 156
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 156
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(307)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 307
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 307
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(168)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 168
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 168
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(376)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 376
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 376
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(22)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 22
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 22
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(341)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 341
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 341
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(208)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 208
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 208
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(318)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 318
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 318
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(63)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 63
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 63
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(287)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 287
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 287
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(240)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 240
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 240
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(138)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 138
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 138
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(361)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 361
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 361
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(98)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 98
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 98
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(51)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 51
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 51
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(79)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 79
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 79
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(106)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 106
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 106
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(211)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 211
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 211
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(14)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning broadcast 14
2022-01-12 15:09:58 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 14
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - removing broadcast 14
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing broadcast 14
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_14
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_14 of size 178496 dropped from memory (free 2346320036)
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_14_piece0
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_14_piece0 of size 28276 dropped from memory (free 2346348312)
2022-01-12 15:09:58 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_14_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:58 INFO  BlockManagerInfo:57 - Removed broadcast_14_piece0 on host.docker.internal:64148 in memory (size: 27.6 KiB, free: 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_14_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Told master about block broadcast_14_piece0
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Done removing broadcast 14, response is 0
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Sent response: 0 to host.docker.internal:64105
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned broadcast 14
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(47)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 47
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 47
2022-01-12 15:09:58 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 10: [59]
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(86)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 86
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 86
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(244)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 244
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 244
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(301)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 301
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 301
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(386)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 386
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 386
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(150)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 150
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 150
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(27)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 27
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 27
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(395)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 395
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 395
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(238)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 238
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 238
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(96)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 96
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 96
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(125)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 125
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 125
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(108)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 108
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 108
2022-01-12 15:09:58 INFO  Executor:57 - Finished task 0.0 in stage 10.0 (TID 10). 1887 bytes result sent to driver
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(127)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 127
2022-01-12 15:09:58 DEBUG ExecutorMetricsPoller:61 - removing (10, 0) from stageTCMP
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 127
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(261)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 261
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 261
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(4)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 4
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 4
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(48)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 48
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 48
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(41)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 41
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 41
2022-01-12 15:09:58 INFO  TaskSetManager:57 - Finished task 0.0 in stage 10.0 (TID 10) in 75 ms on host.docker.internal (executor driver) (1/1)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(179)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 179
2022-01-12 15:09:58 INFO  TaskSchedulerImpl:57 - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 179
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(60)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 60
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 60
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(312)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 312
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 312
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(123)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 123
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 123
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(365)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 365
2022-01-12 15:09:58 INFO  DAGScheduler:57 - ShuffleMapStage 10 (count at LoadTesting.java:21) finished in 0.107 s
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 365
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(256)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 256
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 256
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(2)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 2
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 2
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(21)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 21
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 21
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(199)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 199
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 199
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(30)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 30
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 30
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(371)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 371
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 371
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(167)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 167
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 167
2022-01-12 15:09:58 INFO  DAGScheduler:57 - looking for newly runnable stages
2022-01-12 15:09:58 INFO  DAGScheduler:57 - running: Set()
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(216)
2022-01-12 15:09:58 INFO  DAGScheduler:57 - waiting: Set(ResultStage 11)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 216
2022-01-12 15:09:58 INFO  DAGScheduler:57 - failed: Set()
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 216
2022-01-12 15:09:58 DEBUG MapOutputTrackerMaster:61 - Increasing epoch to 3
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(1)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 1
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 1
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(364)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 364
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - submitStage(ResultStage 11 (name=count at LoadTesting.java:21;jobs=8))
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 364
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(280)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 280
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - missing: List()
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 280
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(163)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 163
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Submitting ResultStage 11 (MapPartitionsRDD[50] at count at LoadTesting.java:21), which has no missing parents
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 163
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 11)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(194)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 194
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 194
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(128)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 128
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 128
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(24)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 24
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 24
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(285)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 285
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 285
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(328)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 328
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 328
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(320)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 320
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 320
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(29)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 29
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 29
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(148)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 148
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 148
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(289)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 289
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 289
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(314)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 314
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 314
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(366)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 366
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 366
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(374)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 374
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 374
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(59)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 59
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 59
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(382)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 382
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 382
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(35)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 35
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 35
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(36)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 36
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 36
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(309)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 309
2022-01-12 15:09:58 INFO  MemoryStore:57 - Block broadcast_20 stored as values in memory (estimated size 10.1 KiB, free 2.2 GiB)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 309
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(44)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 44
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 44
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(52)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 52
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 52
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(205)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 205
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 205
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(214)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 214
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 214
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(331)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 331
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 331
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(8)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 8
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 8
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(213)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 213
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 213
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(265)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 265
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 265
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(17)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 17
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 17
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(317)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 317
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 317
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(85)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 85
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 85
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(12)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 12
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 12
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(62)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 62
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 62
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(272)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 272
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 272
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(302)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 302
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 302
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(207)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 207
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 207
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(70)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 70
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 70
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(267)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 267
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 267
2022-01-12 15:09:58 DEBUG BlockManager:61 - Put block broadcast_20 locally took 3 ms
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(155)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 155
2022-01-12 15:09:58 DEBUG BlockManager:61 - Putting block broadcast_20 without replication took 3 ms
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 155
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(367)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 367
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 367
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(210)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 210
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 210
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(195)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 195
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 195
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(184)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 184
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 184
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(73)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 73
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 73
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(249)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 249
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 249
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(275)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 275
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 275
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(114)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 114
2022-01-12 15:09:58 INFO  MemoryStore:57 - Block broadcast_20_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 2.2 GiB)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 114
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(324)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 324
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 324
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(196)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 196
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 196
2022-01-12 15:09:58 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_20_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(129)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 129
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 129
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(388)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 388
2022-01-12 15:09:58 INFO  BlockManagerInfo:57 - Added broadcast_20_piece0 in memory on host.docker.internal:64148 (size: 5.0 KiB, free: 2.2 GiB)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 388
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(343)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 343
2022-01-12 15:09:58 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_20_piece0
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 343
2022-01-12 15:09:58 DEBUG BlockManager:61 - Told master about block broadcast_20_piece0
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(26)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 26
2022-01-12 15:09:58 DEBUG BlockManager:61 - Put block broadcast_20_piece0 locally took 2 ms
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 26
2022-01-12 15:09:58 DEBUG BlockManager:61 - Putting block broadcast_20_piece0 without replication took 2 ms
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(393)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 393
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 393
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(212)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 212
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 212
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(262)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 262
2022-01-12 15:09:58 INFO  SparkContext:57 - Created broadcast 20 from broadcast at DAGScheduler.scala:1388
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 262
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(313)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 313
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 313
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(151)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 151
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 151
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(193)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 193
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 193
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(153)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 153
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[50] at count at LoadTesting.java:21) (first 15 tasks are for partitions Vector(0))
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 153
2022-01-12 15:09:58 INFO  TaskSchedulerImpl:57 - Adding task set 11.0 with 1 tasks resource profile 0
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(6)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning broadcast 6
2022-01-12 15:09:58 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 6
2022-01-12 15:09:58 DEBUG TaskSetManager:61 - Epoch for TaskSet 11.0: 3
2022-01-12 15:09:58 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - removing broadcast 6
2022-01-12 15:09:58 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 11.0: NODE_LOCAL, ANY
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing broadcast 6
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_6_piece0
2022-01-12 15:09:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_6_piece0 of size 5165 dropped from memory (free 2346337949)
2022-01-12 15:09:58 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_6_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:58 INFO  TaskSetManager:57 - Starting task 0.0 in stage 11.0 (TID 11) (host.docker.internal, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-12 15:09:58 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
2022-01-12 15:09:58 INFO  BlockManagerInfo:57 - Removed broadcast_6_piece0 on host.docker.internal:64148 in memory (size: 5.0 KiB, free: 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_6_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Told master about block broadcast_6_piece0
2022-01-12 15:09:58 INFO  Executor:57 - Running task 0.0 in stage 11.0 (TID 11)
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_6
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_6 of size 10360 dropped from memory (free 2346348309)
2022-01-12 15:09:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (11, 0) -> 1
2022-01-12 15:09:58 DEBUG BlockManager:61 - Getting local block broadcast_20
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Done removing broadcast 6, response is 0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Level for block broadcast_20 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Sent response: 0 to host.docker.internal:64105
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned broadcast 6
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(4)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning broadcast 4
2022-01-12 15:09:58 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 4
2022-01-12 15:09:58 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 2
2022-01-12 15:09:58 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 2, mappers 0-1, partitions 0-1
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - removing broadcast 4
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing broadcast 4
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_4_piece0
2022-01-12 15:09:58 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_4_piece0 of size 28310 dropped from memory (free 2346376619)
2022-01-12 15:09:58 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-12 15:09:58 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 1 ms
2022-01-12 15:09:58 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_4_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:58 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_2_10_0,0)
2022-01-12 15:09:58 DEBUG BlockManager:61 - Getting local shuffle block shuffle_2_10_0
2022-01-12 15:09:58 INFO  BlockManagerInfo:57 - Removed broadcast_4_piece0 on host.docker.internal:64148 in memory (size: 27.6 KiB, free: 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_4_piece0
2022-01-12 15:09:58 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 2 ms
2022-01-12 15:09:58 DEBUG BlockManager:61 - Told master about block broadcast_4_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_4
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_4 of size 178408 dropped from memory (free 2346555027)
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Done removing broadcast 4, response is 0
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Sent response: 0 to host.docker.internal:64105
2022-01-12 15:09:58 INFO  Executor:57 - Finished task 0.0 in stage 11.0 (TID 11). 2605 bytes result sent to driver
2022-01-12 15:09:58 DEBUG ExecutorMetricsPoller:61 - removing (11, 0) from stageTCMP
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned broadcast 4
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(237)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 237
2022-01-12 15:09:58 INFO  TaskSetManager:57 - Finished task 0.0 in stage 11.0 (TID 11) in 17 ms on host.docker.internal (executor driver) (1/1)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 237
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(352)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 352
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 352
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(58)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 58
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 58
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(177)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 177
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 177
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(373)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 373
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 373
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(15)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 15
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 15
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(165)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 165
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 165
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(31)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 31
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 31
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(349)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 349
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 349
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(271)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 271
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 271
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(299)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 299
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 299
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(209)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 209
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 209
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(305)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 305
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 305
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(321)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 321
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 321
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(274)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 274
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 274
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(120)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 120
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 120
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(137)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 137
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 137
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(10)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 10
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 10
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(43)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 43
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 43
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(176)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 176
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 176
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(66)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 66
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 66
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(273)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 273
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 273
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(45)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 45
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 45
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(391)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 391
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 391
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(18)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 18
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 18
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(7)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning broadcast 7
2022-01-12 15:09:58 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 7
2022-01-12 15:09:58 INFO  TaskSchedulerImpl:57 - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2022-01-12 15:09:58 INFO  DAGScheduler:57 - ResultStage 11 (count at LoadTesting.java:21) finished in 0.037 s
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - After removal of stage 11, remaining stages = 1
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - After removal of stage 10, remaining stages = 0
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
2022-01-12 15:09:58 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 11: Stage finished
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Job 8 finished: count at LoadTesting.java:21, took 0.164154 s
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - removing broadcast 7
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing broadcast 7
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_7
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_7 of size 178496 dropped from memory (free 2346733523)
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_7_piece0
2022-01-12 15:09:58 WARN  SparkSession$Builder:69 - Using an existing SparkSession; some spark core configurations may not take effect.
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_7_piece0 of size 28276 dropped from memory (free 2346761799)
2022-01-12 15:09:58 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_7_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:58 INFO  BlockManagerInfo:57 - Removed broadcast_7_piece0 on host.docker.internal:64148 in memory (size: 27.6 KiB, free: 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_7_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Told master about block broadcast_7_piece0
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Done removing broadcast 7, response is 0
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Sent response: 0 to host.docker.internal:64105
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned broadcast 7
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(286)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 286
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 286
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(140)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 140
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 140
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(288)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 288
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 288
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(89)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 89
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 89
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(56)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 56
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 56
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(375)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 375
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 375
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(33)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 33
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 33
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(146)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 146
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 146
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(149)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 149
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 149
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(42)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 42
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 42
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(13)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning broadcast 13
2022-01-12 15:09:58 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 13
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - removing broadcast 13
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing broadcast 13
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_13_piece0
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_13_piece0 of size 5165 dropped from memory (free 2346766964)
2022-01-12 15:09:58 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_13_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:58 INFO  BlockManagerInfo:57 - Removed broadcast_13_piece0 on host.docker.internal:64148 in memory (size: 5.0 KiB, free: 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_13_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Told master about block broadcast_13_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_13
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_13 of size 10360 dropped from memory (free 2346777324)
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Done removing broadcast 13, response is 0
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Sent response: 0 to host.docker.internal:64105
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned broadcast 13
2022-01-12 15:09:58 DEBUG DataSource:61 - Some paths were ignored:
  
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(340)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 340
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 340
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(161)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 161
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 161
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(190)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 190
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 190
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(11)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning broadcast 11
2022-01-12 15:09:58 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 11
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - removing broadcast 11
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing broadcast 11
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_11
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_11 of size 178408 dropped from memory (free 2346955732)
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_11_piece0
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_11_piece0 of size 28310 dropped from memory (free 2346984042)
2022-01-12 15:09:58 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_11_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:58 INFO  BlockManagerInfo:57 - Removed broadcast_11_piece0 on host.docker.internal:64148 in memory (size: 27.6 KiB, free: 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_11_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Told master about block broadcast_11_piece0
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Done removing broadcast 11, response is 0
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Sent response: 0 to host.docker.internal:64105
2022-01-12 15:09:58 INFO  InMemoryFileIndex:57 - It took 4 ms to list leaf files for 1 paths.
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned broadcast 11
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(178)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 178
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 178
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(260)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 260
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 260
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(292)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 292
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 292
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(91)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 91
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 91
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(257)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 257
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 257
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(362)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 362
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 362
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(8)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning broadcast 8
2022-01-12 15:09:58 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 8
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - removing broadcast 8
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing broadcast 8
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_8
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_8 of size 11072 dropped from memory (free 2346995114)
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_8_piece0
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_8_piece0 of size 5511 dropped from memory (free 2347000625)
2022-01-12 15:09:58 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_8_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:58 INFO  BlockManagerInfo:57 - Removed broadcast_8_piece0 on host.docker.internal:64148 in memory (size: 5.4 KiB, free: 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_8_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Told master about block broadcast_8_piece0
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Done removing broadcast 8, response is 0
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Sent response: 0 to host.docker.internal:64105
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned broadcast 8
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(378)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 378
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 378
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(203)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 203
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 203
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(326)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 326
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 326
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(7)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 7
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 7
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(134)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 134
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 134
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(0)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning broadcast 0
2022-01-12 15:09:58 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 0
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - removing broadcast 0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing broadcast 0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_0_piece0
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_0_piece0 of size 28276 dropped from memory (free 2347028901)
2022-01-12 15:09:58 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_0_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:58 INFO  BlockManagerInfo:57 - Removed broadcast_0_piece0 on host.docker.internal:64148 in memory (size: 27.6 KiB, free: 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_0_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Told master about block broadcast_0_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_0
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_0 of size 178496 dropped from memory (free 2347207397)
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Done removing broadcast 0, response is 0
2022-01-12 15:09:58 INFO  InMemoryFileIndex:57 - It took 3 ms to list leaf files for 1 paths.
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Sent response: 0 to host.docker.internal:64105
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned broadcast 0
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(64)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 64
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 64
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(198)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 198
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 198
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(9)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 9
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 9
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(38)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 38
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 38
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(385)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 385
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 385
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(57)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 57
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 57
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(180)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 180
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 180
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(139)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 139
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 139
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(110)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 110
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 110
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(298)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 298
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 298
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(342)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 342
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 342
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(88)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 88
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 88
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(269)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 269
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 269
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(396)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 396
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 396
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(115)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 115
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 115
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(121)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 121
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 121
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(143)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 143
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 143
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(394)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 394
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 394
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(379)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 379
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 379
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(72)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 72
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 72
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(172)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 172
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 172
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(241)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 241
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 241
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(105)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 105
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 105
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(90)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 90
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 90
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(319)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 319
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 319
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(130)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 130
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 130
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(384)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 384
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 384
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(281)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 281
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 281
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(270)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 270
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 270
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(380)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 380
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 380
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(335)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 335
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 335
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(337)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 337
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 337
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(322)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 322
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 322
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(154)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 154
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 154
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(9)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning broadcast 9
2022-01-12 15:09:58 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 9
2022-01-12 15:09:58 DEBUG Analyzer$ResolveReferences:61 - Resolving 'value to value#96
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - removing broadcast 9
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing broadcast 9
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_9_piece0
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_9_piece0 of size 28276 dropped from memory (free 2347235673)
2022-01-12 15:09:58 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_9_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:58 INFO  BlockManagerInfo:57 - Removed broadcast_9_piece0 on host.docker.internal:64148 in memory (size: 27.6 KiB, free: 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_9_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Told master about block broadcast_9_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_9
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_9 of size 178496 dropped from memory (free 2347414169)
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Done removing broadcast 9, response is 0
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Sent response: 0 to host.docker.internal:64105
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned broadcast 9
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(233)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 233
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 233
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(279)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 279
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 279
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(356)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 356
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 356
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(81)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 81
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 81
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(283)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 283
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 283
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(206)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 206
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 206
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(217)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 217
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 217
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(252)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 252
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 252
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(23)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 23
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 23
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(157)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 157
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 157
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(355)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 355
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 355
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(377)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 377
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 377
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(297)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 297
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 297
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(13)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 13
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 13
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(65)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 65
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 65
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(10)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning broadcast 10
2022-01-12 15:09:58 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 10
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - removing broadcast 10
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing broadcast 10
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_10
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_10 of size 15784 dropped from memory (free 2347429953)
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_10_piece0
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_10_piece0 of size 7974 dropped from memory (free 2347437927)
2022-01-12 15:09:58 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_10_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:58 INFO  BlockManagerInfo:57 - Removed broadcast_10_piece0 on host.docker.internal:64148 in memory (size: 7.8 KiB, free: 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_10_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Told master about block broadcast_10_piece0
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Done removing broadcast 10, response is 0
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Sent response: 0 to host.docker.internal:64105
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned broadcast 10
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(183)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 183
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 183
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(290)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 290
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 290
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(219)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 219
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 219
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(78)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 78
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 78
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(68)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 68
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 68
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(147)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 147
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 147
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(204)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 204
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 204
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(234)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 234
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 234
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(61)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 61
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 61
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(259)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 259
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 259
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(294)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 294
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 294
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(291)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 291
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 291
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(166)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 166
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 166
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(118)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 118
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 118
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(344)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 344
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 344
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(315)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 315
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 315
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(383)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 383
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 383
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(358)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 358
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 358
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(215)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 215
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 215
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(242)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 242
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 242
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(202)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 202
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 202
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(133)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 133
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 133
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(330)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 330
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 330
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(169)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 169
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 169
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(135)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 135
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 135
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(117)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 117
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 117
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(230)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 230
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 230
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(50)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 50
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 50
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(175)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 175
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 175
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(293)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 293
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 293
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(363)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 363
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 363
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(372)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 372
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 372
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(122)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 122
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 122
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(336)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 336
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 336
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(131)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 131
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 131
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(16)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning broadcast 16
2022-01-12 15:09:58 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 16
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - removing broadcast 16
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing broadcast 16
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_16
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_16 of size 178496 dropped from memory (free 2347616423)
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_16_piece0
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_16_piece0 of size 28276 dropped from memory (free 2347644699)
2022-01-12 15:09:58 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_16_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:58 INFO  BlockManagerInfo:57 - Removed broadcast_16_piece0 on host.docker.internal:64148 in memory (size: 27.6 KiB, free: 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_16_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Told master about block broadcast_16_piece0
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Done removing broadcast 16, response is 0
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Sent response: 0 to host.docker.internal:64105
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned broadcast 16
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(276)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 276
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 276
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(347)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 347
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 347
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(17)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning broadcast 17
2022-01-12 15:09:58 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 17
2022-01-12 15:09:58 DEBUG Analyzer$ResolveReferences:61 - Resolving 'value to value#102
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - removing broadcast 17
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing broadcast 17
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_17
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_17 of size 15808 dropped from memory (free 2347660507)
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_17_piece0
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_17_piece0 of size 7976 dropped from memory (free 2347668483)
2022-01-12 15:09:58 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_17_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:58 INFO  BlockManagerInfo:57 - Removed broadcast_17_piece0 on host.docker.internal:64148 in memory (size: 7.8 KiB, free: 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_17_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Told master about block broadcast_17_piece0
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Done removing broadcast 17, response is 0
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Sent response: 0 to host.docker.internal:64105
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned broadcast 17
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(164)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 164
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 164
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(316)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 316
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 316
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(69)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 69
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 69
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(80)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 80
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 80
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(19)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 19
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 19
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(227)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 227
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 227
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(359)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 359
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 359
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(197)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 197
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 197
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(258)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 258
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 258
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(239)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 239
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 239
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(116)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 116
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 116
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(232)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 232
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 232
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(11)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 11
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 11
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(14)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 14
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 14
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(228)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 228
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 228
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(102)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 102
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 102
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(229)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 229
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 229
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(360)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 360
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 360
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(20)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 20
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 20
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(76)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 76
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 76
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(300)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 300
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 300
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(187)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 187
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 187
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(218)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 218
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 218
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(55)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 55
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 55
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(334)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 334
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 334
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(186)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 186
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 186
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(182)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 182
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 182
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(132)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 132
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 132
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(39)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 39
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 39
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(346)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 346
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 346
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(369)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 369
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 369
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(104)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 104
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 104
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(97)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 97
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 97
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(162)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 162
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 162
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(255)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 255
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 255
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(278)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 278
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 278
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(124)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 124
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 124
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(248)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 248
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 248
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanShuffle(1)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning shuffle 1
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned shuffle 1
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(32)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 32
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 32
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(82)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 82
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 82
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(296)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 296
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 296
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(5)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 5
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 5
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(181)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 181
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - removing shuffle 1
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 181
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(5)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning broadcast 5
2022-01-12 15:09:58 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 5
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - removing broadcast 5
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing broadcast 5
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_5
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_5 of size 15728 dropped from memory (free 2347684211)
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_5_piece0
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_5_piece0 of size 8050 dropped from memory (free 2347692261)
2022-01-12 15:09:58 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_5_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:58 INFO  BlockManagerInfo:57 - Removed broadcast_5_piece0 on host.docker.internal:64148 in memory (size: 7.9 KiB, free: 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_5_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Told master about block broadcast_5_piece0
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Done removing broadcast 5, response is 0
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Sent response: 0 to host.docker.internal:64105
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned broadcast 5
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(284)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 284
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 284
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(189)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 189
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 189
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(311)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 311
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 311
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(370)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 370
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 370
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(95)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 95
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 95
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(348)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 348
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 348
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(101)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 101
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 101
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(84)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 84
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 84
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(333)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 333
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 333
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(74)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 74
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 74
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(15)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning broadcast 15
2022-01-12 15:09:58 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 15
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - removing broadcast 15
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing broadcast 15
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_15
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_15 of size 11072 dropped from memory (free 2347703333)
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_15_piece0
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_15_piece0 of size 5509 dropped from memory (free 2347708842)
2022-01-12 15:09:58 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_15_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:58 INFO  BlockManagerInfo:57 - Removed broadcast_15_piece0 on host.docker.internal:64148 in memory (size: 5.4 KiB, free: 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_15_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Told master about block broadcast_15_piece0
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Done removing shuffle 1, response is true
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Sent response: true to host.docker.internal:64105
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Done removing broadcast 15, response is 0
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Sent response: 0 to host.docker.internal:64105
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned broadcast 15
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(246)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 246
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 246
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(160)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 160
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 160
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(174)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 174
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 174
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(112)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 112
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 112
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(327)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 327
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 327
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(224)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 224
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 224
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(158)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 158
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 158
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(243)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 243
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 243
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(351)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 351
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 351
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(345)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 345
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 345
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(99)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 99
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 99
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(92)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 92
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 92
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(354)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 354
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 354
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(173)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 173
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 173
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(46)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 46
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 46
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(94)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 94
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 94
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(113)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 113
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 113
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(126)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 126
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 126
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(357)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 357
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 357
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(107)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 107
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 107
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(3)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 3
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 3
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(111)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 111
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 111
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(390)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 390
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 390
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(392)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 392
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 392
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(109)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 109
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 109
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(188)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 188
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 188
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(222)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 222
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 222
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanBroadcast(1)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning broadcast 1
2022-01-12 15:09:58 DEBUG TorrentBroadcast:61 - Unpersisting TorrentBroadcast 1
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - removing broadcast 1
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing broadcast 1
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_1
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_1 of size 11072 dropped from memory (free 2347719914)
2022-01-12 15:09:58 DEBUG BlockManager:61 - Removing block broadcast_1_piece0
2022-01-12 15:09:58 DEBUG MemoryStore:61 - Block broadcast_1_piece0 of size 5500 dropped from memory (free 2347725414)
2022-01-12 15:09:58 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_1_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:58 INFO  BlockManagerInfo:57 - Removed broadcast_1_piece0 on host.docker.internal:64148 in memory (size: 5.4 KiB, free: 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_1_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Told master about block broadcast_1_piece0
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Done removing broadcast 1, response is 0
2022-01-12 15:09:58 DEBUG BlockManagerStorageEndpoint:61 - Sent response: 0 to host.docker.internal:64105
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned broadcast 1
2022-01-12 15:09:58 INFO  FileSourceStrategy:57 - Pushed Filters: 
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(387)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 387
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 387
2022-01-12 15:09:58 INFO  FileSourceStrategy:57 - Post-Scan Filters: (length(trim(value#96, None)) > 0)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(338)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 338
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 338
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(268)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 268
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 268
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(201)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 201
2022-01-12 15:09:58 INFO  FileSourceStrategy:57 - Output Data Schema: struct<value: string>
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 201
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(225)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 225
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 225
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(389)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 389
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 389
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(236)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 236
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 236
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(226)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 226
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 226
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(6)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 6
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 6
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(53)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 53
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 53
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(141)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 141
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 141
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(306)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 306
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 306
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(264)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 264
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 264
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(223)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 223
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 223
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(144)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 144
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 144
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(329)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 329
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 329
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(119)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 119
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 119
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(145)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 145
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 145
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(54)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 54
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 54
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(310)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 310
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 310
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Got cleaning task CleanAccum(83)
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaning accumulator 83
2022-01-12 15:09:58 DEBUG ContextCleaner:61 - Cleaned accumulator 83
2022-01-12 15:09:58 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator inputadapter_input_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     inputadapter_input_0 = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while ( inputadapter_input_0.hasNext()) {
/* 026 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 027 */
/* 028 */       do {
/* 029 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 030 */         UTF8String inputadapter_value_0 = inputadapter_isNull_0 ?
/* 031 */         null : (inputadapter_row_0.getUTF8String(0));
/* 032 */
/* 033 */         boolean filter_isNull_0 = true;
/* 034 */         boolean filter_value_0 = false;
/* 035 */         boolean filter_isNull_2 = false;
/* 036 */         UTF8String filter_value_2 = null;
/* 037 */         if (inputadapter_isNull_0) {
/* 038 */           filter_isNull_2 = true;
/* 039 */         } else {
/* 040 */           filter_value_2 = inputadapter_value_0.trim();
/* 041 */         }
/* 042 */         boolean filter_isNull_1 = filter_isNull_2;
/* 043 */         int filter_value_1 = -1;
/* 044 */
/* 045 */         if (!filter_isNull_2) {
/* 046 */           filter_value_1 = (filter_value_2).numChars();
/* 047 */         }
/* 048 */         if (!filter_isNull_1) {
/* 049 */           filter_isNull_0 = false; // resultCode could change nullability.
/* 050 */           filter_value_0 = filter_value_1 > 0;
/* 051 */
/* 052 */         }
/* 053 */         if (filter_isNull_0 || !filter_value_0) continue;
/* 054 */
/* 055 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 056 */
/* 057 */         filter_mutableStateArray_0[0].reset();
/* 058 */
/* 059 */         filter_mutableStateArray_0[0].zeroOutNullBytes();
/* 060 */
/* 061 */         if (inputadapter_isNull_0) {
/* 062 */           filter_mutableStateArray_0[0].setNullAt(0);
/* 063 */         } else {
/* 064 */           filter_mutableStateArray_0[0].write(0, inputadapter_value_0);
/* 065 */         }
/* 066 */         append((filter_mutableStateArray_0[0].getRow()));
/* 067 */
/* 068 */       } while(false);
/* 069 */       if (shouldStop()) return;
/* 070 */     }
/* 071 */   }
/* 072 */
/* 073 */ }

2022-01-12 15:09:58 INFO  MemoryStore:57 - Block broadcast_21 stored as values in memory (estimated size 174.3 KiB, free 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManager:61 - Put block broadcast_21 locally took 2 ms
2022-01-12 15:09:58 DEBUG BlockManager:61 - Putting block broadcast_21 without replication took 2 ms
2022-01-12 15:09:58 INFO  MemoryStore:57 - Block broadcast_21_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_21_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:58 INFO  BlockManagerInfo:57 - Added broadcast_21_piece0 in memory on host.docker.internal:64148 (size: 27.6 KiB, free: 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_21_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Told master about block broadcast_21_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Put block broadcast_21_piece0 locally took 3 ms
2022-01-12 15:09:58 DEBUG BlockManager:61 - Putting block broadcast_21_piece0 without replication took 3 ms
2022-01-12 15:09:58 INFO  SparkContext:57 - Created broadcast 21 from load at Extract.java:13
2022-01-12 15:09:58 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$executeTake$2
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$executeTake$2) is now cleaned +++
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$5
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
2022-01-12 15:09:58 INFO  SparkContext:57 - Starting job: load at Extract.java:13
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - Merging stage rdd profiles: Set()
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Got job 9 (load at Extract.java:13) with 1 output partitions
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Final stage: ResultStage 12 (load at Extract.java:13)
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Parents of final stage: List()
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Missing parents: List()
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - submitStage(ResultStage 12 (name=load at Extract.java:13;jobs=9))
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - missing: List()
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Submitting ResultStage 12 (MapPartitionsRDD[54] at load at Extract.java:13), which has no missing parents
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 12)
2022-01-12 15:09:58 INFO  MemoryStore:57 - Block broadcast_22 stored as values in memory (estimated size 10.8 KiB, free 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManager:61 - Put block broadcast_22 locally took 2 ms
2022-01-12 15:09:58 DEBUG BlockManager:61 - Putting block broadcast_22 without replication took 2 ms
2022-01-12 15:09:58 INFO  MemoryStore:57 - Block broadcast_22_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_22_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:58 INFO  BlockManagerInfo:57 - Added broadcast_22_piece0 in memory on host.docker.internal:64148 (size: 5.4 KiB, free: 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_22_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Told master about block broadcast_22_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Put block broadcast_22_piece0 locally took 1 ms
2022-01-12 15:09:58 DEBUG BlockManager:61 - Putting block broadcast_22_piece0 without replication took 1 ms
2022-01-12 15:09:58 INFO  SparkContext:57 - Created broadcast 22 from broadcast at DAGScheduler.scala:1388
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[54] at load at Extract.java:13) (first 15 tasks are for partitions Vector(0))
2022-01-12 15:09:58 INFO  TaskSchedulerImpl:57 - Adding task set 12.0 with 1 tasks resource profile 0
2022-01-12 15:09:58 DEBUG TaskSetManager:61 - Epoch for TaskSet 12.0: 3
2022-01-12 15:09:58 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-01-12 15:09:58 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 12.0: NO_PREF, ANY
2022-01-12 15:09:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-01-12 15:09:58 INFO  TaskSetManager:57 - Starting task 0.0 in stage 12.0 (TID 12) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4974 bytes) taskResourceAssignments Map()
2022-01-12 15:09:58 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-01-12 15:09:58 INFO  Executor:57 - Running task 0.0 in stage 12.0 (TID 12)
2022-01-12 15:09:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (12, 0) -> 1
2022-01-12 15:09:58 DEBUG BlockManager:61 - Getting local block broadcast_22
2022-01-12 15:09:58 DEBUG BlockManager:61 - Level for block broadcast_22 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:58 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Rahul%20Kabothula/Intellij%20Maven%20Projects/retail_db/result/task2_result/part-00000-6104a880-9297-4b2e-b8ac-7beeef058e70-c000.csv, range: 0-595175, partition values: [empty row]
2022-01-12 15:09:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-12 15:09:58 DEBUG BlockManager:61 - Getting local block broadcast_21
2022-01-12 15:09:58 DEBUG BlockManager:61 - Level for block broadcast_21 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:58 INFO  Executor:57 - Finished task 0.0 in stage 12.0 (TID 12). 1548 bytes result sent to driver
2022-01-12 15:09:58 DEBUG ExecutorMetricsPoller:61 - removing (12, 0) from stageTCMP
2022-01-12 15:09:58 INFO  TaskSetManager:57 - Finished task 0.0 in stage 12.0 (TID 12) in 19 ms on host.docker.internal (executor driver) (1/1)
2022-01-12 15:09:58 INFO  TaskSchedulerImpl:57 - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2022-01-12 15:09:58 INFO  DAGScheduler:57 - ResultStage 12 (load at Extract.java:13) finished in 0.019 s
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - After removal of stage 12, remaining stages = 0
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
2022-01-12 15:09:58 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 12: Stage finished
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Job 9 finished: load at Extract.java:13, took 0.029163 s
2022-01-12 15:09:58 DEBUG GenerateSafeProjection:61 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-01-12 15:09:58 INFO  FileSourceStrategy:57 - Pushed Filters: 
2022-01-12 15:09:58 INFO  FileSourceStrategy:57 - Post-Scan Filters: 
2022-01-12 15:09:58 INFO  FileSourceStrategy:57 - Output Data Schema: struct<value: string>
2022-01-12 15:09:58 INFO  MemoryStore:57 - Block broadcast_23 stored as values in memory (estimated size 174.3 KiB, free 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManager:61 - Put block broadcast_23 locally took 2 ms
2022-01-12 15:09:58 DEBUG BlockManager:61 - Putting block broadcast_23 without replication took 3 ms
2022-01-12 15:09:58 INFO  MemoryStore:57 - Block broadcast_23_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_23_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:58 INFO  BlockManagerInfo:57 - Added broadcast_23_piece0 in memory on host.docker.internal:64148 (size: 27.6 KiB, free: 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_23_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Told master about block broadcast_23_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Put block broadcast_23_piece0 locally took 3 ms
2022-01-12 15:09:58 DEBUG BlockManager:61 - Putting block broadcast_23_piece0 without replication took 3 ms
2022-01-12 15:09:58 INFO  SparkContext:57 - Created broadcast 23 from load at Extract.java:13
2022-01-12 15:09:58 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$rdd$1
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$rdd$1) is now cleaned +++
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$inferFromDataset$2
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$inferFromDataset$2) is now cleaned +++
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$infer$2
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$infer$2) is now cleaned +++
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$infer$3
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$infer$3) is now cleaned +++
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$6
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$6) is now cleaned +++
2022-01-12 15:09:58 INFO  SparkContext:57 - Starting job: load at Extract.java:13
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - Merging stage rdd profiles: Set()
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Got job 10 (load at Extract.java:13) with 1 output partitions
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Final stage: ResultStage 13 (load at Extract.java:13)
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Parents of final stage: List()
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Missing parents: List()
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - submitStage(ResultStage 13 (name=load at Extract.java:13;jobs=10))
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - missing: List()
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Submitting ResultStage 13 (MapPartitionsRDD[60] at load at Extract.java:13), which has no missing parents
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 13)
2022-01-12 15:09:58 INFO  MemoryStore:57 - Block broadcast_24 stored as values in memory (estimated size 15.5 KiB, free 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManager:61 - Put block broadcast_24 locally took 2 ms
2022-01-12 15:09:58 DEBUG BlockManager:61 - Putting block broadcast_24 without replication took 2 ms
2022-01-12 15:09:58 INFO  MemoryStore:57 - Block broadcast_24_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_24_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:58 INFO  BlockManagerInfo:57 - Added broadcast_24_piece0 in memory on host.docker.internal:64148 (size: 7.8 KiB, free: 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_24_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Told master about block broadcast_24_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Put block broadcast_24_piece0 locally took 1 ms
2022-01-12 15:09:58 DEBUG BlockManager:61 - Putting block broadcast_24_piece0 without replication took 1 ms
2022-01-12 15:09:58 INFO  SparkContext:57 - Created broadcast 24 from broadcast at DAGScheduler.scala:1388
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[60] at load at Extract.java:13) (first 15 tasks are for partitions Vector(0))
2022-01-12 15:09:58 INFO  TaskSchedulerImpl:57 - Adding task set 13.0 with 1 tasks resource profile 0
2022-01-12 15:09:58 DEBUG TaskSetManager:61 - Epoch for TaskSet 13.0: 3
2022-01-12 15:09:58 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-01-12 15:09:58 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 13.0: NO_PREF, ANY
2022-01-12 15:09:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_13.0, runningTasks: 0
2022-01-12 15:09:58 INFO  TaskSetManager:57 - Starting task 0.0 in stage 13.0 (TID 13) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4974 bytes) taskResourceAssignments Map()
2022-01-12 15:09:58 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-01-12 15:09:58 INFO  Executor:57 - Running task 0.0 in stage 13.0 (TID 13)
2022-01-12 15:09:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (13, 0) -> 1
2022-01-12 15:09:58 DEBUG BlockManager:61 - Getting local block broadcast_24
2022-01-12 15:09:58 DEBUG BlockManager:61 - Level for block broadcast_24 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:58 DEBUG GenerateSafeProjection:61 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-01-12 15:09:58 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Rahul%20Kabothula/Intellij%20Maven%20Projects/retail_db/result/task2_result/part-00000-6104a880-9297-4b2e-b8ac-7beeef058e70-c000.csv, range: 0-595175, partition values: [empty row]
2022-01-12 15:09:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-12 15:09:58 DEBUG BlockManager:61 - Getting local block broadcast_23
2022-01-12 15:09:58 DEBUG BlockManager:61 - Level for block broadcast_23 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:58 INFO  Executor:57 - Finished task 0.0 in stage 13.0 (TID 13). 1548 bytes result sent to driver
2022-01-12 15:09:58 DEBUG ExecutorMetricsPoller:61 - removing (13, 0) from stageTCMP
2022-01-12 15:09:58 INFO  TaskSetManager:57 - Finished task 0.0 in stage 13.0 (TID 13) in 91 ms on host.docker.internal (executor driver) (1/1)
2022-01-12 15:09:58 INFO  TaskSchedulerImpl:57 - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2022-01-12 15:09:58 INFO  DAGScheduler:57 - ResultStage 13 (load at Extract.java:13) finished in 0.107 s
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - After removal of stage 13, remaining stages = 0
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
2022-01-12 15:09:58 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 13: Stage finished
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Job 10 finished: load at Extract.java:13, took 0.112336 s
2022-01-12 15:09:58 INFO  FileSourceStrategy:57 - Pushed Filters: 
2022-01-12 15:09:58 INFO  FileSourceStrategy:57 - Post-Scan Filters: 
2022-01-12 15:09:58 INFO  FileSourceStrategy:57 - Output Data Schema: struct<>
2022-01-12 15:09:58 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage2(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=2
/* 006 */ final class GeneratedIteratorForCodegenStage2 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private boolean agg_bufIsNull_0;
/* 011 */   private long agg_bufValue_0;
/* 012 */   private scala.collection.Iterator inputadapter_input_0;
/* 013 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] agg_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 014 */
/* 015 */   public GeneratedIteratorForCodegenStage2(Object[] references) {
/* 016 */     this.references = references;
/* 017 */   }
/* 018 */
/* 019 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 020 */     partitionIndex = index;
/* 021 */     this.inputs = inputs;
/* 022 */
/* 023 */     inputadapter_input_0 = inputs[0];
/* 024 */     agg_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 025 */
/* 026 */   }
/* 027 */
/* 028 */   private void agg_doAggregateWithoutKey_0() throws java.io.IOException {
/* 029 */     // initialize aggregation buffer
/* 030 */     agg_bufIsNull_0 = false;
/* 031 */     agg_bufValue_0 = 0L;
/* 032 */
/* 033 */     while ( inputadapter_input_0.hasNext()) {
/* 034 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 035 */
/* 036 */       long inputadapter_value_0 = inputadapter_row_0.getLong(0);
/* 037 */
/* 038 */       agg_doConsume_0(inputadapter_row_0, inputadapter_value_0);
/* 039 */       // shouldStop check is eliminated
/* 040 */     }
/* 041 */
/* 042 */   }
/* 043 */
/* 044 */   private void agg_doConsume_0(InternalRow inputadapter_row_0, long agg_expr_0_0) throws java.io.IOException {
/* 045 */     // do aggregate
/* 046 */     // common sub-expressions
/* 047 */
/* 048 */     // evaluate aggregate functions and update aggregation buffers
/* 049 */
/* 050 */     long agg_value_3 = -1L;
/* 051 */
/* 052 */     agg_value_3 = agg_bufValue_0 + agg_expr_0_0;
/* 053 */
/* 054 */     agg_bufIsNull_0 = false;
/* 055 */     agg_bufValue_0 = agg_value_3;
/* 056 */
/* 057 */   }
/* 058 */
/* 059 */   protected void processNext() throws java.io.IOException {
/* 060 */     while (!agg_initAgg_0) {
/* 061 */       agg_initAgg_0 = true;
/* 062 */       long agg_beforeAgg_0 = System.nanoTime();
/* 063 */       agg_doAggregateWithoutKey_0();
/* 064 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* aggTime */).add((System.nanoTime() - agg_beforeAgg_0) / 1000000);
/* 065 */
/* 066 */       // output the result
/* 067 */
/* 068 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 069 */       agg_mutableStateArray_0[0].reset();
/* 070 */
/* 071 */       agg_mutableStateArray_0[0].zeroOutNullBytes();
/* 072 */
/* 073 */       agg_mutableStateArray_0[0].write(0, agg_bufValue_0);
/* 074 */       append((agg_mutableStateArray_0[0].getRow()));
/* 075 */     }
/* 076 */   }
/* 077 */
/* 078 */ }

2022-01-12 15:09:58 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private boolean agg_bufIsNull_0;
/* 011 */   private long agg_bufValue_0;
/* 012 */   private scala.collection.Iterator inputadapter_input_0;
/* 013 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] agg_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 014 */
/* 015 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 016 */     this.references = references;
/* 017 */   }
/* 018 */
/* 019 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 020 */     partitionIndex = index;
/* 021 */     this.inputs = inputs;
/* 022 */
/* 023 */     inputadapter_input_0 = inputs[0];
/* 024 */     agg_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 025 */
/* 026 */   }
/* 027 */
/* 028 */   private void agg_doAggregateWithoutKey_0() throws java.io.IOException {
/* 029 */     // initialize aggregation buffer
/* 030 */     agg_bufIsNull_0 = false;
/* 031 */     agg_bufValue_0 = 0L;
/* 032 */
/* 033 */     while ( inputadapter_input_0.hasNext()) {
/* 034 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 035 */
/* 036 */       agg_doConsume_0(inputadapter_row_0);
/* 037 */       // shouldStop check is eliminated
/* 038 */     }
/* 039 */
/* 040 */   }
/* 041 */
/* 042 */   private void agg_doConsume_0(InternalRow inputadapter_row_0) throws java.io.IOException {
/* 043 */     // do aggregate
/* 044 */     // common sub-expressions
/* 045 */
/* 046 */     // evaluate aggregate functions and update aggregation buffers
/* 047 */
/* 048 */     long agg_value_1 = -1L;
/* 049 */
/* 050 */     agg_value_1 = agg_bufValue_0 + 1L;
/* 051 */
/* 052 */     agg_bufIsNull_0 = false;
/* 053 */     agg_bufValue_0 = agg_value_1;
/* 054 */
/* 055 */   }
/* 056 */
/* 057 */   protected void processNext() throws java.io.IOException {
/* 058 */     while (!agg_initAgg_0) {
/* 059 */       agg_initAgg_0 = true;
/* 060 */       long agg_beforeAgg_0 = System.nanoTime();
/* 061 */       agg_doAggregateWithoutKey_0();
/* 062 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* aggTime */).add((System.nanoTime() - agg_beforeAgg_0) / 1000000);
/* 063 */
/* 064 */       // output the result
/* 065 */
/* 066 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 067 */       agg_mutableStateArray_0[0].reset();
/* 068 */
/* 069 */       agg_mutableStateArray_0[0].zeroOutNullBytes();
/* 070 */
/* 071 */       agg_mutableStateArray_0[0].write(0, agg_bufValue_0);
/* 072 */       append((agg_mutableStateArray_0[0].getRow()));
/* 073 */     }
/* 074 */   }
/* 075 */
/* 076 */ }

2022-01-12 15:09:58 INFO  MemoryStore:57 - Block broadcast_25 stored as values in memory (estimated size 174.2 KiB, free 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManager:61 - Put block broadcast_25 locally took 4 ms
2022-01-12 15:09:58 DEBUG BlockManager:61 - Putting block broadcast_25 without replication took 5 ms
2022-01-12 15:09:58 INFO  MemoryStore:57 - Block broadcast_25_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_25_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:58 INFO  BlockManagerInfo:57 - Added broadcast_25_piece0 in memory on host.docker.internal:64148 (size: 27.6 KiB, free: 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_25_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Told master about block broadcast_25_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Put block broadcast_25_piece0 locally took 2 ms
2022-01-12 15:09:58 DEBUG BlockManager:61 - Putting block broadcast_25_piece0 without replication took 2 ms
2022-01-12 15:09:58 INFO  SparkContext:57 - Created broadcast 25 from count at LoadTesting.java:29
2022-01-12 15:09:58 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$collect$2
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$collect$2) is now cleaned +++
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$5
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
2022-01-12 15:09:58 INFO  SparkContext:57 - Starting job: count at LoadTesting.java:29
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - Merging stage rdd profiles: Set()
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - Merging stage rdd profiles: Set()
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Registering RDD 64 (count at LoadTesting.java:29) as input to shuffle 3
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Got job 11 (count at LoadTesting.java:29) with 1 output partitions
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Final stage: ResultStage 15 (count at LoadTesting.java:29)
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Parents of final stage: List(ShuffleMapStage 14)
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Missing parents: List(ShuffleMapStage 14)
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - submitStage(ResultStage 15 (name=count at LoadTesting.java:29;jobs=11))
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - missing: List(ShuffleMapStage 14)
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - submitStage(ShuffleMapStage 14 (name=count at LoadTesting.java:29;jobs=11))
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - missing: List()
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Submitting ShuffleMapStage 14 (MapPartitionsRDD[64] at count at LoadTesting.java:29), which has no missing parents
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - submitMissingTasks(ShuffleMapStage 14)
2022-01-12 15:09:58 INFO  MemoryStore:57 - Block broadcast_26 stored as values in memory (estimated size 15.5 KiB, free 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManager:61 - Put block broadcast_26 locally took 1 ms
2022-01-12 15:09:58 DEBUG BlockManager:61 - Putting block broadcast_26 without replication took 1 ms
2022-01-12 15:09:58 INFO  MemoryStore:57 - Block broadcast_26_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_26_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:58 INFO  BlockManagerInfo:57 - Added broadcast_26_piece0 in memory on host.docker.internal:64148 (size: 7.9 KiB, free: 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_26_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Told master about block broadcast_26_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Put block broadcast_26_piece0 locally took 1 ms
2022-01-12 15:09:58 DEBUG BlockManager:61 - Putting block broadcast_26_piece0 without replication took 1 ms
2022-01-12 15:09:58 INFO  SparkContext:57 - Created broadcast 26 from broadcast at DAGScheduler.scala:1388
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[64] at count at LoadTesting.java:29) (first 15 tasks are for partitions Vector(0))
2022-01-12 15:09:58 INFO  TaskSchedulerImpl:57 - Adding task set 14.0 with 1 tasks resource profile 0
2022-01-12 15:09:58 DEBUG TaskSetManager:61 - Epoch for TaskSet 14.0: 3
2022-01-12 15:09:58 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-01-12 15:09:58 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 14.0: NO_PREF, ANY
2022-01-12 15:09:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_14.0, runningTasks: 0
2022-01-12 15:09:58 INFO  TaskSetManager:57 - Starting task 0.0 in stage 14.0 (TID 14) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4963 bytes) taskResourceAssignments Map()
2022-01-12 15:09:58 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-01-12 15:09:58 INFO  Executor:57 - Running task 0.0 in stage 14.0 (TID 14)
2022-01-12 15:09:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (14, 0) -> 1
2022-01-12 15:09:58 DEBUG BlockManager:61 - Getting local block broadcast_26
2022-01-12 15:09:58 DEBUG BlockManager:61 - Level for block broadcast_26 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:58 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Rahul%20Kabothula/Intellij%20Maven%20Projects/retail_db/result/task2_result/part-00000-6104a880-9297-4b2e-b8ac-7beeef058e70-c000.csv, range: 0-595175, partition values: [empty row]
2022-01-12 15:09:58 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-01-12 15:09:58 DEBUG BlockManager:61 - Getting local block broadcast_25
2022-01-12 15:09:58 DEBUG BlockManager:61 - Level for block broadcast_25 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:58 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 14 with length 1
2022-01-12 15:09:58 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 14: [59]
2022-01-12 15:09:58 INFO  Executor:57 - Finished task 0.0 in stage 14.0 (TID 14). 1887 bytes result sent to driver
2022-01-12 15:09:58 DEBUG ExecutorMetricsPoller:61 - removing (14, 0) from stageTCMP
2022-01-12 15:09:58 INFO  TaskSetManager:57 - Finished task 0.0 in stage 14.0 (TID 14) in 53 ms on host.docker.internal (executor driver) (1/1)
2022-01-12 15:09:58 INFO  TaskSchedulerImpl:57 - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-12 15:09:58 INFO  DAGScheduler:57 - ShuffleMapStage 14 (count at LoadTesting.java:29) finished in 0.053 s
2022-01-12 15:09:58 INFO  DAGScheduler:57 - looking for newly runnable stages
2022-01-12 15:09:58 INFO  DAGScheduler:57 - running: Set()
2022-01-12 15:09:58 INFO  DAGScheduler:57 - waiting: Set(ResultStage 15)
2022-01-12 15:09:58 INFO  DAGScheduler:57 - failed: Set()
2022-01-12 15:09:58 DEBUG MapOutputTrackerMaster:61 - Increasing epoch to 4
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - submitStage(ResultStage 15 (name=count at LoadTesting.java:29;jobs=11))
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - missing: List()
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Submitting ResultStage 15 (MapPartitionsRDD[67] at count at LoadTesting.java:29), which has no missing parents
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 15)
2022-01-12 15:09:58 INFO  MemoryStore:57 - Block broadcast_27 stored as values in memory (estimated size 10.1 KiB, free 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManager:61 - Put block broadcast_27 locally took 2 ms
2022-01-12 15:09:58 DEBUG BlockManager:61 - Putting block broadcast_27 without replication took 2 ms
2022-01-12 15:09:58 INFO  MemoryStore:57 - Block broadcast_27_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_27_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:58 INFO  BlockManagerInfo:57 - Added broadcast_27_piece0 in memory on host.docker.internal:64148 (size: 5.0 KiB, free: 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_27_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Told master about block broadcast_27_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Put block broadcast_27_piece0 locally took 1 ms
2022-01-12 15:09:58 DEBUG BlockManager:61 - Putting block broadcast_27_piece0 without replication took 1 ms
2022-01-12 15:09:58 INFO  SparkContext:57 - Created broadcast 27 from broadcast at DAGScheduler.scala:1388
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[67] at count at LoadTesting.java:29) (first 15 tasks are for partitions Vector(0))
2022-01-12 15:09:58 INFO  TaskSchedulerImpl:57 - Adding task set 15.0 with 1 tasks resource profile 0
2022-01-12 15:09:58 DEBUG TaskSetManager:61 - Epoch for TaskSet 15.0: 4
2022-01-12 15:09:58 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-01-12 15:09:58 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 15.0: NODE_LOCAL, ANY
2022-01-12 15:09:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_15.0, runningTasks: 0
2022-01-12 15:09:58 INFO  TaskSetManager:57 - Starting task 0.0 in stage 15.0 (TID 15) (host.docker.internal, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-12 15:09:58 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
2022-01-12 15:09:58 INFO  Executor:57 - Running task 0.0 in stage 15.0 (TID 15)
2022-01-12 15:09:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (15, 0) -> 1
2022-01-12 15:09:58 DEBUG BlockManager:61 - Getting local block broadcast_27
2022-01-12 15:09:58 DEBUG BlockManager:61 - Level for block broadcast_27 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:58 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 3
2022-01-12 15:09:58 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 3, mappers 0-1, partitions 0-1
2022-01-12 15:09:58 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-12 15:09:58 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-12 15:09:58 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-12 15:09:58 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_3_14_0,0)
2022-01-12 15:09:58 DEBUG BlockManager:61 - Getting local shuffle block shuffle_3_14_0
2022-01-12 15:09:58 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-12 15:09:58 INFO  Executor:57 - Finished task 0.0 in stage 15.0 (TID 15). 2562 bytes result sent to driver
2022-01-12 15:09:58 DEBUG ExecutorMetricsPoller:61 - removing (15, 0) from stageTCMP
2022-01-12 15:09:58 INFO  TaskSetManager:57 - Finished task 0.0 in stage 15.0 (TID 15) in 0 ms on host.docker.internal (executor driver) (1/1)
2022-01-12 15:09:58 INFO  TaskSchedulerImpl:57 - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2022-01-12 15:09:58 INFO  DAGScheduler:57 - ResultStage 15 (count at LoadTesting.java:29) finished in 0.017 s
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - After removal of stage 14, remaining stages = 1
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - After removal of stage 15, remaining stages = 0
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
2022-01-12 15:09:58 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 15: Stage finished
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Job 11 finished: count at LoadTesting.java:29, took 0.090987 s
2022-01-12 15:09:58 WARN  SparkSession$Builder:69 - Using an existing SparkSession; some spark core configurations may not take effect.
2022-01-12 15:09:58 DEBUG DataSource:61 - Some paths were ignored:
  
2022-01-12 15:09:58 INFO  InMemoryFileIndex:57 - It took 2 ms to list leaf files for 1 paths.
2022-01-12 15:09:58 INFO  InMemoryFileIndex:57 - It took 2 ms to list leaf files for 1 paths.
2022-01-12 15:09:58 DEBUG Analyzer$ResolveReferences:61 - Resolving 'value to value#144
2022-01-12 15:09:58 DEBUG Analyzer$ResolveReferences:61 - Resolving 'value to value#150
2022-01-12 15:09:58 INFO  FileSourceStrategy:57 - Pushed Filters: 
2022-01-12 15:09:58 INFO  FileSourceStrategy:57 - Post-Scan Filters: (length(trim(value#144, None)) > 0)
2022-01-12 15:09:58 INFO  FileSourceStrategy:57 - Output Data Schema: struct<value: string>
2022-01-12 15:09:58 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator inputadapter_input_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     inputadapter_input_0 = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while ( inputadapter_input_0.hasNext()) {
/* 026 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 027 */
/* 028 */       do {
/* 029 */         boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 030 */         UTF8String inputadapter_value_0 = inputadapter_isNull_0 ?
/* 031 */         null : (inputadapter_row_0.getUTF8String(0));
/* 032 */
/* 033 */         boolean filter_isNull_0 = true;
/* 034 */         boolean filter_value_0 = false;
/* 035 */         boolean filter_isNull_2 = false;
/* 036 */         UTF8String filter_value_2 = null;
/* 037 */         if (inputadapter_isNull_0) {
/* 038 */           filter_isNull_2 = true;
/* 039 */         } else {
/* 040 */           filter_value_2 = inputadapter_value_0.trim();
/* 041 */         }
/* 042 */         boolean filter_isNull_1 = filter_isNull_2;
/* 043 */         int filter_value_1 = -1;
/* 044 */
/* 045 */         if (!filter_isNull_2) {
/* 046 */           filter_value_1 = (filter_value_2).numChars();
/* 047 */         }
/* 048 */         if (!filter_isNull_1) {
/* 049 */           filter_isNull_0 = false; // resultCode could change nullability.
/* 050 */           filter_value_0 = filter_value_1 > 0;
/* 051 */
/* 052 */         }
/* 053 */         if (filter_isNull_0 || !filter_value_0) continue;
/* 054 */
/* 055 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 056 */
/* 057 */         filter_mutableStateArray_0[0].reset();
/* 058 */
/* 059 */         filter_mutableStateArray_0[0].zeroOutNullBytes();
/* 060 */
/* 061 */         if (inputadapter_isNull_0) {
/* 062 */           filter_mutableStateArray_0[0].setNullAt(0);
/* 063 */         } else {
/* 064 */           filter_mutableStateArray_0[0].write(0, inputadapter_value_0);
/* 065 */         }
/* 066 */         append((filter_mutableStateArray_0[0].getRow()));
/* 067 */
/* 068 */       } while(false);
/* 069 */       if (shouldStop()) return;
/* 070 */     }
/* 071 */   }
/* 072 */
/* 073 */ }

2022-01-12 15:09:58 INFO  MemoryStore:57 - Block broadcast_28 stored as values in memory (estimated size 174.3 KiB, free 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManager:61 - Put block broadcast_28 locally took 2 ms
2022-01-12 15:09:58 DEBUG BlockManager:61 - Putting block broadcast_28 without replication took 2 ms
2022-01-12 15:09:58 INFO  MemoryStore:57 - Block broadcast_28_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_28_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:58 INFO  BlockManagerInfo:57 - Added broadcast_28_piece0 in memory on host.docker.internal:64148 (size: 27.6 KiB, free: 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_28_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Told master about block broadcast_28_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Put block broadcast_28_piece0 locally took 2 ms
2022-01-12 15:09:58 DEBUG BlockManager:61 - Putting block broadcast_28_piece0 without replication took 2 ms
2022-01-12 15:09:58 INFO  SparkContext:57 - Created broadcast 28 from load at Extract.java:13
2022-01-12 15:09:58 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$executeTake$2
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$executeTake$2) is now cleaned +++
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$5
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
2022-01-12 15:09:58 INFO  SparkContext:57 - Starting job: load at Extract.java:13
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - Merging stage rdd profiles: Set()
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Got job 12 (load at Extract.java:13) with 1 output partitions
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Final stage: ResultStage 16 (load at Extract.java:13)
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Parents of final stage: List()
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Missing parents: List()
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - submitStage(ResultStage 16 (name=load at Extract.java:13;jobs=12))
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - missing: List()
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Submitting ResultStage 16 (MapPartitionsRDD[71] at load at Extract.java:13), which has no missing parents
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 16)
2022-01-12 15:09:58 INFO  MemoryStore:57 - Block broadcast_29 stored as values in memory (estimated size 10.8 KiB, free 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManager:61 - Put block broadcast_29 locally took 0 ms
2022-01-12 15:09:58 DEBUG BlockManager:61 - Putting block broadcast_29 without replication took 0 ms
2022-01-12 15:09:58 INFO  MemoryStore:57 - Block broadcast_29_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_29_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:58 INFO  BlockManagerInfo:57 - Added broadcast_29_piece0 in memory on host.docker.internal:64148 (size: 5.4 KiB, free: 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_29_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Told master about block broadcast_29_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Put block broadcast_29_piece0 locally took 1 ms
2022-01-12 15:09:58 DEBUG BlockManager:61 - Putting block broadcast_29_piece0 without replication took 1 ms
2022-01-12 15:09:58 INFO  SparkContext:57 - Created broadcast 29 from broadcast at DAGScheduler.scala:1388
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[71] at load at Extract.java:13) (first 15 tasks are for partitions Vector(0))
2022-01-12 15:09:58 INFO  TaskSchedulerImpl:57 - Adding task set 16.0 with 1 tasks resource profile 0
2022-01-12 15:09:58 DEBUG TaskSetManager:61 - Epoch for TaskSet 16.0: 4
2022-01-12 15:09:58 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-01-12 15:09:58 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 16.0: NO_PREF, ANY
2022-01-12 15:09:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_16.0, runningTasks: 0
2022-01-12 15:09:58 INFO  TaskSetManager:57 - Starting task 0.0 in stage 16.0 (TID 16) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4974 bytes) taskResourceAssignments Map()
2022-01-12 15:09:58 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-01-12 15:09:58 INFO  Executor:57 - Running task 0.0 in stage 16.0 (TID 16)
2022-01-12 15:09:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (16, 0) -> 1
2022-01-12 15:09:58 DEBUG BlockManager:61 - Getting local block broadcast_29
2022-01-12 15:09:58 DEBUG BlockManager:61 - Level for block broadcast_29 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:58 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Rahul%20Kabothula/Intellij%20Maven%20Projects/retail_db/result/task3_result/part-00000-a95372e9-191a-4bcc-a688-8b5a5fea6e6c-c000.csv, range: 0-297837, partition values: [empty row]
2022-01-12 15:09:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-12 15:09:58 DEBUG BlockManager:61 - Getting local block broadcast_28
2022-01-12 15:09:58 DEBUG BlockManager:61 - Level for block broadcast_28 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:58 INFO  Executor:57 - Finished task 0.0 in stage 16.0 (TID 16). 1471 bytes result sent to driver
2022-01-12 15:09:58 DEBUG ExecutorMetricsPoller:61 - removing (16, 0) from stageTCMP
2022-01-12 15:09:58 INFO  TaskSetManager:57 - Finished task 0.0 in stage 16.0 (TID 16) in 16 ms on host.docker.internal (executor driver) (1/1)
2022-01-12 15:09:58 INFO  TaskSchedulerImpl:57 - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2022-01-12 15:09:58 INFO  DAGScheduler:57 - ResultStage 16 (load at Extract.java:13) finished in 0.032 s
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - After removal of stage 16, remaining stages = 0
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
2022-01-12 15:09:58 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 16: Stage finished
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Job 12 finished: load at Extract.java:13, took 0.025131 s
2022-01-12 15:09:58 DEBUG GenerateSafeProjection:61 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-01-12 15:09:58 INFO  FileSourceStrategy:57 - Pushed Filters: 
2022-01-12 15:09:58 INFO  FileSourceStrategy:57 - Post-Scan Filters: 
2022-01-12 15:09:58 INFO  FileSourceStrategy:57 - Output Data Schema: struct<value: string>
2022-01-12 15:09:58 INFO  MemoryStore:57 - Block broadcast_30 stored as values in memory (estimated size 174.3 KiB, free 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManager:61 - Put block broadcast_30 locally took 1 ms
2022-01-12 15:09:58 DEBUG BlockManager:61 - Putting block broadcast_30 without replication took 2 ms
2022-01-12 15:09:58 INFO  MemoryStore:57 - Block broadcast_30_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_30_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:58 INFO  BlockManagerInfo:57 - Added broadcast_30_piece0 in memory on host.docker.internal:64148 (size: 27.6 KiB, free: 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_30_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Told master about block broadcast_30_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Put block broadcast_30_piece0 locally took 3 ms
2022-01-12 15:09:58 DEBUG BlockManager:61 - Putting block broadcast_30_piece0 without replication took 4 ms
2022-01-12 15:09:58 INFO  SparkContext:57 - Created broadcast 30 from load at Extract.java:13
2022-01-12 15:09:58 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$rdd$1
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$rdd$1) is now cleaned +++
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$inferFromDataset$2
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$inferFromDataset$2) is now cleaned +++
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$infer$2
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$infer$2) is now cleaned +++
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$infer$3
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$infer$3) is now cleaned +++
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$6
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$6) is now cleaned +++
2022-01-12 15:09:58 INFO  SparkContext:57 - Starting job: load at Extract.java:13
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - Merging stage rdd profiles: Set()
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Got job 13 (load at Extract.java:13) with 1 output partitions
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Final stage: ResultStage 17 (load at Extract.java:13)
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Parents of final stage: List()
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Missing parents: List()
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - submitStage(ResultStage 17 (name=load at Extract.java:13;jobs=13))
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - missing: List()
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Submitting ResultStage 17 (MapPartitionsRDD[77] at load at Extract.java:13), which has no missing parents
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 17)
2022-01-12 15:09:58 INFO  MemoryStore:57 - Block broadcast_31 stored as values in memory (estimated size 15.4 KiB, free 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManager:61 - Put block broadcast_31 locally took 1 ms
2022-01-12 15:09:58 DEBUG BlockManager:61 - Putting block broadcast_31 without replication took 1 ms
2022-01-12 15:09:58 INFO  MemoryStore:57 - Block broadcast_31_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_31_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:58 INFO  BlockManagerInfo:57 - Added broadcast_31_piece0 in memory on host.docker.internal:64148 (size: 7.8 KiB, free: 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_31_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Told master about block broadcast_31_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Put block broadcast_31_piece0 locally took 1 ms
2022-01-12 15:09:58 DEBUG BlockManager:61 - Putting block broadcast_31_piece0 without replication took 1 ms
2022-01-12 15:09:58 INFO  SparkContext:57 - Created broadcast 31 from broadcast at DAGScheduler.scala:1388
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[77] at load at Extract.java:13) (first 15 tasks are for partitions Vector(0))
2022-01-12 15:09:58 INFO  TaskSchedulerImpl:57 - Adding task set 17.0 with 1 tasks resource profile 0
2022-01-12 15:09:58 DEBUG TaskSetManager:61 - Epoch for TaskSet 17.0: 4
2022-01-12 15:09:58 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-01-12 15:09:58 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 17.0: NO_PREF, ANY
2022-01-12 15:09:58 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_17.0, runningTasks: 0
2022-01-12 15:09:58 INFO  TaskSetManager:57 - Starting task 0.0 in stage 17.0 (TID 17) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4974 bytes) taskResourceAssignments Map()
2022-01-12 15:09:58 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-01-12 15:09:58 INFO  Executor:57 - Running task 0.0 in stage 17.0 (TID 17)
2022-01-12 15:09:58 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (17, 0) -> 1
2022-01-12 15:09:58 DEBUG BlockManager:61 - Getting local block broadcast_31
2022-01-12 15:09:58 DEBUG BlockManager:61 - Level for block broadcast_31 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:58 DEBUG GenerateSafeProjection:61 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-01-12 15:09:58 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Rahul%20Kabothula/Intellij%20Maven%20Projects/retail_db/result/task3_result/part-00000-a95372e9-191a-4bcc-a688-8b5a5fea6e6c-c000.csv, range: 0-297837, partition values: [empty row]
2022-01-12 15:09:58 DEBUG GenerateUnsafeProjection:61 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-01-12 15:09:58 DEBUG BlockManager:61 - Getting local block broadcast_30
2022-01-12 15:09:58 DEBUG BlockManager:61 - Level for block broadcast_30 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:58 INFO  Executor:57 - Finished task 0.0 in stage 17.0 (TID 17). 1573 bytes result sent to driver
2022-01-12 15:09:58 DEBUG ExecutorMetricsPoller:61 - removing (17, 0) from stageTCMP
2022-01-12 15:09:58 INFO  TaskSetManager:57 - Finished task 0.0 in stage 17.0 (TID 17) in 110 ms on host.docker.internal (executor driver) (1/1)
2022-01-12 15:09:58 INFO  TaskSchedulerImpl:57 - Removed TaskSet 17.0, whose tasks have all completed, from pool 
2022-01-12 15:09:58 INFO  DAGScheduler:57 - ResultStage 17 (load at Extract.java:13) finished in 0.126 s
2022-01-12 15:09:58 DEBUG DAGScheduler:61 - After removal of stage 17, remaining stages = 0
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
2022-01-12 15:09:58 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 17: Stage finished
2022-01-12 15:09:58 INFO  DAGScheduler:57 - Job 13 finished: load at Extract.java:13, took 0.126730 s
2022-01-12 15:09:58 INFO  FileSourceStrategy:57 - Pushed Filters: 
2022-01-12 15:09:58 INFO  FileSourceStrategy:57 - Post-Scan Filters: 
2022-01-12 15:09:58 INFO  FileSourceStrategy:57 - Output Data Schema: struct<>
2022-01-12 15:09:58 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage2(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=2
/* 006 */ final class GeneratedIteratorForCodegenStage2 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private boolean agg_bufIsNull_0;
/* 011 */   private long agg_bufValue_0;
/* 012 */   private scala.collection.Iterator inputadapter_input_0;
/* 013 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] agg_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 014 */
/* 015 */   public GeneratedIteratorForCodegenStage2(Object[] references) {
/* 016 */     this.references = references;
/* 017 */   }
/* 018 */
/* 019 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 020 */     partitionIndex = index;
/* 021 */     this.inputs = inputs;
/* 022 */
/* 023 */     inputadapter_input_0 = inputs[0];
/* 024 */     agg_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 025 */
/* 026 */   }
/* 027 */
/* 028 */   private void agg_doAggregateWithoutKey_0() throws java.io.IOException {
/* 029 */     // initialize aggregation buffer
/* 030 */     agg_bufIsNull_0 = false;
/* 031 */     agg_bufValue_0 = 0L;
/* 032 */
/* 033 */     while ( inputadapter_input_0.hasNext()) {
/* 034 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 035 */
/* 036 */       long inputadapter_value_0 = inputadapter_row_0.getLong(0);
/* 037 */
/* 038 */       agg_doConsume_0(inputadapter_row_0, inputadapter_value_0);
/* 039 */       // shouldStop check is eliminated
/* 040 */     }
/* 041 */
/* 042 */   }
/* 043 */
/* 044 */   private void agg_doConsume_0(InternalRow inputadapter_row_0, long agg_expr_0_0) throws java.io.IOException {
/* 045 */     // do aggregate
/* 046 */     // common sub-expressions
/* 047 */
/* 048 */     // evaluate aggregate functions and update aggregation buffers
/* 049 */
/* 050 */     long agg_value_3 = -1L;
/* 051 */
/* 052 */     agg_value_3 = agg_bufValue_0 + agg_expr_0_0;
/* 053 */
/* 054 */     agg_bufIsNull_0 = false;
/* 055 */     agg_bufValue_0 = agg_value_3;
/* 056 */
/* 057 */   }
/* 058 */
/* 059 */   protected void processNext() throws java.io.IOException {
/* 060 */     while (!agg_initAgg_0) {
/* 061 */       agg_initAgg_0 = true;
/* 062 */       long agg_beforeAgg_0 = System.nanoTime();
/* 063 */       agg_doAggregateWithoutKey_0();
/* 064 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* aggTime */).add((System.nanoTime() - agg_beforeAgg_0) / 1000000);
/* 065 */
/* 066 */       // output the result
/* 067 */
/* 068 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 069 */       agg_mutableStateArray_0[0].reset();
/* 070 */
/* 071 */       agg_mutableStateArray_0[0].zeroOutNullBytes();
/* 072 */
/* 073 */       agg_mutableStateArray_0[0].write(0, agg_bufValue_0);
/* 074 */       append((agg_mutableStateArray_0[0].getRow()));
/* 075 */     }
/* 076 */   }
/* 077 */
/* 078 */ }

2022-01-12 15:09:58 DEBUG WholeStageCodegenExec:61 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private boolean agg_bufIsNull_0;
/* 011 */   private long agg_bufValue_0;
/* 012 */   private scala.collection.Iterator inputadapter_input_0;
/* 013 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] agg_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 014 */
/* 015 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 016 */     this.references = references;
/* 017 */   }
/* 018 */
/* 019 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 020 */     partitionIndex = index;
/* 021 */     this.inputs = inputs;
/* 022 */
/* 023 */     inputadapter_input_0 = inputs[0];
/* 024 */     agg_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 025 */
/* 026 */   }
/* 027 */
/* 028 */   private void agg_doAggregateWithoutKey_0() throws java.io.IOException {
/* 029 */     // initialize aggregation buffer
/* 030 */     agg_bufIsNull_0 = false;
/* 031 */     agg_bufValue_0 = 0L;
/* 032 */
/* 033 */     while ( inputadapter_input_0.hasNext()) {
/* 034 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 035 */
/* 036 */       agg_doConsume_0(inputadapter_row_0);
/* 037 */       // shouldStop check is eliminated
/* 038 */     }
/* 039 */
/* 040 */   }
/* 041 */
/* 042 */   private void agg_doConsume_0(InternalRow inputadapter_row_0) throws java.io.IOException {
/* 043 */     // do aggregate
/* 044 */     // common sub-expressions
/* 045 */
/* 046 */     // evaluate aggregate functions and update aggregation buffers
/* 047 */
/* 048 */     long agg_value_1 = -1L;
/* 049 */
/* 050 */     agg_value_1 = agg_bufValue_0 + 1L;
/* 051 */
/* 052 */     agg_bufIsNull_0 = false;
/* 053 */     agg_bufValue_0 = agg_value_1;
/* 054 */
/* 055 */   }
/* 056 */
/* 057 */   protected void processNext() throws java.io.IOException {
/* 058 */     while (!agg_initAgg_0) {
/* 059 */       agg_initAgg_0 = true;
/* 060 */       long agg_beforeAgg_0 = System.nanoTime();
/* 061 */       agg_doAggregateWithoutKey_0();
/* 062 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* aggTime */).add((System.nanoTime() - agg_beforeAgg_0) / 1000000);
/* 063 */
/* 064 */       // output the result
/* 065 */
/* 066 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 067 */       agg_mutableStateArray_0[0].reset();
/* 068 */
/* 069 */       agg_mutableStateArray_0[0].zeroOutNullBytes();
/* 070 */
/* 071 */       agg_mutableStateArray_0[0].write(0, agg_bufValue_0);
/* 072 */       append((agg_mutableStateArray_0[0].getRow()));
/* 073 */     }
/* 074 */   }
/* 075 */
/* 076 */ }

2022-01-12 15:09:58 INFO  MemoryStore:57 - Block broadcast_32 stored as values in memory (estimated size 174.2 KiB, free 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManager:61 - Put block broadcast_32 locally took 1 ms
2022-01-12 15:09:58 DEBUG BlockManager:61 - Putting block broadcast_32 without replication took 2 ms
2022-01-12 15:09:58 INFO  MemoryStore:57 - Block broadcast_32_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_32_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:58 INFO  BlockManagerInfo:57 - Added broadcast_32_piece0 in memory on host.docker.internal:64148 (size: 27.6 KiB, free: 2.2 GiB)
2022-01-12 15:09:58 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_32_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Told master about block broadcast_32_piece0
2022-01-12 15:09:58 DEBUG BlockManager:61 - Put block broadcast_32_piece0 locally took 1 ms
2022-01-12 15:09:58 DEBUG BlockManager:61 - Putting block broadcast_32_piece0 without replication took 1 ms
2022-01-12 15:09:58 INFO  SparkContext:57 - Created broadcast 32 from count at LoadTesting.java:37
2022-01-12 15:09:58 INFO  FileSourceScanExec:57 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$collect$2
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$collect$2) is now cleaned +++
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 - Cleaning indylambda closure: $anonfun$runJob$5
2022-01-12 15:09:58 DEBUG ClosureCleaner:61 -  +++ indylambda closure ($anonfun$runJob$5) is now cleaned +++
2022-01-12 15:09:59 INFO  SparkContext:57 - Starting job: count at LoadTesting.java:37
2022-01-12 15:09:59 DEBUG DAGScheduler:61 - Merging stage rdd profiles: Set()
2022-01-12 15:09:59 DEBUG DAGScheduler:61 - Merging stage rdd profiles: Set()
2022-01-12 15:09:59 INFO  DAGScheduler:57 - Registering RDD 81 (count at LoadTesting.java:37) as input to shuffle 4
2022-01-12 15:09:59 INFO  DAGScheduler:57 - Got job 14 (count at LoadTesting.java:37) with 1 output partitions
2022-01-12 15:09:59 INFO  DAGScheduler:57 - Final stage: ResultStage 19 (count at LoadTesting.java:37)
2022-01-12 15:09:59 INFO  DAGScheduler:57 - Parents of final stage: List(ShuffleMapStage 18)
2022-01-12 15:09:59 INFO  DAGScheduler:57 - Missing parents: List(ShuffleMapStage 18)
2022-01-12 15:09:59 DEBUG DAGScheduler:61 - submitStage(ResultStage 19 (name=count at LoadTesting.java:37;jobs=14))
2022-01-12 15:09:59 DEBUG DAGScheduler:61 - missing: List(ShuffleMapStage 18)
2022-01-12 15:09:59 DEBUG DAGScheduler:61 - submitStage(ShuffleMapStage 18 (name=count at LoadTesting.java:37;jobs=14))
2022-01-12 15:09:59 DEBUG DAGScheduler:61 - missing: List()
2022-01-12 15:09:59 INFO  DAGScheduler:57 - Submitting ShuffleMapStage 18 (MapPartitionsRDD[81] at count at LoadTesting.java:37), which has no missing parents
2022-01-12 15:09:59 DEBUG DAGScheduler:61 - submitMissingTasks(ShuffleMapStage 18)
2022-01-12 15:09:59 INFO  MemoryStore:57 - Block broadcast_33 stored as values in memory (estimated size 15.4 KiB, free 2.2 GiB)
2022-01-12 15:09:59 DEBUG BlockManager:61 - Put block broadcast_33 locally took 0 ms
2022-01-12 15:09:59 DEBUG BlockManager:61 - Putting block broadcast_33 without replication took 1 ms
2022-01-12 15:09:59 INFO  MemoryStore:57 - Block broadcast_33_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 2.2 GiB)
2022-01-12 15:09:59 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_33_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:59 INFO  BlockManagerInfo:57 - Added broadcast_33_piece0 in memory on host.docker.internal:64148 (size: 7.9 KiB, free: 2.2 GiB)
2022-01-12 15:09:59 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_33_piece0
2022-01-12 15:09:59 DEBUG BlockManager:61 - Told master about block broadcast_33_piece0
2022-01-12 15:09:59 DEBUG BlockManager:61 - Put block broadcast_33_piece0 locally took 1 ms
2022-01-12 15:09:59 DEBUG BlockManager:61 - Putting block broadcast_33_piece0 without replication took 1 ms
2022-01-12 15:09:59 INFO  SparkContext:57 - Created broadcast 33 from broadcast at DAGScheduler.scala:1388
2022-01-12 15:09:59 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[81] at count at LoadTesting.java:37) (first 15 tasks are for partitions Vector(0))
2022-01-12 15:09:59 INFO  TaskSchedulerImpl:57 - Adding task set 18.0 with 1 tasks resource profile 0
2022-01-12 15:09:59 DEBUG TaskSetManager:61 - Epoch for TaskSet 18.0: 4
2022-01-12 15:09:59 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-01-12 15:09:59 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 18.0: NO_PREF, ANY
2022-01-12 15:09:59 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_18.0, runningTasks: 0
2022-01-12 15:09:59 INFO  TaskSetManager:57 - Starting task 0.0 in stage 18.0 (TID 18) (host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 4963 bytes) taskResourceAssignments Map()
2022-01-12 15:09:59 DEBUG TaskSetManager:61 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-01-12 15:09:59 INFO  Executor:57 - Running task 0.0 in stage 18.0 (TID 18)
2022-01-12 15:09:59 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (18, 0) -> 1
2022-01-12 15:09:59 DEBUG BlockManager:61 - Getting local block broadcast_33
2022-01-12 15:09:59 DEBUG BlockManager:61 - Level for block broadcast_33 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:59 INFO  FileScanRDD:57 - Reading File path: file:///C:/Users/Rahul%20Kabothula/Intellij%20Maven%20Projects/retail_db/result/task3_result/part-00000-a95372e9-191a-4bcc-a688-8b5a5fea6e6c-c000.csv, range: 0-297837, partition values: [empty row]
2022-01-12 15:09:59 DEBUG GenerateUnsafeProjection:61 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-01-12 15:09:59 DEBUG BlockManager:61 - Getting local block broadcast_32
2022-01-12 15:09:59 DEBUG BlockManager:61 - Level for block broadcast_32 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:59 DEBUG LocalDiskShuffleMapOutputWriter:116 - Writing shuffle index file for mapId 18 with length 1
2022-01-12 15:09:59 DEBUG IndexShuffleBlockResolver:61 - Shuffle index for mapId 18: [59]
2022-01-12 15:09:59 INFO  Executor:57 - Finished task 0.0 in stage 18.0 (TID 18). 1930 bytes result sent to driver
2022-01-12 15:09:59 DEBUG ExecutorMetricsPoller:61 - removing (18, 0) from stageTCMP
2022-01-12 15:09:59 INFO  TaskSetManager:57 - Finished task 0.0 in stage 18.0 (TID 18) in 63 ms on host.docker.internal (executor driver) (1/1)
2022-01-12 15:09:59 INFO  TaskSchedulerImpl:57 - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2022-01-12 15:09:59 DEBUG DAGScheduler:61 - ShuffleMapTask finished on driver
2022-01-12 15:09:59 INFO  DAGScheduler:57 - ShuffleMapStage 18 (count at LoadTesting.java:37) finished in 0.063 s
2022-01-12 15:09:59 INFO  DAGScheduler:57 - looking for newly runnable stages
2022-01-12 15:09:59 INFO  DAGScheduler:57 - running: Set()
2022-01-12 15:09:59 INFO  DAGScheduler:57 - waiting: Set(ResultStage 19)
2022-01-12 15:09:59 INFO  DAGScheduler:57 - failed: Set()
2022-01-12 15:09:59 DEBUG MapOutputTrackerMaster:61 - Increasing epoch to 5
2022-01-12 15:09:59 DEBUG DAGScheduler:61 - submitStage(ResultStage 19 (name=count at LoadTesting.java:37;jobs=14))
2022-01-12 15:09:59 DEBUG DAGScheduler:61 - missing: List()
2022-01-12 15:09:59 INFO  DAGScheduler:57 - Submitting ResultStage 19 (MapPartitionsRDD[84] at count at LoadTesting.java:37), which has no missing parents
2022-01-12 15:09:59 DEBUG DAGScheduler:61 - submitMissingTasks(ResultStage 19)
2022-01-12 15:09:59 INFO  MemoryStore:57 - Block broadcast_34 stored as values in memory (estimated size 10.1 KiB, free 2.2 GiB)
2022-01-12 15:09:59 DEBUG BlockManager:61 - Put block broadcast_34 locally took 0 ms
2022-01-12 15:09:59 DEBUG BlockManager:61 - Putting block broadcast_34 without replication took 1 ms
2022-01-12 15:09:59 INFO  MemoryStore:57 - Block broadcast_34_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 2.2 GiB)
2022-01-12 15:09:59 DEBUG BlockManagerMasterEndpoint:61 - Updating block info on master broadcast_34_piece0 for BlockManagerId(driver, host.docker.internal, 64148, None)
2022-01-12 15:09:59 INFO  BlockManagerInfo:57 - Added broadcast_34_piece0 in memory on host.docker.internal:64148 (size: 5.0 KiB, free: 2.2 GiB)
2022-01-12 15:09:59 DEBUG BlockManagerMaster:61 - Updated info of block broadcast_34_piece0
2022-01-12 15:09:59 DEBUG BlockManager:61 - Told master about block broadcast_34_piece0
2022-01-12 15:09:59 DEBUG BlockManager:61 - Put block broadcast_34_piece0 locally took 1 ms
2022-01-12 15:09:59 DEBUG BlockManager:61 - Putting block broadcast_34_piece0 without replication took 1 ms
2022-01-12 15:09:59 INFO  SparkContext:57 - Created broadcast 34 from broadcast at DAGScheduler.scala:1388
2022-01-12 15:09:59 INFO  DAGScheduler:57 - Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[84] at count at LoadTesting.java:37) (first 15 tasks are for partitions Vector(0))
2022-01-12 15:09:59 INFO  TaskSchedulerImpl:57 - Adding task set 19.0 with 1 tasks resource profile 0
2022-01-12 15:09:59 DEBUG TaskSetManager:61 - Epoch for TaskSet 19.0: 5
2022-01-12 15:09:59 DEBUG TaskSetManager:61 - Adding pending tasks took 0 ms
2022-01-12 15:09:59 DEBUG TaskSetManager:61 - Valid locality levels for TaskSet 19.0: NODE_LOCAL, ANY
2022-01-12 15:09:59 DEBUG TaskSchedulerImpl:61 - parentName: , name: TaskSet_19.0, runningTasks: 0
2022-01-12 15:09:59 INFO  TaskSetManager:57 - Starting task 0.0 in stage 19.0 (TID 19) (host.docker.internal, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
2022-01-12 15:09:59 DEBUG TaskSetManager:61 - No tasks for locality level NODE_LOCAL, so moving to locality level ANY
2022-01-12 15:09:59 INFO  Executor:57 - Running task 0.0 in stage 19.0 (TID 19)
2022-01-12 15:09:59 DEBUG ExecutorMetricsPoller:61 - stageTCMP: (19, 0) -> 1
2022-01-12 15:09:59 DEBUG BlockManager:61 - Getting local block broadcast_34
2022-01-12 15:09:59 DEBUG BlockManager:61 - Level for block broadcast_34 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-01-12 15:09:59 DEBUG MapOutputTrackerMaster:61 - Fetching outputs for shuffle 4
2022-01-12 15:09:59 DEBUG MapOutputTrackerMaster:61 - Convert map statuses for shuffle 4, mappers 0-1, partitions 0-1
2022-01-12 15:09:59 DEBUG ShuffleBlockFetcherIterator:61 - maxBytesInFlight: 50331648, targetRemoteRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-01-12 15:09:59 INFO  ShuffleBlockFetcherIterator:57 - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022-01-12 15:09:59 INFO  ShuffleBlockFetcherIterator:57 - Started 0 remote fetches in 0 ms
2022-01-12 15:09:59 DEBUG ShuffleBlockFetcherIterator:61 - Start fetching local blocks: (shuffle_4_18_0,0)
2022-01-12 15:09:59 DEBUG BlockManager:61 - Getting local shuffle block shuffle_4_18_0
2022-01-12 15:09:59 DEBUG ShuffleBlockFetcherIterator:61 - Got local blocks in 1 ms
2022-01-12 15:09:59 INFO  Executor:57 - Finished task 0.0 in stage 19.0 (TID 19). 2605 bytes result sent to driver
2022-01-12 15:09:59 DEBUG ExecutorMetricsPoller:61 - removing (19, 0) from stageTCMP
2022-01-12 15:09:59 INFO  TaskSetManager:57 - Finished task 0.0 in stage 19.0 (TID 19) in 16 ms on host.docker.internal (executor driver) (1/1)
2022-01-12 15:09:59 INFO  TaskSchedulerImpl:57 - Removed TaskSet 19.0, whose tasks have all completed, from pool 
2022-01-12 15:09:59 INFO  DAGScheduler:57 - ResultStage 19 (count at LoadTesting.java:37) finished in 0.016 s
2022-01-12 15:09:59 DEBUG DAGScheduler:61 - After removal of stage 19, remaining stages = 1
2022-01-12 15:09:59 DEBUG DAGScheduler:61 - After removal of stage 18, remaining stages = 0
2022-01-12 15:09:59 INFO  DAGScheduler:57 - Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
2022-01-12 15:09:59 INFO  TaskSchedulerImpl:57 - Killing all running tasks in stage 19: Stage finished
2022-01-12 15:09:59 INFO  DAGScheduler:57 - Job 14 finished: count at LoadTesting.java:37, took 0.089599 s
2022-01-12 15:09:59 INFO  SparkContext:57 - Invoking stop() from shutdown hook
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:212 - stopping Server@4c59e45e{STARTED}[9.4.40.v20210413]
2022-01-12 15:09:59 DEBUG Server:433 - doStop Server@4c59e45e{STOPPING}[9.4.40.v20210413]
2022-01-12 15:09:59 DEBUG QueuedThreadPool:1038 - ran SparkUI-41-acceptor-0@51b35e4e-ServerConnector@1e530163{HTTP/1.1, (http/1.1)}{0.0.0.0:4040} in QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=3,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}]
2022-01-12 15:09:59 DEBUG AbstractHandlerContainer:167 - Graceful shutdown Server@4c59e45e{STOPPING}[9.4.40.v20210413] by 
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:212 - stopping Spark@1e530163{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:212 - stopping SelectorManager@Spark@1e530163{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:212 - stopping ManagedSelector@27a2a089{STARTED} id=3 keys=0 selected=0 updates=0
2022-01-12 15:09:59 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$CloseConnections@3574e4a8 on ManagedSelector@27a2a089{STOPPING} id=3 keys=0 selected=0 updates=0
2022-01-12 15:09:59 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@27a2a089{STOPPING} id=3 keys=0 selected=0 updates=1
2022-01-12 15:09:59 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@6f20a6b6 woken with none selected
2022-01-12 15:09:59 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@6f20a6b6 woken up from select, 0/0/0 selected
2022-01-12 15:09:59 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@6f20a6b6 processing 0 keys, 1 updates
2022-01-12 15:09:59 DEBUG ManagedSelector:558 - updateable 1
2022-01-12 15:09:59 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$CloseConnections@3574e4a8
2022-01-12 15:09:59 DEBUG ManagedSelector:996 - Closing 0 connections on ManagedSelector@27a2a089{STOPPING} id=3 keys=0 selected=0 updates=0
2022-01-12 15:09:59 DEBUG ManagedSelector:587 - updates 0
2022-01-12 15:09:59 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@6f20a6b6 waiting with 0 keys
2022-01-12 15:09:59 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$StopSelector@4a7adcdf on ManagedSelector@27a2a089{STOPPING} id=3 keys=0 selected=0 updates=0
2022-01-12 15:09:59 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@27a2a089{STOPPING} id=3 keys=0 selected=0 updates=1
2022-01-12 15:09:59 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@6f20a6b6 woken with none selected
2022-01-12 15:09:59 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@6f20a6b6 woken up from select, 0/0/0 selected
2022-01-12 15:09:59 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@6f20a6b6 processing 0 keys, 1 updates
2022-01-12 15:09:59 DEBUG ManagedSelector:558 - updateable 1
2022-01-12 15:09:59 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$StopSelector@4a7adcdf
2022-01-12 15:09:59 DEBUG ManagedSelector:587 - updates 0
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:212 - stopping EatWhatYouKill@2330e3e0/SelectorProducer@24b4d544/PRODUCING/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=4,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:59.0980981+05:30
2022-01-12 15:09:59 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.io.ManagedSelector$$Lambda$472/0x0000000800546c40@2c0b4c83 in QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=4,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}]
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:224 - STOPPED EatWhatYouKill@2330e3e0/SelectorProducer@24b4d544/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=4,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:59.0980981+05:30
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:224 - STOPPED ManagedSelector@27a2a089{STOPPED} id=3 keys=-1 selected=-1 updates=0
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:212 - stopping ManagedSelector@4defd42{STARTED} id=2 keys=0 selected=0 updates=0
2022-01-12 15:09:59 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$CloseConnections@ddce84e on ManagedSelector@4defd42{STOPPING} id=2 keys=0 selected=0 updates=0
2022-01-12 15:09:59 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@4defd42{STOPPING} id=2 keys=0 selected=0 updates=1
2022-01-12 15:09:59 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@92b4a1c woken with none selected
2022-01-12 15:09:59 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@92b4a1c woken up from select, 0/0/0 selected
2022-01-12 15:09:59 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@92b4a1c processing 0 keys, 1 updates
2022-01-12 15:09:59 DEBUG ManagedSelector:558 - updateable 1
2022-01-12 15:09:59 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$CloseConnections@ddce84e
2022-01-12 15:09:59 DEBUG ManagedSelector:996 - Closing 0 connections on ManagedSelector@4defd42{STOPPING} id=2 keys=0 selected=0 updates=0
2022-01-12 15:09:59 DEBUG ManagedSelector:587 - updates 0
2022-01-12 15:09:59 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@92b4a1c waiting with 0 keys
2022-01-12 15:09:59 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$StopSelector@1f1f1cf9 on ManagedSelector@4defd42{STOPPING} id=2 keys=0 selected=0 updates=0
2022-01-12 15:09:59 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@4defd42{STOPPING} id=2 keys=0 selected=0 updates=1
2022-01-12 15:09:59 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@92b4a1c woken with none selected
2022-01-12 15:09:59 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@92b4a1c woken up from select, 0/0/0 selected
2022-01-12 15:09:59 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@92b4a1c processing 0 keys, 1 updates
2022-01-12 15:09:59 DEBUG ManagedSelector:558 - updateable 1
2022-01-12 15:09:59 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$StopSelector@1f1f1cf9
2022-01-12 15:09:59 DEBUG ManagedSelector:587 - updates 0
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:212 - stopping EatWhatYouKill@4248b963/SelectorProducer@7f08caf/PRODUCING/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:59.0980981+05:30
2022-01-12 15:09:59 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.io.ManagedSelector$$Lambda$472/0x0000000800546c40@61f39bb in QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}]
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:224 - STOPPED EatWhatYouKill@4248b963/SelectorProducer@7f08caf/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:59.0980981+05:30
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:224 - STOPPED ManagedSelector@4defd42{STOPPED} id=2 keys=-1 selected=-1 updates=0
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:212 - stopping ManagedSelector@3672276e{STARTED} id=1 keys=0 selected=0 updates=0
2022-01-12 15:09:59 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$CloseConnections@614237e8 on ManagedSelector@3672276e{STOPPING} id=1 keys=0 selected=0 updates=0
2022-01-12 15:09:59 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@3672276e{STOPPING} id=1 keys=0 selected=0 updates=1
2022-01-12 15:09:59 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@6f312f71 woken with none selected
2022-01-12 15:09:59 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@6f312f71 woken up from select, 0/0/0 selected
2022-01-12 15:09:59 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@6f312f71 processing 0 keys, 1 updates
2022-01-12 15:09:59 DEBUG ManagedSelector:558 - updateable 1
2022-01-12 15:09:59 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$CloseConnections@614237e8
2022-01-12 15:09:59 DEBUG ManagedSelector:996 - Closing 0 connections on ManagedSelector@3672276e{STOPPING} id=1 keys=0 selected=0 updates=0
2022-01-12 15:09:59 DEBUG ManagedSelector:587 - updates 0
2022-01-12 15:09:59 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@6f312f71 waiting with 0 keys
2022-01-12 15:09:59 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$StopSelector@7dc2833b on ManagedSelector@3672276e{STOPPING} id=1 keys=0 selected=0 updates=0
2022-01-12 15:09:59 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@3672276e{STOPPING} id=1 keys=0 selected=0 updates=1
2022-01-12 15:09:59 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@6f312f71 woken with none selected
2022-01-12 15:09:59 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@6f312f71 woken up from select, 0/0/0 selected
2022-01-12 15:09:59 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@6f312f71 processing 0 keys, 1 updates
2022-01-12 15:09:59 DEBUG ManagedSelector:558 - updateable 1
2022-01-12 15:09:59 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$StopSelector@7dc2833b
2022-01-12 15:09:59 DEBUG ManagedSelector:587 - updates 0
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:212 - stopping EatWhatYouKill@3abfe845/SelectorProducer@7a0f244f/PRODUCING/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:59.1138021+05:30
2022-01-12 15:09:59 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.io.ManagedSelector$$Lambda$472/0x0000000800546c40@5ac6c4f2 in QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}]
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:224 - STOPPED EatWhatYouKill@3abfe845/SelectorProducer@7a0f244f/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:59.1138021+05:30
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:224 - STOPPED ManagedSelector@3672276e{STOPPED} id=1 keys=-1 selected=-1 updates=0
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:212 - stopping ManagedSelector@7be7e15{STARTED} id=0 keys=0 selected=0 updates=0
2022-01-12 15:09:59 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$CloseConnections@17b68a55 on ManagedSelector@7be7e15{STOPPING} id=0 keys=0 selected=0 updates=0
2022-01-12 15:09:59 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@7be7e15{STOPPING} id=0 keys=0 selected=0 updates=1
2022-01-12 15:09:59 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@2b19042e woken with none selected
2022-01-12 15:09:59 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@2b19042e woken up from select, 0/0/0 selected
2022-01-12 15:09:59 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@2b19042e processing 0 keys, 1 updates
2022-01-12 15:09:59 DEBUG ManagedSelector:558 - updateable 1
2022-01-12 15:09:59 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$CloseConnections@17b68a55
2022-01-12 15:09:59 DEBUG ManagedSelector:996 - Closing 0 connections on ManagedSelector@7be7e15{STOPPING} id=0 keys=0 selected=0 updates=0
2022-01-12 15:09:59 DEBUG ManagedSelector:587 - updates 0
2022-01-12 15:09:59 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@2b19042e waiting with 0 keys
2022-01-12 15:09:59 DEBUG ManagedSelector:286 - Queued change lazy=false org.sparkproject.jetty.io.ManagedSelector$StopSelector@7029b48e on ManagedSelector@7be7e15{STOPPING} id=0 keys=0 selected=0 updates=0
2022-01-12 15:09:59 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@7be7e15{STOPPING} id=0 keys=0 selected=0 updates=1
2022-01-12 15:09:59 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@2b19042e woken with none selected
2022-01-12 15:09:59 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@2b19042e woken up from select, 0/0/0 selected
2022-01-12 15:09:59 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@2b19042e processing 0 keys, 1 updates
2022-01-12 15:09:59 DEBUG ManagedSelector:558 - updateable 1
2022-01-12 15:09:59 DEBUG ManagedSelector:567 - update org.sparkproject.jetty.io.ManagedSelector$StopSelector@7029b48e
2022-01-12 15:09:59 DEBUG ManagedSelector:587 - updates 0
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:212 - stopping EatWhatYouKill@3c35c345/SelectorProducer@ad9e63e/PRODUCING/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:59.1138021+05:30
2022-01-12 15:09:59 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.io.ManagedSelector$$Lambda$472/0x0000000800546c40@72725ee1 in QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}]
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:224 - STOPPED EatWhatYouKill@3c35c345/SelectorProducer@ad9e63e/IDLE/p=false/QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-01-12T15:09:59.1138021+05:30
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:224 - STOPPED ManagedSelector@7be7e15{STOPPED} id=0 keys=-1 selected=-1 updates=0
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:224 - STOPPED SelectorManager@Spark@1e530163{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:212 - stopping HttpConnectionFactory@4eb45fec[HTTP/1.1]
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:224 - STOPPED HttpConnectionFactory@4eb45fec[HTTP/1.1]
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:212 - stopping ScheduledExecutorScheduler@14d8444b{STARTED}
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:224 - STOPPED ScheduledExecutorScheduler@14d8444b{STOPPED}
2022-01-12 15:09:59 INFO  AbstractConnector:381 - Stopped Spark@1e530163{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:224 - STOPPED Spark@1e530163{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-01-12 15:09:59 DEBUG AbstractHandler:107 - stopping Server@4c59e45e{STOPPING}[9.4.40.v20210413]
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:212 - stopping ContextHandlerCollection@39c1fe0b{STARTED}
2022-01-12 15:09:59 DEBUG AbstractHandler:107 - stopping ContextHandlerCollection@39c1fe0b{STOPPING}
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:224 - STOPPED ContextHandlerCollection@39c1fe0b{STOPPED}
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:212 - stopping ErrorHandler@5a00eb1e{STARTED}
2022-01-12 15:09:59 DEBUG AbstractHandler:107 - stopping ErrorHandler@5a00eb1e{STOPPING}
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:224 - STOPPED ErrorHandler@5a00eb1e{STOPPED}
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:212 - stopping QueuedThreadPool[SparkUI]@e48bf9a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}]
2022-01-12 15:09:59 DEBUG QueuedThreadPool:224 - Stopping QueuedThreadPool[SparkUI]@e48bf9a{STOPPING,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6fca5907{s=0/8,p=0}]
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:212 - stopping ReservedThreadExecutor@6fca5907{s=0/8,p=0}
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:224 - STOPPED ReservedThreadExecutor@6fca5907{s=-1/8,p=0}
2022-01-12 15:09:59 DEBUG QueuedThreadPool:317 - Waiting for Thread[SparkUI-38,5,main] for 14999
2022-01-12 15:09:59 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$462/0x000000080052b040@5b4c6e6d in QueuedThreadPool[SparkUI]@e48bf9a{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-12 15:09:59 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$462/0x000000080052b040@5b4c6e6d in QueuedThreadPool[SparkUI]@e48bf9a{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-12 15:09:59 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$462/0x000000080052b040@5b4c6e6d in QueuedThreadPool[SparkUI]@e48bf9a{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-12 15:09:59 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$462/0x000000080052b040@5b4c6e6d in QueuedThreadPool[SparkUI]@e48bf9a{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-12 15:09:59 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$462/0x000000080052b040@5b4c6e6d in QueuedThreadPool[SparkUI]@e48bf9a{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-12 15:09:59 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$462/0x000000080052b040@5b4c6e6d in QueuedThreadPool[SparkUI]@e48bf9a{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-12 15:09:59 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$462/0x000000080052b040@5b4c6e6d in QueuedThreadPool[SparkUI]@e48bf9a{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-12 15:09:59 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$462/0x000000080052b040@5b4c6e6d in QueuedThreadPool[SparkUI]@e48bf9a{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-12 15:09:59 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$462/0x000000080052b040@5b4c6e6d in QueuedThreadPool[SparkUI]@e48bf9a{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-12 15:09:59 DEBUG QueuedThreadPool:1035 - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$462/0x000000080052b040@5b4c6e6d in QueuedThreadPool[SparkUI]@e48bf9a{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-12 15:09:59 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$462/0x000000080052b040@5b4c6e6d in QueuedThreadPool[SparkUI]@e48bf9a{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-12 15:09:59 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$462/0x000000080052b040@5b4c6e6d in QueuedThreadPool[SparkUI]@e48bf9a{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-12 15:09:59 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$462/0x000000080052b040@5b4c6e6d in QueuedThreadPool[SparkUI]@e48bf9a{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-12 15:09:59 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$462/0x000000080052b040@5b4c6e6d in QueuedThreadPool[SparkUI]@e48bf9a{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-12 15:09:59 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-43,5,main] exited for QueuedThreadPool[SparkUI]@e48bf9a{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-12 15:09:59 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-44,5,main] exited for QueuedThreadPool[SparkUI]@e48bf9a{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-12 15:09:59 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$462/0x000000080052b040@5b4c6e6d in QueuedThreadPool[SparkUI]@e48bf9a{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-12 15:09:59 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-37,5,main] exited for QueuedThreadPool[SparkUI]@e48bf9a{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-12 15:09:59 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-40,5,main] exited for QueuedThreadPool[SparkUI]@e48bf9a{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-12 15:09:59 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-38,5,main] exited for QueuedThreadPool[SparkUI]@e48bf9a{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-12 15:09:59 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-39,5,main] exited for QueuedThreadPool[SparkUI]@e48bf9a{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-12 15:09:59 DEBUG QueuedThreadPool:1038 - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$462/0x000000080052b040@5b4c6e6d in QueuedThreadPool[SparkUI]@e48bf9a{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-12 15:09:59 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-42,5,main] exited for QueuedThreadPool[SparkUI]@e48bf9a{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-12 15:09:59 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-41,5,main] exited for QueuedThreadPool[SparkUI]@e48bf9a{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-12 15:09:59 DEBUG QueuedThreadPool:317 - Waiting for Thread[SparkUI-41,5,main] for 14998
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:224 - STOPPED QueuedThreadPool[SparkUI]@e48bf9a{STOPPED,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-01-12 15:09:59 DEBUG AbstractLifeCycle:224 - STOPPED Server@4c59e45e{STOPPED}[9.4.40.v20210413]
2022-01-12 15:09:59 INFO  SparkUI:57 - Stopped Spark web UI at http://host.docker.internal:4040
2022-01-12 15:09:59 INFO  MapOutputTrackerMasterEndpoint:57 - MapOutputTrackerMasterEndpoint stopped!
2022-01-12 15:09:59 INFO  MemoryStore:57 - MemoryStore cleared
2022-01-12 15:09:59 INFO  BlockManager:57 - BlockManager stopped
2022-01-12 15:09:59 INFO  BlockManagerMaster:57 - BlockManagerMaster stopped
2022-01-12 15:09:59 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:57 - OutputCommitCoordinator stopped!
2022-01-12 15:09:59 INFO  SparkContext:57 - Successfully stopped SparkContext
2022-01-12 15:09:59 INFO  ShutdownHookManager:57 - Shutdown hook called
2022-01-12 15:09:59 INFO  ShutdownHookManager:57 - Deleting directory C:\Users\Rahul Kabothula\AppData\Local\Temp\spark-8327734c-8171-44b3-8cfd-9d5360e7fab3
2022-01-12 15:09:59 DEBUG ShutdownHookManager:97 - Completed shutdown in 0.249 seconds; Timeouts: 0
2022-01-12 15:09:59 DEBUG ShutdownHookManager:154 - ShutdownHookManger completed shutdown.
